{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakioh/MusiCAN/blob/main/models/musiCANmods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ATBcagDnDpM"
      },
      "source": [
        "### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjvf82O3S2Yz"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaQQJb6TXgV"
      },
      "outputs": [],
      "source": [
        "# Go to this notebook's directory\n",
        "repo_path = \"/content/drive/MyDrive/MusiCAN/\"\n",
        "%cd {repo_path}/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvGZ0ptpZQNH"
      },
      "outputs": [],
      "source": [
        "# Check GPU connection\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7_ny_A1Z6L9"
      },
      "outputs": [],
      "source": [
        "# Check RAM access\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnLdyhmuzL2Z"
      },
      "outputs": [],
      "source": [
        "# Install muspy related code\n",
        "!pip install muspy\n",
        "import muspy\n",
        "muspy.download_musescore_soundfont() \n",
        "muspy.download_bravura_font() \n",
        "\n",
        "# Install fluidsynth related code\n",
        "!apt install fluidsynth\n",
        "!pip install pyfluidsynth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgRRhU6SSfmz"
      },
      "source": [
        "# musiGAN\n",
        "\n",
        "**Description:** 1-Track MuseGAN architecture build on MiniGAN.\\\n",
        "**Purpose:** implement a composing GAN.\\\n",
        "**Results:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Zy36G-CGamF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from tqdm import notebook\n",
        "from datetime import datetime\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('tableau-colorblind10')\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy import ndimage\n",
        "\n",
        "import muspy\n",
        "import fluidsynth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trwcbyaoSfm2"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePkslq2wSfm4"
      },
      "outputs": [],
      "source": [
        "class Pianoroll :\n",
        "    def __init__ (self, filepath, bars, lowest_pitch, genre_list) :\n",
        "        assert  type(filepath) == str\n",
        "\n",
        "        # Creating the dataset from a file\n",
        "        stored_data = np.load(filepath)\n",
        "        data_array  = stored_data[\"data\"]\n",
        "        labels_array = stored_data[\"labels\"]\n",
        "        self.data   = torch.as_tensor(data_array, dtype = torch.float32)\n",
        "        self.labels = torch.as_tensor(labels_array, dtype = torch.int64)\n",
        "\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data, self.labels)\n",
        "\n",
        "        # Storing additional info about it\n",
        "        self.shape  = tuple(self.data.shape[1:])   # shape of one pianoroll image\n",
        "        self.size   = self.shape[0] * self.shape[1]\n",
        "        self.height       = self.data.shape[2]\n",
        "        self.width        = self.data.shape[1]\n",
        "        self.dataset_size = self.data.shape[0]\n",
        "\n",
        "        self.bars         = bars\n",
        "        self.lowest_pitch = lowest_pitch\n",
        "        self.genre_list   = genre_list\n",
        "\n",
        "        self.blips_per_bar  = self.width // self.bars\n",
        "        self.blips_per_beat = self.blips_per_bar // 4\n",
        "        self.pitches        = self.height\n",
        "        self.octaves        = self.pitches // 12\n",
        "        self.n_labels       = len(self.genre_list)\n",
        "\n",
        "    \n",
        "    def show (self, number = None) :\n",
        "        if number == None :\n",
        "            number = np.random.randint(self.dataset_size)\n",
        "        else :\n",
        "            assert  type(number) == int\n",
        "            assert  number >= 0 and number < self.dataset_size\n",
        "\n",
        "        plt.figure(figsize = (12, 6))\n",
        "        plt.title(f\"pianoroll #{number}\")\n",
        "        plt.imshow(self.data[number].T)\n",
        "        plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5pWodkypE8U"
      },
      "source": [
        "### LPD5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH4y0TdiRjuD"
      },
      "outputs": [],
      "source": [
        "default_training_path = \"../experiments\"\n",
        "\n",
        "#default_dataset       = \"lpd5_full_4bars\"\n",
        "default_dataset       = \"datacombi_1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCEcB4f4pE8V"
      },
      "outputs": [],
      "source": [
        "lpd5_path = \"../experiments/lpd5_full_4bars/prepared_arrays.npz\"\n",
        "lpd5_bars = 4\n",
        "lpd5_lowest_pitch = 24\n",
        "lpd5_genre_list = ['Rap', 'Latin', 'International', 'Electronic', \n",
        "                   'Country', 'Folk', 'Blues', 'Reggae', 'Jazz',\n",
        "                   'Vocal', 'New-Age', 'RnB', 'Pop_Rock']\n",
        "#lpd5 = Pianoroll(lpd5_path, lpd5_bars, lpd5_lowest_pitch, lpd5_genre_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-k4JCCXOIXS"
      },
      "outputs": [],
      "source": [
        "dc1_path = \"../experiments/datacombi_1/prepared_arrays.npz\"\n",
        "dc1_bars = 4 # actually 12 but 4 for gen and dis compatibiliy reasons.\n",
        "dc1_lowest_pitch = 24\n",
        "dc1_genre_list   = ['Latin', 'Electronic', 'Country', 'RnB', 'Pop_Rock', 'Classical', 'Game']\n",
        "\n",
        "lpd5 = Pianoroll(dc1_path, dc1_bars, dc1_lowest_pitch, dc1_genre_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRH2fKd1pE8W"
      },
      "outputs": [],
      "source": [
        "lpd5.show()\n",
        "print(\"lpd5.dataset_size\", lpd5.dataset_size)\n",
        "print(\"lpd5.shape\", lpd5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_kByFrepE8X"
      },
      "outputs": [],
      "source": [
        "print(\"lpd5.blips_per_bar\", lpd5.blips_per_bar)\n",
        "print(\"lpd5.pitches\", lpd5.pitches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tnu9HElSfm5"
      },
      "source": [
        "## Architecture classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdGO-KlvSfm5"
      },
      "source": [
        "### Support classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acpAO9NSSfm5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    These two classes serves as torch layers to binarize the output of the Generator while keeping the layer still \"backpropagatable\" (via a hardtanh).\n",
        "    This is not our own code. For source, see:\n",
        "    https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#:~:text=A%20straight%2Dthrough%20estimator%20is,function%20was%20an%20identity%20function.\n",
        "\"\"\"\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0.5).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return torch.nn.functional.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # only binarize in eval() mode, not in training\n",
        "        x = x  if self.training  else  STEFunction.apply(x)\n",
        "        #x = STEFunction.apply(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Tgofn5pfRU"
      },
      "outputs": [],
      "source": [
        "class GeneratorBlock(torch.nn.Module):\n",
        "    \"\"\" 2d transconv layer, batch normalization & ReLU \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gen_block = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose2d(in_dim, out_dim, kernel, stride),\n",
        "            torch.nn.BatchNorm2d(out_dim),\n",
        "            torch.nn.ReLU()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen_block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n38oto6cpfRW"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorBlock(torch.nn.Module):\n",
        "    \"\"\"3d conv layer & Leaky ReLU\"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "        self.dis_block = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(in_dim, out_dim, kernel, stride),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2)   # MuseGAN Hyperparameter\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dis_block(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU1bKYfdSfm6"
      },
      "source": [
        "### Main neural network classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swqlncpkJKeh"
      },
      "outputs": [],
      "source": [
        "class MusiGen (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-track museGAN generator, consisting of two sub-networks (so-called \n",
        "    temporal and bar generator)\n",
        "\n",
        "    input : seed vector, a normally distributed random vector, \n",
        "            length: (B + 1) * 64 = 5 * 64 here\n",
        "    output: pianaroll, binary tensor, shape: (B x T x P) = (4 x 48 x 84) here\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) : \n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 64\n",
        "        \n",
        "        self.temporal_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # heuristically added linear layer\n",
        "            torch.nn.Linear(1, 31),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 1\n",
        "            torch.nn.ConvTranspose1d(64, 1024, 2, 2),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 2\n",
        "            torch.nn.ConvTranspose1d(1024, 1, 3, 1),\n",
        "            torch.nn.BatchNorm1d(1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.bar_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # transconv layers\n",
        "            GeneratorBlock( 128, 1024, (2, 1), (2, 1)),\n",
        "            GeneratorBlock(1024,  512, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 512,  256, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 256,  256, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 256,  128, (3, 1), (3, 1)),\n",
        "            GeneratorBlock( 128,   64, (1, self.octaves), (1, self.octaves)),\n",
        "\n",
        "            # last layer with tanh & binarization activation fct.s\n",
        "            torch.nn.ConvTranspose2d(64, 1, (1, 12), (1, 12)),\n",
        "            torch.nn.BatchNorm2d(1),\n",
        "            torch.nn.Tanh(),\n",
        "            StraightThroughEstimator() # binarization\n",
        "        )\n",
        "        \n",
        "\n",
        "        if log :\n",
        "            print(f\"Generator: parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward_custom (self, seed) :\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  len(seed.shape) == 2\n",
        "        assert  seed.shape[0] >= 1\n",
        "        assert  seed.shape[1] == (1 + self.bars) * self.seedlength\n",
        "\n",
        "        batchsize = seed.shape[0]\n",
        "        return self.forward(batchsize, seed)\n",
        "\n",
        "\n",
        "    def forward (self, batch_size, seed = None) :\n",
        "        \n",
        "        if seed == None :\n",
        "            assert type(batch_size) == int\n",
        "            assert batch_size >= 1\n",
        "            device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "            seed = torch.normal(0., 1, (batch_size, (1 + self.bars) * self.seedlength)).to(device)\n",
        "            \n",
        "        seeds = torch.chunk(seed, chunks = 5, dim = 1)\n",
        "        \n",
        "        # create time-independent first half of seed for bar generator\n",
        "        bar_seed_1 = seeds[0]\n",
        "        bar_seed_1 = bar_seed_1.view((-1, self.seedlength, 1, 1)) # reshape for transconv layers\n",
        "\n",
        "        # generate pianorolls bar by bar\n",
        "        generated_bars = []\n",
        "        for temporal_seed in seeds[1:]:\n",
        "            \n",
        "            ## generate time-dependent second half of seed for bar generator\n",
        "\n",
        "            temporal_seed = temporal_seed.view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "            #print(f\"temporal seed: {temporal_seed.size()}\")\n",
        "            bar_seed_2 = self.temporal_generator(temporal_seed) # (batch size x 1 x 64)\n",
        "            #print(f\"bar seed 2: {bar_seed_2.size()}\")\n",
        "\n",
        "            ## reshape & concatenate both halfs of seed for bar generator \n",
        "            \n",
        "            bar_seed_2 = bar_seed_2.view(-1, self.seedlength, 1, 1)\n",
        "            bar_seed   = torch.cat((bar_seed_1, bar_seed_2), dim = 1) # (batch size x 128 x 1 x 1)\n",
        "            #print(f\"bar seed: {bar_seed d.size()}\")\n",
        "\n",
        "            ## generate one bar \n",
        "            \n",
        "            generated_bar = self.bar_generator(bar_seed) # (batch size x 1 x 24 x 84)\n",
        "            #print(f\"generated_bar: {generated_bar.size()}\")\n",
        "            generated_bars.append(generated_bar) \n",
        "\n",
        "        pianoroll = torch.cat(generated_bars, dim = 1) # (batch size x 4 x 24 x 84) \n",
        "        #print(f\"gen output: {pianoroll.size()}\")\n",
        "\n",
        "        return pianoroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOkq0b4VpfRV"
      },
      "outputs": [],
      "source": [
        "class MusiGenMod1 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-track museGAN generator, consisting of two sub-networks (so-called \n",
        "    temporal and bar generator)\n",
        "\n",
        "    input : seed vector, a normally distributed random vector, \n",
        "            length: (B + 1) * 64 = 5 * 64 here\n",
        "    output: pianaroll, binary tensor, shape: (B x T x P) = (4 x 48 x 84) here\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) : \n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 64\n",
        "        \n",
        "        self.temporal_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # heuristically added linear layer\n",
        "            torch.nn.Linear(1, 31),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 1\n",
        "            torch.nn.ConvTranspose1d(64, 1024, 2, 2),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 2\n",
        "            torch.nn.ConvTranspose1d(1024, 1, 3, 1),\n",
        "            torch.nn.BatchNorm1d(1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.bar_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # transconv layers\n",
        "            GeneratorBlock( 128, 1024, (3, 1), (3, 1)),\n",
        "            GeneratorBlock(1024,  512, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 512,  256, (1, self.octaves), (1, self.octaves)),\n",
        "            GeneratorBlock( 256,  256, (1, 12), (1, 12)),\n",
        "            GeneratorBlock( 256,  128, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 128,   64, (2, 1), (2, 1)),\n",
        "\n",
        "            # last layer with tanh & binarization activation fct.s\n",
        "            torch.nn.ConvTranspose2d(64, 1, (2, 1), (2, 1)),\n",
        "            torch.nn.BatchNorm2d(1),\n",
        "            torch.nn.Tanh(),\n",
        "            StraightThroughEstimator() # binarization\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Generator: parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward_custom (self, seed) :\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  len(seed.shape) == 2\n",
        "        assert  seed.shape[0] >= 1\n",
        "        assert  seed.shape[1] == (1 + self.bars) * self.seedlength\n",
        "\n",
        "        batchsize = seed.shape[0]\n",
        "        return self.forward(batchsize, seed)\n",
        "\n",
        "\n",
        "    def forward (self, batch_size, seed = None) :\n",
        "        \n",
        "        if seed == None :\n",
        "            assert type(batch_size) == int\n",
        "            assert batch_size >= 1\n",
        "            device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "            seed = torch.normal(0., 1, (batch_size, (1 + self.bars) * self.seedlength)).to(device)\n",
        "            \n",
        "        seeds = torch.chunk(seed, chunks = 5, dim = 1)\n",
        "        \n",
        "        # create time-independent first half of seed for bar generator\n",
        "        bar_seed_1 = seeds[0]\n",
        "        bar_seed_1 = bar_seed_1.view((-1, self.seedlength, 1, 1)) # reshape for transconv layers\n",
        "\n",
        "        # generate pianorolls bar by bar\n",
        "        generated_bars = []\n",
        "        for temporal_seed in seeds[1:]:\n",
        "            \n",
        "            ## generate time-dependent second half of seed for bar generator\n",
        "\n",
        "            temporal_seed = temporal_seed.view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "            #print(f\"temporal seed: {temporal_seed.size()}\")\n",
        "            bar_seed_2 = self.temporal_generator(temporal_seed) # (batch size x 1 x 64)\n",
        "            #print(f\"bar seed 2: {bar_seed_2.size()}\")\n",
        "\n",
        "            ## reshape & concatenate both halfs of seed for bar generator \n",
        "            \n",
        "            bar_seed_2 = bar_seed_2.view(-1, self.seedlength, 1, 1)\n",
        "            bar_seed   = torch.cat((bar_seed_1, bar_seed_2), dim = 1) # (batch size x 128 x 1 x 1)\n",
        "            #print(f\"bar seed: {bar_seed d.size()}\")\n",
        "\n",
        "            ## generate one bar \n",
        "            \n",
        "            generated_bar = self.bar_generator(bar_seed) # (batch size x 1 x 24 x 84)\n",
        "            #print(f\"generated_bar: {generated_bar.size()}\")\n",
        "            generated_bars.append(generated_bar) \n",
        "\n",
        "        pianoroll = torch.cat(generated_bars, dim = 1) # (batch size x 4 x 24 x 84) \n",
        "        #print(f\"gen output: {pianoroll.size()}\")\n",
        "\n",
        "        return pianoroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K4uNT3CJbDo"
      },
      "outputs": [],
      "source": [
        "class MusiGenMod2 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-track museGAN generator, consisting of two sub-networks (so-called \n",
        "    temporal and bar generator)\n",
        "\n",
        "    input : seed vector, a normally distributed random vector, \n",
        "            length: (B + 1) * 64 = 5 * 64 here\n",
        "    output: pianaroll, binary tensor, shape: (B x T x P) = (4 x 48 x 84) here\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) : \n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 128\n",
        "        \n",
        "        self.temporal_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # heuristically added linear layer\n",
        "            torch.nn.Linear(1, 31),\n",
        "            torch.nn.BatchNorm1d(self.seedlength),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 1\n",
        "            torch.nn.ConvTranspose1d(self.seedlength, 512, 2, 2),\n",
        "            torch.nn.BatchNorm1d(512),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 2\n",
        "            torch.nn.ConvTranspose1d(512, 1024, 2, 2),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 3\n",
        "            torch.nn.ConvTranspose1d(1024, 1, 5, 1),\n",
        "            torch.nn.BatchNorm1d(1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.bar_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # transconv layers\n",
        "            GeneratorBlock( 2*self.seedlength, 1024, (2, 1), (2, 1)),\n",
        "            GeneratorBlock(1024,  512, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 512,  256, (1, self.octaves), (1, self.octaves)),\n",
        "            GeneratorBlock( 256,  256, (1, 4), (1, 4)),\n",
        "            GeneratorBlock( 256,  256, (1, 3), (1, 3)),\n",
        "            GeneratorBlock( 256,  128, (3, 1), (3, 1)),\n",
        "            GeneratorBlock( 128,   64, (2, 1), (2, 1)),\n",
        "\n",
        "            # last layer with tanh & binarization activation fct.s\n",
        "            torch.nn.ConvTranspose2d(64, 1, (2, 1), (2, 1)),\n",
        "            torch.nn.BatchNorm2d(1),\n",
        "            torch.nn.Tanh(),\n",
        "            StraightThroughEstimator() # binarization\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Generator: parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, batch_size, seed = None) :\n",
        "        \n",
        "        if seed == None :\n",
        "            assert type(batch_size) == int\n",
        "            assert batch_size >= 1\n",
        "            device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "            seed = torch.normal(0., 1, (batch_size, (1 + self.bars) * self.seedlength)).to(device)\n",
        "            \n",
        "        seeds = torch.chunk(seed, chunks = 5, dim = 1)\n",
        "        \n",
        "        # create time-independent first half of seed for bar generator\n",
        "        bar_seed_1 = seeds[0]\n",
        "        bar_seed_1 = bar_seed_1.view((-1, self.seedlength, 1, 1)) # reshape for transconv layers\n",
        "\n",
        "        # generate pianorolls bar by bar\n",
        "        generated_bars = []\n",
        "        for temporal_seed in seeds[1:]:\n",
        "            \n",
        "            ## generate time-dependent second half of seed for bar generator\n",
        "\n",
        "            temporal_seed = temporal_seed.view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "            #print(f\"temporal seed: {temporal_seed.size()}\", temporal_seed.device)\n",
        "            #print(f\"temporal generator: {self.temporal_generator[0].device}\")\n",
        "            bar_seed_2 = self.temporal_generator(temporal_seed) # (batch size x 1 x 128)\n",
        "            #print(f\"bar seed 2: {bar_seed_2.size()}\")\n",
        "\n",
        "            ## reshape & concatenate both halfs of seed for bar generator \n",
        "        \n",
        "            bar_seed_2 = bar_seed_2.view(-1, self.seedlength, 1, 1)\n",
        "            bar_seed   = torch.cat((bar_seed_1, bar_seed_2), dim = 1) # (batch size x 256 x 1 x 1)\n",
        "            #print(f\"bar seed: {bar_seed.size()}\")\n",
        "\n",
        "            ## generate one bar \n",
        "            \n",
        "            generated_bar = self.bar_generator(bar_seed) # (batch size x 1 x 48 x 84)\n",
        "            #print(f\"generated_bar: {generated_bar.size()}\")\n",
        "            generated_bars.append(generated_bar) \n",
        "\n",
        "        pianoroll = torch.cat(generated_bars, dim = 1) # (batch size x 4 x 48 x 84) \n",
        "        #print(f\"gen output: {pianoroll.size()}\")\n",
        "\n",
        "        return pianoroll"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MusiGenMod3 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-track museGAN generator, consisting of two sub-networks (so-called \n",
        "    temporal and bar generator)\n",
        "\n",
        "    input : seed vector, a normally distributed random vector, \n",
        "            length: (B + 1) * 64 = 5 * 64 here\n",
        "    output: pianaroll, binary tensor, shape: (B x T x P) = (4 x 48 x 84) here\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) : \n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 128\n",
        "        \n",
        "        self.temporal_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # heuristically added linear layer\n",
        "            torch.nn.Linear(1, 31),\n",
        "            torch.nn.BatchNorm1d(self.seedlength),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 1\n",
        "            torch.nn.ConvTranspose1d(self.seedlength, 512, 2, 2),\n",
        "            torch.nn.BatchNorm1d(512),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 2\n",
        "            torch.nn.ConvTranspose1d(512, 1024, 2, 2),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 3\n",
        "            torch.nn.ConvTranspose1d(1024, 1, 5, 1),\n",
        "            torch.nn.BatchNorm1d(1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.bar_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # transconv layers\n",
        "            GeneratorBlock( 2*self.seedlength, 1024, (2, 1), (2, 1)),\n",
        "            GeneratorBlock(1024,  512, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 512,  256, (1, self.octaves), (1, self.octaves)),\n",
        "            GeneratorBlock( 256,  256, (1, 4), (1, 4)),\n",
        "            GeneratorBlock( 256,  256, (1, 3), (1, 3)),\n",
        "            GeneratorBlock( 256,  128, (3, 1), (3, 1)),\n",
        "            GeneratorBlock( 128,   64, (2, 1), (2, 1)),\n",
        "\n",
        "            # last layer with tanh & binarization activation fct.s\n",
        "            torch.nn.ConvTranspose2d(64, 1, (2, 1), (2, 1)),\n",
        "            torch.nn.BatchNorm2d(1),\n",
        "            torch.nn.Tanh(),\n",
        "            StraightThroughEstimator() # binarization\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Generator: parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, batch_size, seed = None) :\n",
        "        \n",
        "        if seed == None :\n",
        "            assert type(batch_size) == int\n",
        "            assert batch_size >= 1\n",
        "            device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "            seed = torch.normal(0., 1, (batch_size, (1 + self.bars) * self.seedlength)).to(device)\n",
        "            \n",
        "        seeds = torch.chunk(seed, chunks = 5, dim = 1)\n",
        "        \n",
        "        # create time-independent first half of seed for bar generator\n",
        "        track_seed = seeds[0].view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "        bar_seed_1 = self.temporal_generator(track_seed) # (batch size x 1 x 128)\n",
        "        bar_seed_1 = bar_seed_1.view((-1, self.seedlength, 1, 1)) # reshape for transconv layers\n",
        "        \n",
        "        # generate pianorolls bar by bar\n",
        "        generated_bars = []\n",
        "        for temporal_seed in seeds[1:]:\n",
        "            \n",
        "            ## generate time-dependent second half of seed for bar generator\n",
        "            temporal_seed = temporal_seed.view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "            bar_seed_2 = self.temporal_generator(temporal_seed) # (batch size x 1 x 128)\n",
        "            \n",
        "            ## reshape & concatenate both halfs of seed for bar generator \n",
        "            bar_seed_2 = bar_seed_2.view(-1, self.seedlength, 1, 1)\n",
        "            bar_seed   = torch.cat((bar_seed_1, bar_seed_2), dim = 1) # (batch size x 256 x 1 x 1)\n",
        "            \n",
        "            ## generate one bar \n",
        "            generated_bar = self.bar_generator(bar_seed) # (batch size x 1 x 48 x 84)\n",
        "            generated_bars.append(generated_bar) \n",
        "\n",
        "        pianoroll = torch.cat(generated_bars, dim = 1) # (batch size x 4 x 48 x 84) \n",
        "        \n",
        "        return pianoroll"
      ],
      "metadata": {
        "id": "I3O6lUnvtSqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aax8PSv8Rm2_"
      },
      "outputs": [],
      "source": [
        "class MusiDis (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-Track musiCAN discriminator, with 2 heads \n",
        "    \n",
        "    input : (B x T x P) binary pianoroll\n",
        "\n",
        "    output: 1. single number, prob. that the input pianoroll is a \n",
        "            real and not generated\n",
        "            2. vector of length = number of genres, prob. that the input \n",
        "            pianoroll is of a certain genre type\n",
        "\n",
        "    n_labels : number of labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) :\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        \n",
        "        self.n_labels   = lpd5.n_labels\n",
        "      \n",
        "        # common body: conv layers\n",
        "        self.discriminator_conv = torch.nn.Sequential(\n",
        "            DiscriminatorBlock(  1, 128, (2, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (3, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 1, 12), (1, 1, 12)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1,  self.octaves), (1, 1,  self.octaves)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 256, (1, 4,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(256, 512, (1, 3,  1), (1, 2,  1))\n",
        "            )\n",
        "        \n",
        "        # heads: fully-connected layers\n",
        "        self.discriminator_music_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, 1))\n",
        "        \n",
        "        self.discriminator_genre_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(512*2, 512),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(512, self.n_labels))\n",
        "\n",
        "        if log :\n",
        "            print(f\"Discriminator parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward (self, pianoroll):\n",
        "\n",
        "        # reshape input for transconvs\n",
        "        pianoroll   = pianoroll.view(-1, 1, self.bars, self.T, self.P) \n",
        "        # print(\"dis input prep.\", pianoroll.shape)\n",
        "\n",
        "        # put through common body and flatten instances\n",
        "        common_conv_output = self.discriminator_conv(pianoroll)\n",
        "        common_fc_input = common_conv_output.view(-1, 512*2)  \n",
        "        # print(\"dis conv out\", common_conv_output.size())\n",
        "\n",
        "        # put through each head to judge music (real / fake) and genre labels\n",
        "        music_judgement = self.discriminator_music_head(common_fc_input).flatten().float()\n",
        "        genre_judgement = self.discriminator_genre_head(common_fc_input).view(-1, self.n_labels).float()\n",
        "        # print(\"dis out \", music_judgement.size(), genre_judgement.size())\n",
        "\n",
        "        return music_judgement, genre_judgement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5vGYaCfpfRW"
      },
      "outputs": [],
      "source": [
        "class MusiDisMod1 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-Track musiCAN discriminator, with 2 heads \n",
        "    \n",
        "    input : (B x T x P) binary pianoroll\n",
        "\n",
        "    output: 1. single number, prob. that the input pianoroll is a \n",
        "            real and not generated\n",
        "            2. vector of length = number of genres, prob. that the input \n",
        "            pianoroll is of a certain genre type\n",
        "\n",
        "    n_labels : number of labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) :\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        \n",
        "        self.n_labels   = lpd5.n_labels\n",
        "      \n",
        "        # common body: conv layers\n",
        "        self.discriminator_conv = torch.nn.Sequential(\n",
        "            DiscriminatorBlock(  1, 128, (2, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (3, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 1, 12), (1, 1, 12)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1,  self.octaves), (1, 1,  self.octaves)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 256, (1, 4,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(256, 512, (1, 3,  1), (1, 2,  1))\n",
        "            )\n",
        "        \n",
        "        # heads: fully-connected layers\n",
        "        self.discriminator_music_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            #torch.nn.Linear(1024, 1))\n",
        "            # added\n",
        "            torch.nn.Linear(1024, 256),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(256, 16),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(16, 1))\n",
        "        \n",
        "        self.discriminator_genre_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(512*2, 512),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(512, self.n_labels))\n",
        "        if log :\n",
        "            print(f\"Discriminator parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward (self, pianoroll):\n",
        "\n",
        "        # reshape input for transconvs\n",
        "        pianoroll   = pianoroll.view(-1, 1, self.bars, self.T, self.P) \n",
        "        # print(\"dis input prep.\", pianoroll.shape)\n",
        "\n",
        "        # put through common body and flatten instances\n",
        "        common_conv_output = self.discriminator_conv(pianoroll)\n",
        "        common_fc_input = common_conv_output.view(-1, 512*2)  \n",
        "        # print(\"dis conv out\", common_conv_output.size())\n",
        "\n",
        "        # put through each head to judge music (real / fake) and genre labels\n",
        "        music_judgement = self.discriminator_music_head(common_fc_input).flatten().float()\n",
        "        genre_judgement = self.discriminator_genre_head(common_fc_input).view(-1, self.n_labels).float()\n",
        "        # print(\"dis out \", music_judgement.size(), genre_judgement.size())\n",
        "\n",
        "        return music_judgement, genre_judgement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB4I8sulRypo"
      },
      "outputs": [],
      "source": [
        "class MusiDisMod2 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-Track musiCAN discriminator, with 2 heads \n",
        "    \n",
        "    input : (B x T x P) binary pianoroll\n",
        "\n",
        "    output: 1. single number, prob. that the input pianoroll is a \n",
        "            real and not generated\n",
        "            2. vector of length = number of genres, prob. that the input \n",
        "            pianoroll is of a certain genre type\n",
        "\n",
        "    n_labels : number of labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) :\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        \n",
        "        self.n_labels   = lpd5.n_labels\n",
        "      \n",
        "        # common body: conv layers\n",
        "        self.discriminator_conv = torch.nn.Sequential(\n",
        "            DiscriminatorBlock(  1, 128, (2, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (3, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 1, 3), (1, 1, 3)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1, 4), (1, 1, 4)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1,  self.octaves), (1, 1,  self.octaves)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 256, (1, 4,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(256, 512, (1, 3,  1), (1, 2,  1))\n",
        "            )\n",
        "        \n",
        "        # heads: fully-connected layers\n",
        "        self.discriminator_music_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            #torch.nn.Linear(1024, 1)\n",
        "            # added\n",
        "            torch.nn.Linear(1024, 256),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(256, 16),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(16, 1)\n",
        "        )\n",
        "        \n",
        "        self.discriminator_genre_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(512, self.n_labels)\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Discriminator parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward (self, pianoroll):\n",
        "\n",
        "        # reshape input for transconvs\n",
        "        pianoroll   = pianoroll.view(-1, 1, self.bars, self.T, self.P) \n",
        "        # print(\"dis input prep.\", pianoroll.shape)\n",
        "\n",
        "        # put through common body and flatten instances\n",
        "        common_conv_output = self.discriminator_conv(pianoroll)\n",
        "        common_fc_input = common_conv_output.view(-1, 512*2)  \n",
        "        # print(\"dis conv out\", common_conv_output.size())\n",
        "\n",
        "        # put through each head to judge music (real / fake) and genre labels\n",
        "        music_judgement = self.discriminator_music_head(common_fc_input).flatten().float()\n",
        "        genre_judgement = self.discriminator_genre_head(common_fc_input).view(-1, self.n_labels).float()\n",
        "        # print(\"dis out \", music_judgement.size(), genre_judgement.size())\n",
        "\n",
        "        return music_judgement, genre_judgement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MusiDisMod3 (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-Track musiCAN discriminator, with 2 heads \n",
        "    \n",
        "    input : (B x T x P) binary pianoroll\n",
        "\n",
        "    output: 1. single number, prob. that the input pianoroll is a \n",
        "            real and not generated\n",
        "            2. vector of length = number of genres, prob. that the input \n",
        "            pianoroll is of a certain genre type\n",
        "\n",
        "    n_labels : number of labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) :\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        \n",
        "        self.n_labels   = lpd5.n_labels\n",
        "      \n",
        "        # common body: conv layers\n",
        "        self.discriminator_conv = torch.nn.Sequential(\n",
        "            DiscriminatorBlock(  1, 128, (2, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (3, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 1, 3), (1, 1, 3)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1, 4), (1, 1, 4)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1,  self.octaves), (1, 1,  self.octaves)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 256, (1, 4,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(256, 512, (1, 3,  1), (1, 2,  1))\n",
        "            )\n",
        "        \n",
        "        # heads: fully-connected layers\n",
        "        self.discriminator_music_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, 256),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(256, 16),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(16, 1)\n",
        "        )\n",
        "        \n",
        "        self.discriminator_genre_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, 256),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(256, 32),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(32, self.n_labels)\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Discriminator parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward (self, pianoroll):\n",
        "\n",
        "        # reshape input for transconvs\n",
        "        pianoroll   = pianoroll.view(-1, 1, self.bars, self.T, self.P) \n",
        "        # print(\"dis input prep.\", pianoroll.shape)\n",
        "\n",
        "        # put through common body and flatten instances\n",
        "        common_conv_output = self.discriminator_conv(pianoroll)\n",
        "        common_fc_input = common_conv_output.view(-1, 512*2)  \n",
        "        # print(\"dis conv out\", common_conv_output.size())\n",
        "\n",
        "        # put through each head to judge music (real / fake) and genre labels\n",
        "        music_judgement = self.discriminator_music_head(common_fc_input).flatten().float()\n",
        "        genre_judgement = self.discriminator_genre_head(common_fc_input).view(-1, self.n_labels).float()\n",
        "        # print(\"dis out \", music_judgement.size(), genre_judgement.size())\n",
        "\n",
        "        return music_judgement, genre_judgement"
      ],
      "metadata": {
        "id": "a3Y1F50Q4aZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swF_vr8kSfm9"
      },
      "source": [
        "## Training & evaluation classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG8eX-HGSfm-"
      },
      "source": [
        "### Training support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_lrgdWMSrIk"
      },
      "source": [
        "#### Training metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0p-ZDYGSfm-"
      },
      "outputs": [],
      "source": [
        "def abs_mean_diff (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "        compare two batches of data by calculating the absolute mean difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # equalize shapes\n",
        "    real_shape = real_batch.shape[-2:]\n",
        "    real_batch = real_batch.view(-1, *real_shape)\n",
        "    generated_batch = generated_batch.view(-1, *real_shape)\n",
        "    assert  generated_batch.shape == real_batch.shape\n",
        "\n",
        "    # averaged over batches \n",
        "    generated_mean = torch.mean(generated_batch, dim = 0)\n",
        "    real_mean      = torch.mean(real_batch, dim = 0)\n",
        "\n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    absolute_mean_difference = torch.mean(torch.abs(real_mean - generated_mean))\n",
        "\n",
        "    return absolute_mean_difference.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uWF5EdvzU8Y"
      },
      "outputs": [],
      "source": [
        "def abs_std_diff (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "        compare two batches of data by calculating the absolute standard deviation difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # equalize shapes\n",
        "    real_shape = real_batch.shape[-2:]\n",
        "    real_batch = real_batch.view(-1, *real_shape)\n",
        "    generated_batch = generated_batch.view(-1, *real_shape)\n",
        "    assert  generated_batch.shape == real_batch.shape\n",
        "\n",
        "    # averaged over batches \n",
        "    generated_std = torch.std(generated_batch, dim = 0, unbiased = True)\n",
        "    real_std      = torch.std(real_batch, dim = 0, unbiased = True)\n",
        "    \n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    absolute_std_difference = torch.mean(torch.abs(real_std - generated_std))\n",
        "\n",
        "    return absolute_std_difference.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvYGRG9z2dR-"
      },
      "outputs": [],
      "source": [
        "def inter_bar_var (generated_batch) :\n",
        "    \"\"\"\n",
        "        computes the inter-bar standard deviation\n",
        "    \"\"\"\n",
        "\n",
        "    inter_bar_std_dev = torch.mean(torch.std(generated_batch, dim = 1, \n",
        "                                             unbiased = True)) # std over bars\n",
        "    \n",
        "    return inter_bar_std_dev.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NjqpcV34U3t"
      },
      "outputs": [],
      "source": [
        "def inter_track_var (generated_batch) :\n",
        "    \"\"\"\n",
        "        computes the inter-track standard deviation\n",
        "    \"\"\"\n",
        "\n",
        "    inter_track_std_dev = torch.mean(torch.std(generated_batch, dim = 0, \n",
        "                                               unbiased = True)) # std over tracks\n",
        "    \n",
        "    return inter_track_std_dev.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS0kN-LMSzV0"
      },
      "source": [
        "#### Loss function support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYO2ATSm3oRb"
      },
      "outputs": [],
      "source": [
        "def unif_cross_entropy(probabilities, weight):\n",
        "    return(torch.mean(weight * torch.log(probabilities)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWKiWR-hYbJG"
      },
      "outputs": [],
      "source": [
        "def softmax(probabilities, safe_normalization = True, eps = 0.000001):\n",
        "  \n",
        "    if safe_normalization == \"safe\":\n",
        "        exp_probs = torch.exp(probabilities)\n",
        "        normalization = torch.maximum(torch.sum(exp_probs, dim = 1), eps)\n",
        "  \n",
        "        if normalization > 0: \n",
        "            return(exp_probs / normalization)\n",
        "    \n",
        "        else:\n",
        "            return(exp_probs)\n",
        "  \n",
        "    else:\n",
        "        return(torch.nn.functional.softmax(probabilities, dim = 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_sum(probabilities):\n",
        "    sig_probs = torch.sigmoid(probabilities)\n",
        "    normalization = torch.sum(sig_probs, dim = 1)\n",
        "    return(sig_probs / normalization)"
      ],
      "metadata": {
        "id": "EUWhfPU55OlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0LYqJUeUJne"
      },
      "outputs": [],
      "source": [
        "# Note: this function comes directly from the museGAN tutorial [1].\n",
        "def compute_gradient_penalty(discriminator, real_samples, fake_samples, device):\n",
        "    \"\"\"Compute the gradient penalty for regularization. Intuitively, the\n",
        "    gradient penalty help stablize the magnitude of the gradients that the\n",
        "    discriminator provides to the generator, and thus help stablize the training\n",
        "    of the generator.\"\"\"\n",
        "    # Get random interpolations between real and fake samples\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1).to(device)\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n",
        "    interpolates = interpolates.requires_grad_(True)\n",
        "    \n",
        "    # Get the discriminator output for the interpolations\n",
        "    d_interpolates, _ = discriminator(interpolates)\n",
        "    # Get gradients w.r.t. the interpolations\n",
        "    fake = torch.ones(real_samples.size(0)).to(device)\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    # Compute gradient penalty\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/musegan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ejVE_JNS2VE"
      },
      "source": [
        "#### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxg1fBDoSfm_"
      },
      "outputs": [],
      "source": [
        "class Log :\n",
        "    \"\"\"\n",
        "        container class for GANTraining logs\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__ (self, rounds, dis_rounds, n_labels) :\n",
        "        self.losses        = np.zeros((7, rounds)) \n",
        "        self.music_probs   = np.zeros((2, rounds))\n",
        "        self.genre_probs   = np.zeros((1 + n_labels, rounds))\n",
        "        self.abs_diff      = np.zeros((2, rounds))  # abs_mean_diff(), abs_std_diff()\n",
        "        self.gen_var       = np.zeros((2, rounds))  # inter_bar_var(), inter_track_var()\n",
        "        \n",
        "        self._dis_losses   = torch.zeros((5, dis_rounds)).cpu()\n",
        "        self._music_probs  = torch.zeros((2, dis_rounds)).cpu()\n",
        "        self._genre_probs  = torch.zeros((1 + n_labels, rounds)).cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMlCiiOwBybk"
      },
      "outputs": [],
      "source": [
        "class LogLoaded :\n",
        "    \"\"\"\n",
        "        A class to load stored Log data from an .npz file\n",
        "        and to use it exactly like Log.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log_dictionary) :\n",
        "        for keyword, value in log_dictionary.items() :\n",
        "            setattr(self, keyword, value)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WstRQBd2SfnA"
      },
      "source": [
        "### GANTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg1SZJl7SfnA"
      },
      "outputs": [],
      "source": [
        "class GANTraining :\n",
        "    \"\"\"\n",
        "        general GAN training class\n",
        "        How To Use:\n",
        "        * `MyTrain = GANTraining(<Generator>, <Discriminator>, <torch_dataset>)`\n",
        "        * `MyTrain.setup(<int_rounds>, batchsize = 1, discriminator_rounds = 1,     \n",
        "                        loss_function = [\"WGAN\", \"GAN\"])`\n",
        "        * `MyTrain.train()`\n",
        "      \n",
        "        After That:\n",
        "        * `MyTrain.gen` contains trained Generator\n",
        "        * `MyTrain.dis` contains trained Discriminator\n",
        "        * `MyTrain.log` contains metrics from each round (see class Log)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, Gen, Dis, dataset) :\n",
        "        assert  type(dataset) == torch.utils.data.dataset.TensorDataset\n",
        "        \n",
        "        self.device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "\n",
        "        # GAN classes and dataset\n",
        "        self.n_labels = lpd5.n_labels     # number of labels in dataset, automate maybe\n",
        "        self.GenClass = Gen\n",
        "        self.DisClass = Dis\n",
        "        self.dataset  = dataset\n",
        "        \n",
        "\n",
        "    def setup (self, rounds, batch_size = 1, discriminator_rounds = 1, \n",
        "               loss_function = \"CAN\", norm_dis_probs = False) :\n",
        "        assert  type(rounds) == int\n",
        "        assert  rounds >= 1\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 1\n",
        "        assert  type(discriminator_rounds) == int\n",
        "        assert  discriminator_rounds >= 1\n",
        "        assert  loss_function in [\"GAN\", \"WGAN\", \"WGAN-GP\", \"CAN\",  \"WCAN-GP\"]\n",
        "\n",
        "        # Training parameters\n",
        "        self.rounds     = rounds\n",
        "        self.batch_size = batch_size\n",
        "        self.dis_rounds = discriminator_rounds\n",
        "        self.loss       = loss_function\n",
        "        self.norm_dis_probs = norm_dis_probs\n",
        "        self.start_round = 0\n",
        "\n",
        "        # Dataloader\n",
        "        self.data_loader = torch.utils.data.DataLoader(self.dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                drop_last = True,\n",
        "                                shuffle = True)\n",
        "        self.dataset_size = self.dataset.tensors[0].shape[0]  # number of instances in dataset\n",
        "        self.batch_count = self.dataset_size // self.batch_size\n",
        "        self._batch_idx  = self.batch_count \n",
        "        \n",
        "        # Logs\n",
        "        self.log    = Log(self.rounds, self.dis_rounds, self.n_labels)\n",
        "        self.backup = False   # only on if self.set_backup() is run\n",
        "        \n",
        "        # Initialize GAN\n",
        "        self.gen = self.GenClass().to(self.device)\n",
        "        self.dis = self.DisClass().to(self.device)\n",
        "        self.optimizer_gen = torch.optim.Adam(self.gen.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        self.optimizer_dis = torch.optim.Adam(self.dis.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        # Note: ADAM parameters from GAN tutorial [1].\n",
        "\n",
        "\n",
        "    def resume (self, gen, dis, logs, start_round) :\n",
        "        assert  isinstance(gen, self.GenClass)\n",
        "        assert  isinstance(dis, self.DisClass)\n",
        "        assert  type(start_round) == int\n",
        "        assert  start_round > 1 and start_round < self.rounds\n",
        "        \n",
        "        # Load models\n",
        "        self.gen = gen.to(self.device).train()\n",
        "        self.dis = dis.to(self.device).train()\n",
        "\n",
        "        # Load partial logs full log\n",
        "        for name, array in logs.__dict__.items() :\n",
        "            #print(name, array.shape)\n",
        "            log_array = getattr(self.log, name)\n",
        "            #print(\"log\", name, log_array.shape)\n",
        "            if name[0] == \"_\" :\n",
        "                array = torch.from_numpy(array).cpu()\n",
        "            log_array[:, :start_round] = array[:, :start_round]\n",
        "            setattr(self.log, name, log_array)\n",
        "            #print(\"\")\n",
        "\n",
        "        self.start_round = start_round\n",
        "\n",
        "       \n",
        "    def set_backups (self, training_name, checkpoints) :\n",
        "        assert  type(training_name) == str\n",
        "        for element in checkpoints :\n",
        "            assert  type(element) == int\n",
        "            assert  element > 0  and  element <= self.rounds\n",
        "        \n",
        "        self.training_name   = training_name\n",
        "        self.training_folder = \"\"   # 'timestamp+training_name', gets set at first backup\n",
        "        self.checkpoints     = [point for point in checkpoints\n",
        "                                if point > self.start_round]\n",
        "        self.backup          = True  # Flag for rest of code\n",
        "\n",
        "\n",
        "\n",
        "    def _get_batch (self) :\n",
        "        \"\"\"\n",
        "            samples one batch of data from self.data_loader without replacement.\n",
        "            When the self.data_set is depleted of fresh batches, \n",
        "            self.data_loader will shuffle a list of new batches.\n",
        "        \"\"\"\n",
        "        if self._batch_idx >= self.batch_count :\n",
        "            self._data_iter = iter(self.data_loader)\n",
        "            self._batch_idx = 0\n",
        "        batch_data, batch_labels = self._data_iter.next()\n",
        "        batch_data = batch_data.view(-1, lpd5.bars, \n",
        "                                     lpd5.blips_per_bar, lpd5.pitches)\n",
        "        self._batch_idx += 1\n",
        "\n",
        "        return batch_data.to(self.device), batch_labels.to(self.device)\n",
        "\n",
        "\n",
        "    def train (self) :\n",
        "        assert  hasattr(self, \"data_loader\")  # If test fails, you haven't run set_params()\n",
        "\n",
        "        print(f\"Training\")\n",
        "        arranged_tensor = torch.arange(self.batch_size) # used each round\n",
        "  \n",
        "        for round in notebook.tqdm(range(self.start_round, self.rounds)) :\n",
        "            for dis_round in range(self.dis_rounds) :\n",
        "                # Forward propagation\n",
        "                batch_real, labels_real        = self._get_batch()\n",
        "                music_dis_real, genre_dis_real = self.dis.forward(batch_real)\n",
        "                self.music_prob_real = torch.sigmoid(music_dis_real)\n",
        "                genre_probs_real     = softmax(genre_dis_real)\n",
        "                self.genre_prob_real = genre_probs_real[arranged_tensor, labels_real] # get prob of real genre\n",
        "                \n",
        "                batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "                music_dis_gen, genre_dis_gen = self.dis.forward(batch_gen)\n",
        "                self.music_prob_gen  = torch.sigmoid(music_dis_gen)\n",
        "                self.genre_probs_gen = softmax(genre_dis_gen)\n",
        "                \n",
        "                # Calculating the Discriminator loss function\n",
        "                if self.loss == \"GAN\" :\n",
        "                    self.loss_real_music = - torch.mean(torch.log(self.music_prob_real))\n",
        "                    self.loss_gen_music  = - torch.mean(torch.log(1 - self.music_prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "                    self.loss_real_genre = torch.tensor(0.)\n",
        "                \n",
        "                elif self.loss == \"WGAN\" :\n",
        "                    var_gen   = torch.var(music_dis_gen)\n",
        "                    var_real  = torch.var(music_dis_real)\n",
        "                    self.loss_reg  = torch.where(var_gen > 1, \n",
        "                                                 (var_gen - 1)**2, 0) \\\n",
        "                                     + torch.where(var_real > 1, \n",
        "                                                   (var_real - 1)**2, 0)\n",
        "                    self.loss_real_music = - torch.mean(music_dis_real)\n",
        "                    self.loss_gen_music  = torch.mean(music_dis_gen)\n",
        "                    self.loss_real_genre = torch.tensor(0.)\n",
        "                \n",
        "                elif self.loss == \"WGAN-GP\" :    \n",
        "                    gradient_penalty = compute_gradient_penalty(\n",
        "                        self.dis, batch_real, batch_gen, self.device)\n",
        "                    self.loss_reg        = 10 * gradient_penalty\n",
        "                    self.loss_real_music = - torch.mean(music_dis_real)\n",
        "                    self.loss_gen_music  = torch.mean(music_dis_gen)\n",
        "                    self.loss_real_genre = torch.tensor(0.)\n",
        "                \n",
        "\n",
        "                elif self.loss == \"CAN\" :\n",
        "                    self.loss_real_music = - torch.mean(torch.log(self.music_prob_real))\n",
        "                    self.loss_real_genre = - torch.mean(torch.log(self.genre_prob_real))\n",
        "                    self.loss_gen_music = - torch.mean(torch.log(1 - self.music_prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "\n",
        "                elif self.loss == \"WCAN-GP\" : \n",
        "                    self.loss_reg  = 10.0 * compute_gradient_penalty(\n",
        "                                     self.dis, batch_real, batch_gen, self.device)\n",
        "                    self.loss_real_music = - torch.mean(music_dis_real)\n",
        "                    self.loss_real_genre = - torch.mean(torch.log(self.genre_prob_real))\n",
        "                    self.loss_gen_music  = torch.mean(music_dis_gen)\n",
        "\n",
        "                if self.norm_dis_probs :\n",
        "                    prob_norm        = torch.mean((self.music_prob_real + \n",
        "                        self.music_prob_gen - 1)**2)\n",
        "                    self.loss_reg += 1 * prob_norm\n",
        "                \n",
        "                self.loss_dis = self.loss_real_music + self.loss_real_genre \\\n",
        "                              + self.loss_gen_music + self.loss_reg\n",
        "                self._log_all(round, k = dis_round)\n",
        "                \n",
        "                # Discriminator update\n",
        "                self.optimizer_dis.zero_grad()\n",
        "                self.loss_dis.backward()\n",
        "                self.optimizer_dis.step()\n",
        "                \n",
        "\n",
        "            # Calculating the Generator loss function\n",
        "            batch_new = self.gen.forward(batch_size = self.batch_size)\n",
        "            music_dis_new, genre_dis_new = self.dis.forward(batch_new)\n",
        "                \n",
        "            if self.loss == \"GAN\" :\n",
        "                music_prob_new = torch.sigmoid(music_dis_new)\n",
        "                self.loss_gen_music = -torch.mean(torch.log(music_prob_new)) \n",
        "                self.loss_gen_genre = torch.tensor(0.)\n",
        "            \n",
        "            elif self.loss == \"WGAN\" :\n",
        "                self.loss_gen_music = -torch.mean(music_dis_new)\n",
        "                self.loss_gen_genre = torch.tensor(0.)\n",
        "\n",
        "            elif self.loss == \"WGAN-GP\" :\n",
        "                self.loss_gen_music = -torch.mean(music_dis_new)\n",
        "                self.loss_gen_genre = torch.tensor(0.)\n",
        "            \n",
        "            elif self.loss == \"CAN\" :\n",
        "                music_prob_new = torch.sigmoid(music_dis_new)\n",
        "                genre_probs_new = softmax(genre_dis_new)\n",
        "\n",
        "                self.loss_gen_music = - torch.mean(music_prob_new)\n",
        "                self.loss_gen_genre = - torch.mean( \\\n",
        "                    unif_cross_entropy(genre_probs_new, 1 / self.n_labels) + \\\n",
        "                    unif_cross_entropy(1 - genre_probs_new, 1 - 1 / self.n_labels))\n",
        "\n",
        "            elif self.loss == \"WCAN-GP\" :\n",
        "                music_prob_new = torch.sigmoid(music_dis_new)\n",
        "                genre_probs_new = softmax(genre_dis_new)\n",
        "\n",
        "                self.loss_gen_music = - torch.mean(music_dis_new)\n",
        "                self.loss_gen_genre = - torch.mean( \\\n",
        "                    unif_cross_entropy(genre_probs_new, 1 / self.n_labels) + \\\n",
        "                    unif_cross_entropy(1 - genre_probs_new, 1 - 1 / self.n_labels))\n",
        "\n",
        "            self.loss_gen = self.loss_gen_music + self.loss_gen_genre\n",
        "\n",
        "            self._log_all(round)\n",
        "                \n",
        "            \n",
        "            # Generator update\n",
        "            self.optimizer_gen.zero_grad()\n",
        "            self.loss_gen.backward()\n",
        "            self.optimizer_gen.step()\n",
        "\n",
        "\n",
        "            # Make a backup\n",
        "            if self.backup  and  (round + 1) in self.checkpoints :\n",
        "                self._save_checkpoint(round + 1)\n",
        "\n",
        "            # Stop Training if diverges\n",
        "            divergence = torch.any(torch.isnan(self.loss_dis.detach().cpu()))\n",
        "            if divergence:\n",
        "                print(\"Training stopped: nan values encontered.\")\n",
        "                break\n",
        "                                \n",
        "            \n",
        "        # Put GAN in eval mode\n",
        "        self.gen.eval()\n",
        "        self.dis.eval()\n",
        "        print(\"Training complete. GAN now in eval() mode.\")\n",
        "\n",
        "\n",
        "    def _save_checkpoint (self, round) :\n",
        "        if round == min(self.checkpoints) :\n",
        "            self.training_folder = save_training(self.training_name, \n",
        "                                        self, checkpoint = round)\n",
        "            print(f\"Saved checkpoint {round} under '{self.training_folder}'.\")\n",
        "        else :\n",
        "            save_training(self.training_folder, self, \n",
        "                            checkpoint = round, new_folder = False)\n",
        "            print(f\"Saved checkpoint {round}.\")\n",
        "\n",
        "\n",
        "    def _log_all (self, round, k = -1) :\n",
        "        if k >= 0 : # before each Discriminator update\n",
        "            self.log._dis_losses[0, k] = self.loss_dis.cpu().detach()\n",
        "            self.log._dis_losses[1, k] = self.loss_real_music.cpu().detach()\n",
        "            self.log._dis_losses[2, k] = self.loss_real_genre.cpu().detach()\n",
        "            self.log._dis_losses[3, k] = self.loss_gen_music.cpu().detach()\n",
        "            self.log._dis_losses[4, k] = self.loss_reg.cpu().detach()\n",
        "\n",
        "            self.log._music_probs[0, k] = self.music_prob_real.mean().cpu().detach()\n",
        "            self.log._music_probs[1, k] = self.music_prob_gen.mean().cpu().detach()\n",
        "            self.log._genre_probs[0, k]  = self.genre_prob_real.mean().cpu().detach() # prob of right label of real batch\n",
        "            self.log._genre_probs[1:, k] = self.genre_probs_gen.mean(dim = 0).cpu().detach() # prob of genres of generated batch\n",
        "        \n",
        "        if k == -1 : # before each Generator update\n",
        "            # Losses\n",
        "            dis_losses = self.log._dis_losses.detach().cpu().numpy()\n",
        "            self.log.losses[:4, round] = dis_losses[:4].mean(axis = 1)\n",
        "            self.log.losses[5, round] = dis_losses[4].mean()\n",
        "            self.log.losses[4, round]  = self.loss_gen.detach().cpu().numpy()\n",
        "            self.log.losses[6, round]  = self.loss_gen_genre.detach().cpu().numpy()\n",
        "            \n",
        "            # Discriminator Probabilities\n",
        "            music_probs                 = self.log._music_probs.cpu().detach().numpy()\n",
        "            genre_probs                 = self.log._genre_probs.cpu().detach().numpy()\n",
        "            self.log.music_probs[:, round] = music_probs.mean(axis = 1)\n",
        "            self.log.genre_probs[:, round] = genre_probs.mean(axis = 1)\n",
        "\n",
        "            # Generator metrics\n",
        "            batch_real, _ = self._get_batch()\n",
        "            batch_gen     = self.gen.forward(batch_size = self.batch_size)\n",
        "            self.log.abs_diff[0, round] = abs_mean_diff(batch_gen, batch_real)\n",
        "            self.log.abs_diff[1, round] = abs_std_diff(batch_gen, batch_real)\n",
        "            self.log.gen_var[0, round]  = inter_bar_var(batch_gen)\n",
        "            self.log.gen_var[1, round]  = inter_track_var(batch_gen)\n",
        "            \n",
        "\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UjwRjHiook6"
      },
      "source": [
        "### Evaluation support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixzSjpbOS64f"
      },
      "source": [
        "#### Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3STzYDPRS9HD"
      },
      "outputs": [],
      "source": [
        "def empty_bar_ratio (data) :\n",
        "    \"\"\"\n",
        "        ratio of bars devoid of notes\n",
        "        \n",
        "        also called:\n",
        "            EB = \"empty bar ratio\"\n",
        "    \"\"\"\n",
        "\n",
        "    if type(data) == torch.Tensor :\n",
        "        data = data.cpu().detach().numpy()\n",
        "\n",
        "    data = data.reshape((-1, lpd5.bars, lpd5.blips_per_bar, lpd5.pitches)) # split into bars\n",
        "    data_reduced = np.mean(data, axis = (2, 3)).flatten() # mean over bar pixels\n",
        "    data_mask    = np.array(data_reduced == 0)  # bool of which bars are empty\n",
        "    empty_bar_fraction = np.mean(data_mask)  # mean over all bars\n",
        "\n",
        "    return empty_bar_fraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GclWeQ3TU7hU"
      },
      "outputs": [],
      "source": [
        "def pitch_classes_per_bar (data) :\n",
        "    \"\"\"\n",
        "        number of pitch classes used per bar (from 0 to 12)\n",
        "        \n",
        "        also called:\n",
        "            UPC = \"used pitch classes per bar\"\n",
        "    \"\"\"\n",
        "\n",
        "    if type(data) == torch.Tensor :\n",
        "        data = data.cpu().detach().numpy()\n",
        "\n",
        "    data = data.reshape((-1, lpd5.bars, lpd5.blips_per_bar, lpd5.pitches)) # split into bars\n",
        "    data = data.reshape((-1, lpd5.blips_per_bar, lpd5.pitches))  # array of bars\n",
        "    data = data.reshape((-1, lpd5.blips_per_bar, lpd5.octaves, 12)) # split into octaves\n",
        "    \n",
        "    pitches_used = np.any(data, axis = (1, 2))  # OR over timesteps and octaves\n",
        "    number_pitches = np.sum(pitches_used, axis = 1) # sum over pitches\n",
        "    mean_pitch_classes_per_bar = np.mean(number_pitches) # mean over all bars\n",
        "    \n",
        "    return mean_pitch_classes_per_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10tasJPahEvQ"
      },
      "outputs": [],
      "source": [
        "def qualified_note_ratio (data) :\n",
        "    \"\"\"\n",
        "        ratio of \"qualified\" notes,\n",
        "        defined as a 3 blips/timesteps or longer. \n",
        "        In the current lpd5 dataset with 48-blip bars that is a 1/16 note.\n",
        "        ! Not like in museGAN (used 96-blip bars and thus a 1/32 note threshold)\n",
        "        \n",
        "        also called:\n",
        "            QN = \"qualified note ratio\"\n",
        "    \"\"\"\n",
        "    minimum_length = 3 # blips\n",
        "\n",
        "    if type(data) == torch.Tensor :\n",
        "        data = data.cpu().detach().numpy()\n",
        "\n",
        "    data = data.reshape((-1, lpd5.width, lpd5.height)) # whole tracks\n",
        "    conv = np.array([-1, 1]) # used to measure note start and ends\n",
        "\n",
        "    total_notes       = 0\n",
        "    total_quali_notes = 0\n",
        "    for track in data :\n",
        "        for pitch_line in track.T :\n",
        "            note_starts = np.convolve(pitch_line, conv)\n",
        "            note_stops  = np.convolve(pitch_line, -conv)\n",
        "            start_indices = np.where(note_starts == -1)[0]\n",
        "            stop_indices  = np.where(note_stops == -1)[0]\n",
        "            \n",
        "            note_lengths     = stop_indices - start_indices\n",
        "            note_count       = note_lengths.shape[0]\n",
        "            quali_note_count = np.sum(note_lengths >= minimum_length)\n",
        "            total_notes       += note_count\n",
        "            total_quali_notes += quali_note_count\n",
        "\n",
        "    quali_note_ratio = total_quali_notes / total_notes\n",
        "\n",
        "    return quali_note_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEpHEch60X02"
      },
      "outputs": [],
      "source": [
        "def muspy_metrics (data) :\n",
        "    \"\"\"\n",
        "    computes 4 muspy metrics from a batch of pianoroll data\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    averaged_metrics : np.array, size = (4), dtype = float\n",
        "        all values taken from whole pianoroll tracks and\n",
        "        are averaged over all tracks\n",
        "        1. muspy.pitch_range()\n",
        "            pitch range from lowest to highest pitch\n",
        "        2. muspy.polyphony()\n",
        "            average number of pitches being played concurrently\n",
        "        3. muspy.scale_consistency()\n",
        "            how many of the notes are in the track’s main scale \n",
        "            (max of notes in any scale)\n",
        "        4. muspy.empty_measure_rate()\n",
        "            ratio of 1/4 note beats where no note is played\n",
        "            \"measure\" is here defined as 1/4 notes by us.\n",
        "\n",
        "        For more details, see [1]\n",
        "\n",
        "    [1] https://muspy.readthedocs.io/en/stable/metrics.html?highlight=measures#other-metrics\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if type(data) == torch.Tensor :\n",
        "        data = data.cpu().detach().numpy()\n",
        "\n",
        "    data = data.reshape((-1, lpd5.width, lpd5.height)) # whole tracks\n",
        "    data.dtype = bool\n",
        "    \n",
        "    pianorolls = np.pad(data, \n",
        "                        ((0, 0), (0, 0), \n",
        "                         (lpd5.lowest_pitch, \n",
        "                          128 - lpd5.lowest_pitch - lpd5.height))\n",
        "                 )   # complete the pitch range\n",
        "    \n",
        "    muspy_stats = np.zeros((4, data.shape[0]))\n",
        "    for i, track in enumerate(pianorolls):\n",
        "        piano_music = muspy.from_pianoroll_representation(\n",
        "                        track,\n",
        "                        resolution = lpd5.blips_per_beat, \n",
        "                        encode_velocity = False\n",
        "                    )   # convert to muspy.music_object\n",
        "                  \n",
        "        muspy_stats[0, i] = muspy.pitch_range(piano_music)\n",
        "        muspy_stats[1, i] = muspy.polyphony(piano_music)\n",
        "        muspy_stats[2, i] = muspy.scale_consistency(piano_music)\n",
        "        muspy_stats[3, i] = muspy.empty_measure_rate(piano_music, \n",
        "                                                     lpd5.blips_per_beat)\n",
        "        \n",
        "    averaged_metrics = np.nanmean(muspy_stats, axis = 1)\n",
        "    \n",
        "    return averaged_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqBIvah5RK7k"
      },
      "outputs": [],
      "source": [
        "# Calculate key metrics of dataset for evaluation\n",
        "\n",
        "lpd5_metrics_file = f\"{default_training_path}/{default_dataset}/lpd5_metrics.json\"\n",
        "\n",
        "if not os.path.exists(lpd5_metrics_file):\n",
        "    # Calculating these metrics takes several minutes for lpd5.\n",
        "    # Therefore, they are calculated once and then stored in a file.\n",
        "    metrics = {}\n",
        "    metrics[\"abs_mean_diff\"]   = 0   # difference of dataset to itself\n",
        "    metrics[\"abs_std_diff\"]    = 0\n",
        "    metrics[\"inter_bar_var\"]   = inter_bar_var(lpd5.data.view(-1, lpd5.bars, lpd5.blips_per_bar, lpd5.pitches))\n",
        "    metrics[\"inter_track_var\"] = inter_track_var(lpd5.data)\n",
        "    metrics[\"empty_bar_ratio\"]        = empty_bar_ratio(lpd5.data)\n",
        "    metrics[\"pitch_classses_per_bar\"] = pitch_classes_per_bar(lpd5.data)\n",
        "    metrics[\"qualified_note_ratio\"]   = qualified_note_ratio(lpd5.data)\n",
        "    metrics[\"muspy_metrics\"] = muspy_metrics(lpd5.data)\n",
        "    with open(lpd5_metrics_file, 'wb') as file :\n",
        "        pickle.dump(metrics, file)\n",
        "\n",
        "\n",
        "with open(lpd5_metrics_file, 'rb') as file :\n",
        "    # Loading all metrics is much quicker than recalculating them\n",
        "    metrics = pickle.load(file)\n",
        "    lpd5.abs_mean_diff   = metrics[\"abs_mean_diff\"]\n",
        "    lpd5.abs_std_diff    = metrics[\"abs_std_diff\"]\n",
        "    lpd5.inter_bar_var   = metrics[\"inter_bar_var\"]\n",
        "    lpd5.inter_track_var = metrics[\"inter_track_var\"]\n",
        "    lpd5.empty_bar_ratio        = metrics[\"empty_bar_ratio\"]\n",
        "    lpd5.pitch_classses_per_bar = metrics[\"pitch_classses_per_bar\"]\n",
        "    lpd5.qualified_note_ratio   = metrics[\"qualified_note_ratio\"]\n",
        "    lpd5.muspy_metrics = metrics[\"muspy_metrics\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyJRhxx8L_4y"
      },
      "source": [
        "#### Show results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VBC5mONqw-T"
      },
      "outputs": [],
      "source": [
        "def plot_training (log, dataset = lpd5, CAN = False, show_loss_terms = False) :\n",
        "    training_rounds = log.losses.shape[1]\n",
        "    rounds          = np.arange(training_rounds) + 1\n",
        "    filter_size     = math.ceil(training_rounds / 100)\n",
        "    med_filter      = lambda x: ndimage.median_filter(x, size = filter_size)\n",
        "    \n",
        "    \n",
        "\n",
        "    # Training metrics\n",
        "\n",
        "    plt.figure(figsize = (16, 8))\n",
        "    plt.suptitle(\"Training metrics\", size=18)\n",
        "    \n",
        "    ## Losses\n",
        "    plt.title(\"Losses\")\n",
        "    dis_loss = log.losses[0]\n",
        "    gen_loss = log.losses[4]\n",
        "    plt.plot(rounds, dis_loss, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, gen_loss, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, med_filter(dis_loss), label=\"Discriminator Loss\", \n",
        "             c=\"b\") #, lw = 0.5)\n",
        "    plt.plot(rounds, med_filter(gen_loss), label=\"Generator Loss\", \n",
        "             c=\"r\") #, lw = 0.5)\n",
        "    plt.xlabel(\"round\")\n",
        "    plt.yscale('symlog', linthreshy = 10)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    if show_loss_terms :\n",
        "        plt.figure(figsize=(16,4))\n",
        "        plt.title(r\"Discriminator & Generator Loss Terms\")\n",
        "        loss_term_labels = [\"Music Discriminator on Real Data\",\n",
        "                          \"Genre Discriminator for Real Label\",\n",
        "                          \"Music Discriminator on Generated Data\",\n",
        "                          \"Cross Entropy of Genre Discriminator on Generated Data\",\n",
        "                          \"Regulizer Term\"]\n",
        "        for label_idx, loss_idx in enumerate([1,2,3,6,5]):\n",
        "            loss_term = log.losses[loss_idx]\n",
        "            plt.plot(rounds, med_filter(loss_term), label=loss_term_labels[label_idx])\n",
        "      \n",
        "        plt.xlabel(\"round\")\n",
        "        plt.yscale('symlog', linthreshy = 10)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    ## Probabilities\n",
        "    plt.figure(figsize=(16,4))\n",
        "    prob_real = log.music_probs[0]\n",
        "    prob_gen  = log.music_probs[1]\n",
        "    prob_diff = prob_real - prob_gen\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(r\"$p_{Dis}(data_{real} = real)$\")\n",
        "    plt.plot(rounds, np.ones_like(prob_real), \n",
        "             linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "    plt.plot(rounds, np.zeros_like(prob_real), \n",
        "             linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "    plt.plot(rounds, prob_real, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, med_filter(prob_real), c=\"b\") #, lw = 0.5)\n",
        "    plt.xlabel(\"round\")\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(r\"$p_{Dis}(data_{real} = real) - p_{Dis}(data_{gen} = real)$\")\n",
        "    plt.plot(rounds, np.ones_like(prob_diff), \n",
        "             linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "    plt.plot(rounds, np.zeros_like(prob_diff), \n",
        "             linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "    plt.plot(rounds, prob_diff, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, med_filter(prob_diff), c=\"b\") #, lw = 0.5)\n",
        "    plt.xlabel(\"round\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "    ## CAN metrics\n",
        "    if CAN :\n",
        "        genre_probs = log.genre_probs[1:]\n",
        "        \n",
        "        plt.title(\"Batch-averaged Generator Probabilities during Training\")\n",
        "        plt.plot(rounds, np.ones(genre_probs.shape[1]), \n",
        "                 linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "        plt.plot(rounds, np.zeros(genre_probs.shape[1]), \n",
        "                 linestyle=\"-.\", lw=0.5, color='k', alpha=0.3)\n",
        "        plt.plot(rounds, genre_probs.T)\n",
        "        plt.xlabel(\"round\")\n",
        "        plt.legend(dataset.genre_list)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # Generator metrics\n",
        "\n",
        "    plt.figure(figsize=(16,6))\n",
        "    plt.suptitle(\"Generator metrics\", size=18)\n",
        "    abs_mean_diff   = log.abs_diff[0]\n",
        "    abs_std_diff    = log.abs_diff[1]\n",
        "    inter_bar_var   = log.gen_var[0]\n",
        "    inter_track_var = log.gen_var[1]\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Absolute mean and std difference to dataset\")\n",
        "    plt.plot(rounds, abs_mean_diff, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, abs_std_diff, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, med_filter(abs_mean_diff), label = \"abs_mean_diff\", \n",
        "             c='b') #, lw = 0.5)\n",
        "    plt.plot(rounds, med_filter(abs_std_diff), label = \"abs_std_diff\", \n",
        "             c=\"r\") #, lw = 0.5)\n",
        "    plt.xlabel(\"round\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Generator variation\")\n",
        "    plt.plot(rounds, np.ones_like(inter_bar_var) * lpd5.inter_bar_var, \n",
        "             linestyle=\"--\", lw=0.5, color='b', label=\"dataset bar-wise std.\")\n",
        "    plt.plot(rounds, np.ones_like(inter_bar_var) * lpd5.inter_track_var, \n",
        "             linestyle=\"--\", lw=0.5, color='r', label=\"dataset track-wise std.\")\n",
        "    plt.plot(rounds, inter_bar_var, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, inter_track_var, lw = 0.5, alpha=0.5)\n",
        "    plt.plot(rounds, med_filter(inter_bar_var), label = \"bar-wise std dev.\", \n",
        "             c=\"b\") #, lw = 0.5)\n",
        "    plt.plot(rounds, med_filter(inter_track_var), label = \"track-wise std dev.\", \n",
        "             c=\"r\") #, lw = 0.5)\n",
        "    plt.xlabel(\"round\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWBpY1DkSfm_"
      },
      "outputs": [],
      "source": [
        "def long_test (generator, discriminator, data, test_size = 1000, \n",
        "               dataset = default_dataset): \n",
        "    \"\"\"\n",
        "        runs a detailed evaluation of generator performance\n",
        "        and compares it to the training data set in a pandas table\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    with torch.inference_mode() :  # saves gpu memory\n",
        "        device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "        \n",
        "        # Test on generated data\n",
        "        generator.eval().to(device)\n",
        "        discriminator.eval().to(device)\n",
        "        data_real, labels_real = iter(torch.utils.data.DataLoader(data.dataset,\n",
        "                        batch_size = test_size, \n",
        "                        shuffle = True, drop_last = True)\n",
        "                    ).next()  # make one batch of test_size\n",
        "        data_real   = data_real.to(device)\n",
        "        labels_real = labels_real.to(device)\n",
        "\n",
        "        ## Generator\n",
        "        data_generated = generator.forward(batch_size = test_size)\n",
        "        \n",
        "        gen_abs_mean_diff   = abs_mean_diff(data_generated, data_real)\n",
        "        gen_abs_std_diff    = abs_std_diff(data_generated, data_real)\n",
        "        gen_inter_bar_var   = inter_bar_var(data_generated)\n",
        "        gen_inter_track_var = inter_track_var(data_generated)\n",
        "\n",
        "        gen_empty_bar_ratio        = empty_bar_ratio(data_generated)\n",
        "        gen_pitch_classses_per_bar = pitch_classes_per_bar(data_generated)\n",
        "        gen_qualified_note_ratio   = qualified_note_ratio(data_generated)\n",
        "\n",
        "        gen_muspy_metrics = muspy_metrics(data_generated)\n",
        "\n",
        "    # Create comparison table: generated data vs. real data\n",
        "    \n",
        "    real_music_metrics = np.array([\n",
        "        lpd5.abs_mean_diff,\n",
        "        lpd5.abs_std_diff,\n",
        "        lpd5.inter_bar_var,\n",
        "        lpd5.inter_track_var,\n",
        "        lpd5.empty_bar_ratio,\n",
        "        lpd5.pitch_classses_per_bar,\n",
        "        lpd5.qualified_note_ratio,\n",
        "        lpd5.muspy_metrics[0],\n",
        "        lpd5.muspy_metrics[1],\n",
        "        lpd5.muspy_metrics[2],\n",
        "        lpd5.muspy_metrics[3],\n",
        "    ], dtype = float).round(2)\n",
        "    gen_music_metrics = np.array([\n",
        "        gen_abs_mean_diff,\n",
        "        gen_abs_std_diff,\n",
        "        gen_inter_bar_var,\n",
        "        gen_inter_track_var,\n",
        "        gen_empty_bar_ratio,\n",
        "        gen_pitch_classses_per_bar,\n",
        "        gen_qualified_note_ratio,\n",
        "        gen_muspy_metrics[0],\n",
        "        gen_muspy_metrics[1],\n",
        "        gen_muspy_metrics[2],\n",
        "        gen_muspy_metrics[3],\n",
        "    ], dtype = float).round(2)\n",
        "\n",
        "    table_dict = {\n",
        "        \"Metrics\":[\n",
        "            \"Absoluted mean difference\", \n",
        "            \"Absoluted standard deviation difference\", \n",
        "            \"Inter-bar standard deviation\",\n",
        "            \"Inter-track standard deviation\",\n",
        "            \"Empty bar ratio\",\n",
        "            \"Used pitch classes per bar\",\n",
        "            \"Qualified note ratio\",\n",
        "            \"Pitch range\",\n",
        "            \"Polyphony\",\n",
        "            \"Scale consistency\",\n",
        "            \"Empty 1/4 note ratio\",\n",
        "        ],\n",
        "        \"real music\":real_music_metrics,\n",
        "        \"generated music\":gen_music_metrics,\n",
        "        \"Abbreviation\":[\"AMD\", \"ASD\", \"IBS\", \"ITS\", \"EB\", \"UPC\", \"QN\", \n",
        "                        \"PR\", \"PL\", \"SC\", \"EN\",],\n",
        "        \"metric source\":[\"own\", \"own\", \"own\", \"own\", \n",
        "                        \"museGAN\", \"museGAN\", \"museGAN\",\n",
        "                        \"muspy\", \"muspy\", \"muspy\", \"muspy\",],        \n",
        "    }\n",
        "    \n",
        "    table_panda = pd.DataFrame(table_dict)\n",
        "    \n",
        "    print(\"Comparison between the real and the generated music\\n\")\n",
        "    display(table_panda)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntUausIx9L9q"
      },
      "outputs": [],
      "source": [
        "# Tweak1: Toggle to only `show_best` according to discriminator\n",
        "# Tweak2: `show_real` data instead of generated\n",
        "# Tweak3: Choose `playback_speed` (3 for 4-bar tracks, 1 for 12-bar tracks)\n",
        "# Tweak4: Save samples from a `checkpoint` in a subfolder of that name.\n",
        "def quick_test (generator, discriminator, data, test_size = 100, num_images = 1, \n",
        "                dataset = default_dataset, save_to = None, show_best = False,\n",
        "                show_real = False, playback_speed = 3, checkpoint = 0) : \n",
        "\n",
        "    device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "\n",
        "    # Calculating Discriminator predictions\n",
        "    with torch.inference_mode() :    \n",
        "        # Loading real data and models\n",
        "        generator.eval().to(device)\n",
        "        discriminator.eval().to(device)\n",
        "        data_real, labels_real = iter(torch.utils.data.DataLoader(data.dataset,\n",
        "                        batch_size = test_size, \n",
        "                        shuffle = True, drop_last = True)\n",
        "                    ).next()  # make one batch of test_size\n",
        "        data_real   = data_real.to(device)\n",
        "        labels_real = labels_real.to(device)\n",
        "\n",
        "        # Generator\n",
        "        data_generated = generator.forward(batch_size = test_size)\n",
        "        \n",
        "\n",
        "        # Discriminator\n",
        "        music_dis_gen,  genre_dis_gen  = discriminator.forward(data_generated)\n",
        "        music_prob_gen  = torch.sigmoid(music_dis_gen)\n",
        "        std_prob_gen    = torch.std_mean(music_prob_gen, unbiased=True)\n",
        "        \n",
        "        music_dis_real, genre_dis_real = discriminator.forward(data_real)\n",
        "        music_prob_real = torch.sigmoid(music_dis_real)\n",
        "        std_prob_real   = torch.std_mean(music_prob_real, unbiased=True)\n",
        "        \n",
        "        # Converting some generated data to pianorolls\n",
        "        if show_real :\n",
        "            show_data = data_real.cpu().detach().numpy()\n",
        "            probs = music_prob_real.cpu().detach().numpy()\n",
        "        else :\n",
        "            show_data = data_generated.cpu().detach().numpy()\n",
        "            probs = music_prob_gen.cpu().detach().numpy()\n",
        "        if show_best :\n",
        "            best        = np.argpartition(-probs, num_images)\n",
        "            images      = show_data[best]\n",
        "            their_probs = probs[best]\n",
        "        else :\n",
        "            images      = show_data[:num_images]\n",
        "            their_probs = probs[:num_images]\n",
        "        images         = images.reshape(-1, data.width, data.height)\n",
        "        pianorolls     = np.pad(images, ((0, 0), (0, 0), \n",
        "                                        (data.lowest_pitch, \n",
        "                                        128 - data.lowest_pitch - data.height)))   \n",
        "                            # complete the pitch range\n",
        "\n",
        "    # Create audio save folder\n",
        "    default_path = f\"{default_training_path}/{dataset}\"\n",
        "    if save_to == None :\n",
        "        audio_folder = f\"{default_path}/temp_audio\"\n",
        "    else :\n",
        "        if checkpoint == 0 :\n",
        "            subfolder = \"\"\n",
        "        else :\n",
        "            subfolder = f\"/{checkpoint}\"\n",
        "        audio_folder = f\"{default_path}/{save_to}/audio{subfolder}\"\n",
        "    try:   # make new folder\n",
        "        os.makedirs(audio_folder)\n",
        "    except OSError:   # it already exists\n",
        "        pass\n",
        "\n",
        "\n",
        "    # Discriminator Results\n",
        "    print(f\"Discriminator p(x_real = real) = \" +\n",
        "        f\"{std_prob_real[1]*100:.0f}±{std_prob_real[0]*100:.0f}%\")\n",
        "    print(f\"Discriminator p(x_gen = real)  = \" +\n",
        "        f\"{std_prob_gen[1]*100:.0f}±{std_prob_gen[0]*100:.0f}%\")\n",
        "    print(\"\\n\\n\")\n",
        "    \n",
        "    # Generator examples\n",
        "    if show_real :\n",
        "        print(\"Example of the real music\")\n",
        "    else :\n",
        "        print(\"Example of the generated music\")\n",
        "    print(f\"saved under '{audio_folder}'\")\n",
        "    for i in range(num_images) :\n",
        "        beat_resolution = playback_speed * data.blips_per_beat // 3 \n",
        "        piano_music = muspy.from_pianoroll_representation(pianorolls[i] > 0,\n",
        "                        resolution = beat_resolution, \n",
        "                        encode_velocity = False)   # convert to muspy.music_object\n",
        "        \n",
        "        # save audio tracks\n",
        "        timestamp     = datetime.now()\n",
        "        audiopath     = f\"{audio_folder}/{timestamp}.wav\"\n",
        "        pianorollpath = f\"{audio_folder}/{timestamp}.npy\"\n",
        "        muspy.write_audio(path = audiopath, music = piano_music)\n",
        "        np.save(pianorollpath, pianorolls[i])\n",
        "\n",
        "        # Display example pianorolls with audio\n",
        "        kind = 'real'  if show_real else  'gen'\n",
        "        print(\"\")\n",
        "        print(f\"p(x_{kind} = real)  = {their_probs[i]*100:.2f}%\")\n",
        "        print(f\"file: {timestamp}.wav\")\n",
        "        \n",
        "        display(Audio(filename = audiopath))\n",
        "        muspy.visualization.show_pianoroll(piano_music)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4rFGcgSMO7j"
      },
      "source": [
        "#### Save and load trained models and logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m92AAeQbMMl1"
      },
      "outputs": [],
      "source": [
        "def save_training (training_name, trainer, info_txt = None, \n",
        "                   dataset = default_dataset, new_folder = True, \n",
        "                   checkpoint = 0) :\n",
        "    assert  type(training_name) == str               \n",
        "    assert  info_txt == None  or  type(info_txt) == str\n",
        "    \n",
        "    # If trainer has already saved a checkpoint, no new folder is needed.\n",
        "    if hasattr(trainer, \"training_name\") :\n",
        "        if (training_name == trainer.training_name  and\n",
        "            trainer.training_folder != \"\") :\n",
        "            \n",
        "            training_name = trainer.training_folder\n",
        "            new_folder    = False\n",
        "    \n",
        "    # Name the save folder\n",
        "    if new_folder:\n",
        "        now             = datetime.now()\n",
        "        date            = f\"{now.year}-{now.month:02d}-{now.day:02d}\"\n",
        "        time            = f\"{now.hour:02d}-{now.minute:02d}\"\n",
        "        timestamp       = f\"{date}_{time}\"\n",
        "        training_folder = f\"{timestamp}_{training_name}\"\n",
        "    else :\n",
        "        training_folder = training_name\n",
        "    save_folder = f\"{default_training_path}/{dataset}/{training_folder}\"\n",
        "    \n",
        "    model_folder = f\"{save_folder}/model\"\n",
        "    try:   # make new folder\n",
        "        os.makedirs(model_folder)\n",
        "    except OSError:   # it already exists\n",
        "        pass\n",
        "    \n",
        "\n",
        "    # save models\n",
        "    gen = trainer.gen\n",
        "    dis = trainer.dis\n",
        "    \n",
        "    if checkpoint == 0 :\n",
        "        torch.save(gen.state_dict(), f\"{model_folder}/gen.pt\")\n",
        "        torch.save(dis.state_dict(), f\"{model_folder}/dis.pt\")\n",
        "    else : \n",
        "        # here, checkpoint is an int: the current training round number\n",
        "        torch.save(gen.state_dict(), f\"{model_folder}/gen{checkpoint}.pt\")\n",
        "        torch.save(dis.state_dict(), f\"{model_folder}/dis{checkpoint}.pt\")\n",
        "\n",
        "    # save logs\n",
        "    if checkpoint == 0 :\n",
        "        log_file = f\"{save_folder}/logs.npz\"\n",
        "        log_dict = trainer.log.__dict__\n",
        "    else :\n",
        "        # here, checkpoint is an int: the current training round number\n",
        "        total_rounds = checkpoint\n",
        "        log_file = f\"{save_folder}/logs{checkpoint}.npz\"\n",
        "        log_dict = trainer.log.__dict__.copy()\n",
        "        # shorten the log arrays to current checkpoint \n",
        "        for key, value in log_dict.items() :\n",
        "            if type(value) == np.ndarray :\n",
        "                log_dict[key] = value[:, :total_rounds]\n",
        "    \n",
        "    np.savez(log_file, **log_dict)     \n",
        "    \n",
        "\n",
        "    # save additional info about training\n",
        "    info_path  = f\"{save_folder}/info.txt\"\n",
        "    and_info   = \"\"\n",
        "    if info_txt != None :\n",
        "        with open(info_path, \"w+\") as f :\n",
        "            f.writelines(info_txt)\n",
        "        and_info = \"and info text \"  \n",
        "    \n",
        "    if checkpoint == 0:\n",
        "        print(f\"Saved models {and_info}under:\\n\",\n",
        "            f\"'{default_training_path}/{dataset}/\\n\",\n",
        "            f\" {training_folder}'\")\n",
        "        \n",
        "    return training_folder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK6Iwny8CvsL"
      },
      "outputs": [],
      "source": [
        "def load_training (training_folder, model = (MusiGen, MusiDis), \n",
        "                   print_info = False, dataset = default_dataset, \n",
        "                   checkpoint = 0) :\n",
        "    save_folder = f\"{default_training_path}/{dataset}/{training_folder}\"\n",
        "    assert  os.path.exists(save_folder)\n",
        "\n",
        "    # load models\n",
        "    model_folder       = f\"{save_folder}/model\"\n",
        "    GenClass, DisClass = model\n",
        "    gen, dis           = GenClass(), DisClass()\n",
        "    cp = \"\"  if checkpoint == 0 else  f\"{checkpoint}\"   # here, checkpoint is an int: the current training round number\n",
        "    device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    gen.load_state_dict(torch.load(f\"{model_folder}/gen{cp}.pt\", \n",
        "                                   map_location = device))\n",
        "    dis.load_state_dict(torch.load(f\"{model_folder}/dis{cp}.pt\",\n",
        "                                   map_location = device))\n",
        "    \n",
        "\n",
        "    # Prepare models for evaluation\n",
        "    device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "    gen    = gen.to(device)\n",
        "    dis    = dis.to(device)\n",
        "    gen.eval()\n",
        "    dis.eval()\n",
        "\n",
        "    # load logs\n",
        "    if checkpoint == 0 :\n",
        "        log_file = f\"{save_folder}/logs.npz\"\n",
        "    else :\n",
        "        log_file = f\"{save_folder}/logs{checkpoint}.npz\"\n",
        "\n",
        "    logs = None\n",
        "    with np.load(log_file) as log_dict :\n",
        "        logs = LogLoaded(log_dict)\n",
        "    \n",
        "    # load info\n",
        "    info_path  = f\"{save_folder}/info.txt\"\n",
        "    if print_info :\n",
        "        with open(info_path, \"r\") as f :\n",
        "            print(f.read())\n",
        "    \n",
        "    return gen, dis, logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7J679rwSfnC"
      },
      "source": [
        "## Network training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6uuHHR6fQOe"
      },
      "source": [
        "### Main Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_folder = \"2022-09-15_19-48_8k-mod2-can-dc1\"\n",
        "checkpoint      = 6000\n",
        "gen, dis, logs  = load_training (training_folder, \n",
        "                                 model = (MusiGenMod2, MusiDisMod2),\n",
        "                                 checkpoint = checkpoint)"
      ],
      "metadata": {
        "id": "RRKwUQ8--NW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gasGW3KpSfnM"
      },
      "outputs": [],
      "source": [
        "training_name = \"8k-mod2-can-dc1\"\n",
        "lpd5Train     = GANTraining(MusiGenMod2, MusiDisMod2, lpd5.dataset)\n",
        "lpd5Train.setup(8000, batch_size = 25, discriminator_rounds = 5, \n",
        "                loss_function = \"WCAN-GP\", norm_dis_probs = True)\n",
        "lpd5Train.resume(gen, dis, logs, start_round = checkpoint)\n",
        "lpd5Train.set_backups(training_name, checkpoints = [4000, 6000, 6500, 7000, 7500])\n",
        "lpd5Train.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eBKbfRJbh6D"
      },
      "outputs": [],
      "source": [
        "info_text     = \\\n",
        "f\"\"\"\n",
        "Training info: {training_name}\n",
        "=======================\n",
        "\n",
        "models: MusiGenMod2, MusiDisMod2\n",
        "dataset: datacombi_1\n",
        "\n",
        "rounds = 8000\n",
        "batch_size = 25\n",
        "discriminator_rounds = 5\n",
        "loss_function = WCAN-GP+norm*\n",
        "checkpoints   = [4000, 6000, 6500, 7000, 7500]\n",
        "\n",
        "adam_optimizer_params:\n",
        "    gen: (lr = 0.001, betas = (0.5, 0.9))\n",
        "    dis: (lr = 0.001, betas = (0.5, 0.9))\n",
        "\n",
        "additional comments:\n",
        "    * genre loss term have a factor 10 before them\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47lzP9FrGRaI"
      },
      "outputs": [],
      "source": [
        "training_folder_name = save_training(training_name, lpd5Train, info_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXwYSkWt3oRg"
      },
      "outputs": [],
      "source": [
        "plot_training(lpd5Train.log, CAN = False, show_loss_terms = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd-LOltQSfnN"
      },
      "outputs": [],
      "source": [
        "long_test(lpd5Train.gen, lpd5Train.dis, lpd5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlOBH55thlJQ"
      },
      "outputs": [],
      "source": [
        "quick_test(lpd5Train.gen, lpd5Train.dis, lpd5, num_images = 5, \n",
        "           save_to = training_folder_name, playback_speed = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb-NJGprfWGK"
      },
      "source": [
        "### Loading and investigating old trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load 1"
      ],
      "metadata": {
        "id": "Ae7T8wSzuIJ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI_lD4kCfbl0"
      },
      "outputs": [],
      "source": [
        "#gen, dis, logs = load_training(training_folder_name, print_info = True)\n",
        "loaded_folder = \"2022-09-15_21-23_8k-mod2-can-dc1\"\n",
        "gen, dis, logs = load_training(loaded_folder, \n",
        "                               print_info = True, #checkpoint=4000, \n",
        "                               model = (MusiGenMod2, MusiDisMod2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7D5VmVLffr7"
      },
      "outputs": [],
      "source": [
        "plot_training(logs, CAN = True, show_loss_terms = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUYxjanafl3a"
      },
      "outputs": [],
      "source": [
        "long_test(gen, dis, lpd5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajOJ3t7ngFgr"
      },
      "outputs": [],
      "source": [
        "quick_test(gen, dis, lpd5, num_images = 10, show_best = False,\n",
        "           show_real = False, playback_speed = 1, \n",
        "           #checkpoint = 4000,\n",
        "           save_to = loaded_folder,\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load 2"
      ],
      "metadata": {
        "id": "gshIJIV-uNbN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB1MAvmo66e_"
      },
      "outputs": [],
      "source": [
        "def dis_check (generator, discriminator, data, test_size = 100, num_images = 1, \n",
        "                dataset = default_dataset, save_to = None, show_best = False,\n",
        "                show_real = False, playback_speed = 3, checkpoint = 0) : \n",
        "\n",
        "    device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "\n",
        "    # Calculating Discriminator predictions\n",
        "    with torch.inference_mode() :    \n",
        "        # Loading real data and models\n",
        "        generator.eval().to(device)\n",
        "        discriminator.eval().to(device)\n",
        "        data_real, labels_real = iter(torch.utils.data.DataLoader(data.dataset,\n",
        "                        batch_size = test_size, \n",
        "                        shuffle = True, drop_last = True)\n",
        "                    ).next()  # make one batch of test_size\n",
        "        data_real   = data_real.to(device)\n",
        "        labels_real = labels_real.to(device)\n",
        "\n",
        "        # Generator\n",
        "        data_generated = generator.forward(batch_size = test_size)\n",
        "        \n",
        "\n",
        "        # Discriminator\n",
        "        music_dis_gen,  genre_dis_gen  = discriminator.forward(data_generated)\n",
        "        music_prob_gen  = torch.sigmoid(music_dis_gen)\n",
        "        std_prob_gen    = torch.std_mean(music_prob_gen, unbiased=True)\n",
        "        \n",
        "        music_dis_real, genre_dis_real = discriminator.forward(data_real)\n",
        "        music_prob_real = torch.sigmoid(music_dis_real)\n",
        "        std_prob_real   = torch.std_mean(music_prob_real, unbiased=True)\n",
        "        \n",
        "\n",
        "        return music_dis_gen,  genre_dis_gen, music_dis_real, genre_dis_real"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music_dis_gen,  genre_dis_gen, music_dis_real, genre_dis_real = \\\n",
        "    dis_check(gen, dis, lpd5, test_size = 10)"
      ],
      "metadata": {
        "id": "8pgSGfI_p6aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_dis_gen.shape"
      ],
      "metadata": {
        "id": "nh0dWUZktKm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = softmax(genre_dis_gen)\n",
        "print(sm.shape)\n",
        "sm"
      ],
      "metadata": {
        "id": "Hoacf50jqGrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(sm, dim=1)"
      ],
      "metadata": {
        "id": "00lhJQRuqbt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mgp = torch.mean(sm, dim=0)\n",
        "mean_genre_probs = mgp.cpu().detach().numpy()\n",
        "mgp"
      ],
      "metadata": {
        "id": "1dhjqL-StTLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(lpd5.genre_list, mean_genre_probs)\n"
      ],
      "metadata": {
        "id": "jFxIb_iQthIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load 3"
      ],
      "metadata": {
        "id": "2gCCfHbIuQcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quick_test(gen, dis, lpd5, num_images = 5, show_best = False,\n",
        "           show_real = False, playback_speed = 1, \n",
        "           save_to = loaded_folder, \n",
        "           checkpoint = 4000)"
      ],
      "metadata": {
        "id": "nZbCOtRkxUHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93bpgNMruOJL"
      },
      "outputs": [],
      "source": [
        "gen2, dis2, logs2 = load_training(\"2022-09-12_02-14_10k-vanilla-musegan\", \n",
        "                                  model = (MusiGen_old, MusiDis_old),\n",
        "                                  print_info = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzEwzqch6Rcu"
      },
      "outputs": [],
      "source": [
        "quick_test(gen2, dis2, lpd5, num_images = 5, show_best = True) #, save_to = \"2022-09-12_19-55_20k-reproduce-musgan-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJGlxDXep2P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8ATBcagDnDpM",
        "trwcbyaoSfm2",
        "E5pWodkypE8U",
        "3tnu9HElSfm5",
        "KdGO-KlvSfm5",
        "kU1bKYfdSfm6",
        "L_lrgdWMSrIk",
        "xS0kN-LMSzV0",
        "6ejVE_JNS2VE",
        "ixzSjpbOS64f",
        "LyJRhxx8L_4y"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('aml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9db57278ae8397bc5fe3bec6b9ba53c33a2aa76e79d386f678fc754e34f9547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}