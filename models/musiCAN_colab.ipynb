{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjvf82O3S2Yz",
        "outputId": "166f92b2-6f45-41d1-84b9-49a3bf2cf03e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU connection\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvGZ0ptpZQNH",
        "outputId": "cdc933fb-88bb-4c8f-d909-5dd8eed488ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  9 08:14:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check RAM access\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7_ny_A1Z6L9",
        "outputId": "ad90af07-50f9-4b1f-9fdd-2a5b5cfeebad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakioh/MusiCAN/blob/main/models/first_music_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgRRhU6SSfmz"
      },
      "source": [
        "# musiGAN\n",
        "\n",
        "**Description:** 1-Track MuseGAN architecture build on MiniGAN.\\\n",
        "**Purpose:** implement a composing GAN.\\\n",
        "**Results:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Zy36G-CGamF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from tqdm import notebook\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('tableau-colorblind10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4FXsUC5Sfm2"
      },
      "source": [
        "## Class and function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trwcbyaoSfm2"
      },
      "source": [
        "### Data creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wrtg4LZNSfm3"
      },
      "outputs": [],
      "source": [
        "class CentralDotImage :\n",
        "    \"\"\"\n",
        "        creates mock data set out of a simple image copied multiple times\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "        __init__(height, width, dataset_size = 100) : \n",
        "            creates all attributes\n",
        "        show() : \n",
        "            plt.plots image\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        height : int\n",
        "            of image, in pixels\n",
        "        width : int\n",
        "            of image, in pixels\n",
        "        size : int\n",
        "            number of pixels in image\n",
        "        dataset_size : int\n",
        "            number of images\n",
        "        \n",
        "        image : torch.Tensor\n",
        "            out of 1s and 0s,\n",
        "            size = (width, height)\n",
        "        vector : torch.Tensor\n",
        "            flattened image,\n",
        "            size = (size)\n",
        "        data : torch.Tensor\n",
        "            images copied dataset_size times\n",
        "            size = (dataset_size, size)\n",
        "        dataset : torch.TensorDataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, height, width, dataset_size = 100) :\n",
        "        # Input checks\n",
        "        assert  type(height) == int \n",
        "        assert  height >= 1 \n",
        "        assert  type(width) == int\n",
        "        assert  width >= 1\n",
        "        assert  type(dataset_size) == int\n",
        "        assert  dataset_size >= 1\n",
        "\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.shape  = (height, width)\n",
        "        self.size   = height * width\n",
        "        self.dataset_size = dataset_size\n",
        "\n",
        "        # Image creation\n",
        "        self.image = torch.zeros(height, width)\n",
        "        for i in range(height) :\n",
        "            for j in range(width) :\n",
        "                self.image[i, j] = \\\n",
        "                    i + 1 <= math.ceil(3/4 * height) and \\\n",
        "                    i + 1 > math.floor(1/4 * height) and \\\n",
        "                    j + 1 <= math.ceil(3/4 * width) and \\\n",
        "                    j + 1 > math.floor(1/4 * width)\n",
        "\n",
        "        # Dataset creation\n",
        "        self.vector  = self.image.flatten()\n",
        "        self.data    = self.vector[None, :].expand(dataset_size, self.size)\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data)\n",
        "\n",
        "    def show (self) :\n",
        "        plt.imshow(self.image)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ePkslq2wSfm4"
      },
      "outputs": [],
      "source": [
        "class Pianoroll :\n",
        "    def __init__ (self, filepath) :\n",
        "        assert  type(filepath) == str\n",
        "\n",
        "        # Creating the dataset from a file\n",
        "        stored_data = np.load(filepath)\n",
        "        data_array  = stored_data[\"data\"]\n",
        "        label_array = stored_data[\"labels\"]\n",
        "        self.data   = torch.as_tensor(data_array, dtype = torch.float32)\n",
        "        self.labels = torch.as_tensor(label_array, dtype = torch.int64)\n",
        "\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data, self.labels)\n",
        "\n",
        "        # Storing additional info about it\n",
        "        self.shape  = tuple(self.data.shape[1:])   # shape of one pianoroll image\n",
        "        self.size   = self.shape[0] * self.shape[1]\n",
        "        self.height       = self.data.shape[2]\n",
        "        self.width        = self.data.shape[1]\n",
        "        self.dataset_size = self.data.shape[0]\n",
        "\n",
        "        self.genre_list = ['Rap', 'Latin', 'International', 'Electronic', \n",
        "                           'Country', 'Folk', 'Blues', 'Reggae', 'Jazz',\n",
        "                           'Vocal', 'New-Age', 'RnB', 'Pop_Rock']\n",
        "    \n",
        "    def show (self, number = None) :\n",
        "        if number == None :\n",
        "            number = np.random.randint(self.dataset_size)\n",
        "        else :\n",
        "            assert  type(number) == int\n",
        "            assert  number >= 0 and number < self.dataset_size\n",
        "\n",
        "        plt.figure(figsize = (12, 3))\n",
        "        plt.title(f\"pianoroll #{number}\")\n",
        "        plt.imshow(self.data[number].T)\n",
        "        plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tnu9HElSfm5"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdGO-KlvSfm5"
      },
      "source": [
        "#### Support classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "acpAO9NSSfm5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    These two classes serves as torch layers to binarize the output of the Generator while keeping the layer still \"backpropagatable\" (via a hardtanh).\n",
        "    This is not our own code. For source, see:\n",
        "    https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#:~:text=A%20straight%2Dthrough%20estimator%20is,function%20was%20an%20identity%20function.\n",
        "\"\"\"\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return torch.nn.functional.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU1bKYfdSfm6"
      },
      "source": [
        "#### Parent Network classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WV9CrCJySfm6"
      },
      "outputs": [],
      "source": [
        "class Network (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "        General neural network class for specialized networks.\n",
        "        Create those by:\n",
        "        ```\n",
        "        myNet = Network(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myNet.create_model(layer_list)\n",
        "        myNet.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self) : \n",
        "        super().__init__()\n",
        "    \n",
        "\n",
        "    def print_stats (self) :\n",
        "        print(f\"{self.name}:\")\n",
        "        print(f\"    input length:  {self.I}\")\n",
        "        print(f\"    output length: {self.O}\")\n",
        "        if hasattr(self, 'model') :\n",
        "            print(f\"    layers:        {len(self.model)}\")\n",
        "            print(f\"    parameters:    {self.count_params()}\")\n",
        "        else :\n",
        "            print(f\"    Create the network architecture with .create_model(<layer_list>)\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, input, numpy_out = False) :\n",
        "        \"\"\"run network\"\"\"\n",
        "        output = self.model(input)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def _numpify (self, tensor) :\n",
        "        return tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h-X5wb88Sfm7"
      },
      "outputs": [],
      "source": [
        "class Generator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Generator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myGen = Generator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myGen.create_model(layer_list)\n",
        "        myGen.print_stats()\n",
        "        ```\n",
        "\n",
        "        There are two forward() variants:\n",
        "        * `forward(batchsize = 0, numpy_out = False)` with auto-generated normally distributed seeds.\n",
        "        * `forward_custom(seed, numpy_out = False)` with custom seeds as input.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, batch_size = 0, numpy_out = False) :\n",
        "        \"\"\"run network with a batch of normally distributed seeds\"\"\"\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 0\n",
        "\n",
        "        # Seed generation\n",
        "        if batch_size == 0 :\n",
        "            seed_size = (self.I,)\n",
        "        else :\n",
        "            seed_size = (batch_size, self.I)\n",
        "        seed = torch.normal(0, 1, seed_size)\n",
        "        \n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out)\n",
        "\n",
        "            \n",
        "    def forward_custom (self, seed, numpy_out = False) :\n",
        "        \"\"\"run network with custom seed\"\"\"\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  seed.shape[-1] == self.I\n",
        "\n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out = numpy_out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lGwxqBfzSfm8"
      },
      "outputs": [],
      "source": [
        "class Discriminator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Discriminator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myDis = Discriminator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myDis.create_model(layer_list)\n",
        "        myDis.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, input, prob_out = False, numpy_out = False) :\n",
        "        \"\"\"\n",
        "            run network, optionally return probability (default logit) or numpy array (default torch)\n",
        "        \"\"\"\n",
        "        assert  type(input) in [torch.Tensor, np.ndarray]\n",
        "        assert  input.shape[-1] == self.I\n",
        "\n",
        "        if type(input) == np.ndarray :\n",
        "            input = torch.tensor(input)\n",
        "\n",
        "        # Running the network\n",
        "        \n",
        "        output = super().forward(input)\n",
        "        if prob_out :\n",
        "            output = torch.sigmoid(output)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swF_vr8kSfm9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG8eX-HGSfm-"
      },
      "source": [
        "#### Support classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unif_cross_entropy(probabilities, weight):\n",
        "  return(torch.mean(weight * torch.log(probabilities)))"
      ],
      "metadata": {
        "id": "OVUkrN64aa2F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D0p-ZDYGSfm-"
      },
      "outputs": [],
      "source": [
        "def generator_goodness (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "        compare two batches of data by calculating the absolute mean difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # averaged over batches \n",
        "    generated_mean = torch.mean(generated_batch)\n",
        "    real_mean      = torch.mean(real_batch)\n",
        "\n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    goodness_criteria = torch.mean(torch.abs(real_mean - generated_mean))\n",
        "\n",
        "    return goodness_criteria.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Jxg1fBDoSfm_"
      },
      "outputs": [],
      "source": [
        "class Log :\n",
        "    \"\"\"\n",
        "        container class for GANTraining logs\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__ (self) :\n",
        "        self.losses       = None\n",
        "        self.music_probs  = None # probs how real / fake music\n",
        "        self.genre_probs  = None # probs of each genre labels of music\n",
        "        self.gen_goodness = None\n",
        "        self._dis_losses  = None\n",
        "        self._music_probs = None\n",
        "        self._genre_probs = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mWBpY1DkSfm_"
      },
      "outputs": [],
      "source": [
        "def quick_test(generator, discriminator, data, test_size = 10, num_images = 1): \n",
        "    \n",
        "    # Test on generated data\n",
        "    generator.eval()\n",
        "    discriminator.eval()\n",
        "    device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "    data_real = iter(torch.utils.data.DataLoader(data.dataset,  # make a batch\n",
        "                     batch_size = test_size, \n",
        "                     shuffle = True, drop_last = True)\n",
        "                ).next()[0].to(device)\n",
        "    \n",
        "    ## Generator\n",
        "    data_generated = generator.forward(batch_size = test_size)\n",
        "\n",
        "    ## Discriminator\n",
        "\n",
        "    gen_judgements  = discriminator.forward(data_generated)\n",
        "    real_judgements = discriminator.forward(data_real)\n",
        "    gen_probs       = torch.sigmoid(gen_judgements)\n",
        "    real_probs      = torch.sigmoid(real_judgements)\n",
        "    gen_prob        = torch.std_mean(gen_probs, unbiased=True)\n",
        "    real_prob       = torch.std_mean(real_probs, unbiased=True)\n",
        "    \n",
        "    # Discriminator Results\n",
        "    print(f\"Discriminator p(x_real = real) = \" +\n",
        "          f\"{real_prob[1]*100:.0f}±{real_prob[0]*100:.0f}%\")\n",
        "    print(f\"Discriminator p(x_gen = real)  = \" +\n",
        "          f\"{gen_prob[1]*100:.0f}±{gen_prob[0]*100:.0f}%\")\n",
        "    \n",
        "    # Generator examples\n",
        "    images  = data_generated.cpu().detach().numpy() \\\n",
        "              .reshape(-1, data.height, data.width)\n",
        "    np.random.shuffle(images)  # shuffles ordering of images \n",
        "    \n",
        "    plt.title(\"Generated examples\")\n",
        "    for i in range(num_images) :\n",
        "        plt.figure(figsize = (12, 3))\n",
        "        plt.imshow(images[i])\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WstRQBd2SfnA"
      },
      "source": [
        "#### GANTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fg1SZJl7SfnA"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import Path\n",
        "class GANTraining :\n",
        "    \"\"\"\n",
        "        general GAN training class\n",
        "        How To Use:\n",
        "        * `MyTrain = GANTraining(<Generator>, <Discriminator>, <torch_dataset>)`\n",
        "        * `MyTrain.setup(<int_rounds>, batchsize = 1, discriminator_rounds = 1,     \n",
        "                        loss_function = [\"WGAN\", \"GAN\"])`\n",
        "        * `MyTrain.train()`\n",
        "      \n",
        "        After That:\n",
        "        * `MyTrain.gen` contains trained Generator\n",
        "        * `MyTrain.dis` contains trained Discriminator\n",
        "        * `MyTrain.log` contains metrics from each round:\n",
        "            - .losses       : np.array, shape = (5, rounds)\n",
        "            - .probs        : np.array, shape = (2, rounds)\n",
        "            - .gen_goodness : np.array, shape = (rounds,)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, Gen, Dis, dataset) :\n",
        "        # Input checks\n",
        "        #assert  issubclass(Gen, Generator)\n",
        "        #assert  issubclass(Dis, Discriminator)\n",
        "        assert  type(dataset) == torch.utils.data.dataset.TensorDataset\n",
        "        #assert  Gen().O == Dis().I\n",
        "        #assert  Dis().O == 1\n",
        "        #assert  dataset.tensors[0].shape[-1] == Gen().O   # real and gen. data should have the same size\n",
        "\n",
        "        self.device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "\n",
        "        # GAN classes and dataset\n",
        "        self.n_labels = 13     # number of labels in dataset, automate maybe\n",
        "        self.GenClass = Gen\n",
        "        self.DisClass = Dis\n",
        "        self.dataset  = dataset\n",
        "        #self.dataset.tensors[0].to(self.device)\n",
        "        \n",
        "\n",
        "    def setup (self, rounds, batch_size = 1, discriminator_rounds = 1, \n",
        "               loss_function = \"CAN\") :\n",
        "        assert  type(rounds) == int\n",
        "        assert  rounds >= 1\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 1\n",
        "        assert  type(discriminator_rounds) == int\n",
        "        assert  discriminator_rounds >= 1\n",
        "        assert  loss_function in [\"GAN\", \"WGAN\", \"CAN\"]\n",
        "\n",
        "        # Training parameters\n",
        "        self.rounds     = rounds\n",
        "        self.batch_size = batch_size\n",
        "        self.dis_rounds = discriminator_rounds\n",
        "        self.loss       = loss_function\n",
        "\n",
        "        # Dataloader\n",
        "        self.data_loader = torch.utils.data.DataLoader(self.dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                drop_last = True,\n",
        "                                shuffle = True)\n",
        "        self.dataset_size = self.dataset.tensors[0].shape[0]  # number of instances in dataset\n",
        "        self.batch_count = self.dataset_size // self.batch_size\n",
        "        self._batch_idx  = self.batch_count \n",
        "        \n",
        "        # Logs\n",
        "        self.log = Log()\n",
        "        self.log.losses       = np.zeros((5, self.rounds)) \n",
        "        self.log.music_probs  = np.zeros((2, self.rounds))\n",
        "        self.log.genre_probs = np.zeros((1 + self.n_labels, self.rounds))\n",
        "        self.log.gen_goodness = np.zeros((self.rounds,))\n",
        "        self.log._dis_losses  = torch.zeros((4, self.dis_rounds)).cpu()\n",
        "        self.log._music_probs = torch.zeros((2, self.dis_rounds)).cpu()\n",
        "        self.log._genre_probs = torch.zeros((1 + self.n_labels, self.rounds)).cpu()\n",
        "\n",
        "    def train (self) :\n",
        "        assert  hasattr(self, \"data_loader\")  # If test fails, you haven't run set_params()\n",
        "\n",
        "        print(f\"Training\")\n",
        "        self._initialize_GAN()\n",
        "        arranged_tensor = torch.arange(self.batch_size) # used each round\n",
        "\n",
        "        for round in notebook.tqdm(range(self.rounds)) :\n",
        "            for dis_round in range(self.dis_rounds) :\n",
        "                print(f\"Dis. round {dis_round + 1}           \", end=\"\\r\")  # print one dot for every dis_round\n",
        "                \n",
        "                # Forward propagation\n",
        "                batch_real, labels_real = self._get_batch()\n",
        "                # print(\"dis batch\", batch_real.device)\n",
        "                batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "                print(\"batch_gen complete     \", end = '\\r')\n",
        "                music_dis_real, genre_dis_real = self.dis.forward(batch_real)\n",
        "                print(\"dis_real complete      \", end = '\\r')\n",
        "                music_dis_gen, genre_dis_gen = self.dis.forward(batch_gen)\n",
        "                print(\"dis_gen complete       \", end = '\\r')\n",
        "\n",
        "                self.music_prob_real = torch.sigmoid(music_dis_real)\n",
        "                genre_probs_real = torch.nn.functional.softmax(genre_dis_real, dim = 1)\n",
        "                self.genre_prob_real = genre_probs_real[arranged_tensor, labels_real] # get prob of real genre\n",
        "                self.music_prob_gen  = torch.sigmoid(music_dis_gen)\n",
        "                self.genre_probs_gen  = torch.nn.functional.softmax(genre_dis_gen, dim = 1)\n",
        "                \n",
        "                # Calculating the Discriminator loss function\n",
        "                if self.loss == \"GAN\" :\n",
        "                    self.loss_real = - torch.mean(torch.log(self.music_prob_real))\n",
        "                    self.loss_gen  = - torch.mean(torch.log(1 - self.music_prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "                \n",
        "                elif self.loss == \"WGAN\" :\n",
        "                    var_gen   = torch.var(music_dis_gen)\n",
        "                    var_real  = torch.var(music_dis_real)\n",
        "                    self.loss_reg  = torch.where(var_gen > 1, \n",
        "                                                 (var_gen - 1)**2, 0) \\\n",
        "                                     + torch.where(var_real > 1, \n",
        "                                                   (var_real - 1)**2, 0)\n",
        "                    self.loss_real = - torch.mean(music_dis_real)\n",
        "                    self.loss_gen  = torch.mean(music_dis_gen)\n",
        "                \n",
        "                elif self.loss == \"CAN\" :\n",
        "                    self.loss_real_music = - torch.mean(torch.log(self.music_prob_real))\n",
        "                    self.loss_real_genre = - torch.mean(torch.log(self.genre_prob_real))\n",
        "                    self.loss_real = self.loss_real_music + self.loss_real_genre\n",
        "                    self.loss_gen = - torch.mean(torch.log(1 - self.music_prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "\n",
        "                self.loss_dis = self.loss_real + self.loss_gen + self.loss_reg\n",
        "                self._log_all(round, k = dis_round)\n",
        "                print(\"loss_dis complete      \", end = '\\r')\n",
        "                \n",
        "                # Discriminator update\n",
        "                self.optimizer_dis.zero_grad()\n",
        "                self.loss_dis.backward()\n",
        "                self.optimizer_dis.step()\n",
        "                print(\"dis.backward() complete\", end = '\\r')\n",
        "\n",
        "\n",
        "            # Calculating the Generator loss function\n",
        "            batch_new = self.gen.forward(batch_size = self.batch_size)\n",
        "            print(\"batch_gen complete     \", end = '\\r')\n",
        "            music_dis_new, genre_dis_new = self.dis.forward(batch_new)\n",
        "            # print(\"dis new output:\", music_dis_new.size(), genre_dis_new.size())\n",
        "            print(\"dis_new complete       \", end = '\\r')\n",
        "                \n",
        "            if self.loss == \"GAN\" :\n",
        "                music_prob_new = torch.sigmoid(music_dis_new)\n",
        "                self.loss_gen = -torch.mean(torch.log(music_prob_new)) \n",
        "            elif self.loss == \"WGAN\" :\n",
        "                self.loss_gen = -torch.mean(music_dis_new)\n",
        "            elif self.loss == \"CAN\" :\n",
        "                music_prob_new = torch.sigmoid(music_dis_new)\n",
        "                self.loss_gen_music = -torch.mean(music_prob_new)\n",
        "                genre_probs_new = torch.nn.functional.softmax(genre_dis_new, dim = 1)\n",
        "                # print(genre_probs_new.size())\n",
        "                self.loss_gen_genre = - torch.mean( \\\n",
        "                    unif_cross_entropy(genre_probs_new, 1 / self.n_labels) + \\\n",
        "                    unif_cross_entropy(1 - genre_probs_new, 1 - 1 / self.n_labels))\n",
        "                self.loss_gen = self.loss_gen_music + self.loss_gen_genre\n",
        "\n",
        "            self._log_all(round)\n",
        "            print(\"loss_gen complete      \", end = '\\r')\n",
        "                \n",
        "            \n",
        "            # Generator update\n",
        "            self.optimizer_gen.zero_grad()\n",
        "            self.loss_gen.backward()\n",
        "            self.optimizer_gen.step()\n",
        "            print(\"gen.backward() complete\", end = '\\r')\n",
        "\n",
        "        # Put GAN in eval mode\n",
        "        self.gen.eval()\n",
        "        self.dis.eval()\n",
        "        print(\"Training complete. GAN now in eval() mode.\")\n",
        "\n",
        "\n",
        "    def _initialize_GAN (self) :\n",
        "        \"\"\"\n",
        "            Before each training, the Generator and Discriminator will be freshly initialized with new random weights.\n",
        "        \"\"\"\n",
        "        self.gen = self.GenClass().to(self.device)\n",
        "        self.dis = self.DisClass().to(self.device)\n",
        "        self.optimizer_gen = torch.optim.Adam(self.gen.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        self.optimizer_dis = torch.optim.Adam(self.dis.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        # Note: ADAM parameters from GAN tutorial [1].\n",
        "        \n",
        "\n",
        "    def _get_batch (self) :\n",
        "        \"\"\"\n",
        "            samples one batch of data from self.data_loader without replacement.\n",
        "            When the self.data_set is depleted of fresh batches, \n",
        "            self.data_loader will shuffle a list of new batches.\n",
        "        \"\"\"\n",
        "        if self._batch_idx >= self.batch_count :\n",
        "            self._data_iter = iter(self.data_loader)\n",
        "            self._batch_idx = 0\n",
        "        batch_data, batch_labels = self._data_iter.next()\n",
        "        self._batch_idx += 1\n",
        "\n",
        "        return batch_data.to(self.device), batch_labels.to(self.device)\n",
        "\n",
        "\n",
        "\n",
        "    def _log_all (self, round, k = -1) :\n",
        "        if k >= 0 : # before each Discriminator update\n",
        "            self.log._dis_losses[0, k] = self.loss_dis.cpu().detach()\n",
        "            self.log._dis_losses[1, k] = self.loss_real.cpu().detach()\n",
        "            self.log._dis_losses[2, k] = self.loss_gen.cpu().detach()\n",
        "            self.log._dis_losses[3, k] = self.loss_reg.cpu().detach()\n",
        "            self.log._music_probs[0, k] = self.music_prob_real.mean().cpu().detach()\n",
        "            self.log._music_probs[1, k] = self.music_prob_gen.mean().cpu().detach()\n",
        "            self.log._genre_probs[0, k]  = self.genre_prob_real.mean().cpu().detach() # prob of right label of real batch\n",
        "            self.log._genre_probs[1:, k] = self.genre_probs_gen.mean().cpu().detach() # prob of genres of generated batch\n",
        "        \n",
        "        if k == -1 : # before each Generator update\n",
        "            # Losses\n",
        "            dis_losses = self.log._dis_losses.detach().cpu().numpy()\n",
        "            self.log.losses[0:4, round] = dis_losses.mean(axis = 1)\n",
        "            self.log.losses[4, round]   = self.loss_gen.detach().cpu().numpy()\n",
        "            \n",
        "            # Discriminator Probabilities\n",
        "            music_probs                 = self.log._music_probs.cpu().detach().numpy()\n",
        "            genre_probs                 = self.log._genre_probs.cpu().detach().numpy()\n",
        "            self.log.music_probs[:, round] = music_probs.mean(axis = 1)\n",
        "            self.log.genre_probs[:, round] = genre_probs.mean(axis = 1)\n",
        "\n",
        "            # Generator Goodness\n",
        "            batch_real, _ = self._get_batch()\n",
        "            batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "            goodness   = generator_goodness(batch_gen, batch_real)\n",
        "            self.log.gen_goodness[round] = goodness\n",
        "\n",
        "\n",
        "    def plot (self) :\n",
        "        rounds = np.arange(self.rounds) + 1\n",
        "        plt.suptitle(\"Training results\")\n",
        "        plt.title(\"Loss Terms\")\n",
        "        plt.plot(rounds, self.log.losses.T)\n",
        "        plt.xlabel(\"round\")\n",
        "        plt.ylim(-5, 5)\n",
        "        plt.legend([\"Discriminator Loss\", \"Dis. Real Term\", \"Dis. Gen Term\", \"Dis. Reg Term\", \"Generator Loss\"])\n",
        "        plt.show()\n",
        "\n",
        "        plt.title(\"Batch-averaged Discriminator Probabilities during Training\")\n",
        "        plt.plot(rounds, self.log.music_probs.T)\n",
        "        plt.plot(rounds, self.log.genre_probs[0,:])\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylim(0,1)\n",
        "        plt.legend([\"real data\", \"generated data\", \"true label\"])\n",
        "        plt.show()\n",
        "\n",
        "        plt.title(\"Batch-averaged Generator Probabilities during Training\")\n",
        "        plt.plot(rounds, self.log.genre_probs[1:,:].T)\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylim(0,1)\n",
        "        plt.legend(lpd5.genre_list)\n",
        "        plt.show()\n",
        "\n",
        "        plt.title(\"Generator Goodness during Training\")\n",
        "        plt.plot(rounds, self.log.gen_goodness)\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylim(0,1)\n",
        "        plt.legend([\"Averaged real-generated difference\"])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def save (self, training_filepath, name) :\n",
        "        file_name = training_filepath + name\n",
        "        torch.save(self.gen.state_dict(), file_name + \"_gen.obj\")\n",
        "        torch.save(self.dis.state_dict(), file_name + \"_dis.obj\")\n",
        "\n",
        "        print(f\"Saved training under '{file_name}'\")\n",
        "\n",
        "    def load (self, training_filepath, name) :\n",
        "        file_name = training_filepath + name \n",
        "        self.gen.load_state_dict(torch.load(file_name + \"_gen.obj\"))\n",
        "        self.dis.load_state_dict(torch.load(file_name + \"_dis.obj\"))\n",
        "        \n",
        "        print(f\"Loaded training from '{file_name}'\")\n",
        "\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7J679rwSfnC"
      },
      "source": [
        "## Network training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5nBoKe5SfnC"
      },
      "source": [
        "**Template for own Generator or Discriminator class**\n",
        "```python\n",
        "class SETCLASSNAME (Generator OR Discriminator) :\n",
        "    def __init__ (self) :\n",
        "        super().__init__()\n",
        "        self.name = self.__class__.__name__\n",
        "\n",
        "        self.I     = #SET SEED LENGTH\n",
        "        self.O     = #SET OUTPUT LENGTH\n",
        "        self.model = torch.nn.Sequential(\n",
        "            # ENTER TORCH.NN MODULES\n",
        "        )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb1wFpAtSfnD"
      },
      "source": [
        "### musiCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZTquiObSfnD"
      },
      "source": [
        "#### LPD5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lqPo9MWSfnE"
      },
      "outputs": [],
      "source": [
        "data_name = \"lpd5_full_4bars\"\n",
        "lpd5 = Pianoroll(\"/content/drive/MyDrive/MusiCAN_data_and_models/\" + data_name + \"/prepared_arrays.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IR7FUnhSfnE"
      },
      "outputs": [],
      "source": [
        "lpd5.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDpG8WkXSfnF"
      },
      "outputs": [],
      "source": [
        "lpd5.bars = 4\n",
        "lpd5.blips_per_bar = lpd5.width // lpd5.bars\n",
        "lpd5.pitches = lpd5.height\n",
        "lpd5.octaves = lpd5.pitches // 12\n",
        "\n",
        "print(\"lpd5.blips_per_bar\", lpd5.blips_per_bar)\n",
        "print(\"lpd5.pitches\", lpd5.pitches)\n",
        "print(\"lpd5.octaves\", lpd5.octaves)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymVvmrUiSfnG"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGqY1QFSSfnG"
      },
      "outputs": [],
      "source": [
        "class GeneratorBlock(torch.nn.Module):\n",
        "    \"\"\" 2d transconv layer, batch normalization & ReLU \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gen_block = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose2d(in_dim, out_dim, kernel, stride),\n",
        "            torch.nn.BatchNorm2d(out_dim),\n",
        "            torch.nn.ReLU()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen_block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdFfD0A8SfnH"
      },
      "outputs": [],
      "source": [
        "class MusiGen (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-track museGAN generator, consisting of two sub-networks (so-called \n",
        "    temporal and bar generator)\n",
        "\n",
        "    input : seed vector, a normally distributed random vector, \n",
        "            length: (B + 1) * 64 = 5 * 64 here\n",
        "    output: pianaroll, binary tensor, shape: (B x T x P) = (4 x 48 x 84) here\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, log = False, **kwargs) : \n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 64\n",
        "        \n",
        "        self.temporal_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # heuristically added linear layer\n",
        "            torch.nn.Linear(1, 31),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 1\n",
        "            torch.nn.ConvTranspose1d(64, 1024, 2, 2),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # transconv layer 2\n",
        "            torch.nn.ConvTranspose1d(1024, 1, 3, 1),\n",
        "            torch.nn.BatchNorm1d(1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.bar_generator = torch.nn.Sequential(\n",
        "            \n",
        "            # transconv layers\n",
        "            GeneratorBlock( 128, 1024, (2, 1), (2, 1)),\n",
        "            GeneratorBlock(1024,  512, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 512,  256, (2, 1), (2, 1)),\n",
        "            GeneratorBlock( 256,  256, (2, 1), (2, 1)),\n",
        "            # GeneratorBlock( 256,  256, (2, 1), (2, 1)),   # added\n",
        "            GeneratorBlock( 256,  128, (3, 1), (3, 1)),\n",
        "            GeneratorBlock( 128,   64, (1, self.octaves), (1, self.octaves)),\n",
        "\n",
        "            # last layer with tanh & binarization activation fct.s\n",
        "            torch.nn.ConvTranspose2d(64, 1, (1, 12), (1, 12)),\n",
        "            torch.nn.BatchNorm2d(1),\n",
        "            torch.nn.Tanh(),\n",
        "            StraightThroughEstimator() # binarization\n",
        "        )\n",
        "\n",
        "        if log :\n",
        "            print(f\"Generator: parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward_custom (self, seed) :\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  len(seed.shape) == 2\n",
        "        assert  seed.shape[0] >= 1\n",
        "        assert  seed.shape[1] == (1 + self.bars) * self.seedlength\n",
        "\n",
        "        batchsize = seed.shape[0]\n",
        "        return self.forward(batchsize, seed)\n",
        "\n",
        "\n",
        "    def forward (self, batch_size, seed = None) :\n",
        "        \n",
        "        if seed == None :\n",
        "            assert type(batch_size) == int\n",
        "            assert batch_size >= 1\n",
        "            device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "            seed = torch.normal(0., 1, (batch_size, (1 + self.bars) * self.seedlength)).to(device)\n",
        "            \n",
        "        seeds = torch.chunk(seed, chunks = 5, dim = 1)\n",
        "        \n",
        "        # create time-independent first half of seed for bar generator\n",
        "        bar_seed_1 = seeds[0]\n",
        "        bar_seed_1 = bar_seed_1.view((-1, self.seedlength, 1, 1)) # reshape for transconv layers\n",
        "\n",
        "        # generate pianorolls bar by bar\n",
        "        generated_bars = []\n",
        "        for temporal_seed in seeds[1:]:\n",
        "            \n",
        "            ## generate time-dependent second half of seed for bar generator\n",
        "\n",
        "            temporal_seed = temporal_seed.view(-1, self.seedlength, 1) # reshape for transconv layers\n",
        "            #print(f\"temporal seed: {temporal_seed.size()}\")\n",
        "            bar_seed_2 = self.temporal_generator(temporal_seed) # (batch size x 1 x 64)\n",
        "            #print(f\"bar seed 2: {bar_seed_2.size()}\")\n",
        "\n",
        "            ## reshape & concatenate both halfs of seed for bar generator \n",
        "            \n",
        "            bar_seed_2 = bar_seed_2.view(-1, self.seedlength, 1, 1)\n",
        "            bar_seed   = torch.cat((bar_seed_1, bar_seed_2), dim = 1) # (batch size x 128 x 1 x 1)\n",
        "            #print(f\"bar seed: {bar_seed d.size()}\")\n",
        "\n",
        "            ## generate one bar \n",
        "            \n",
        "            generated_bar = self.bar_generator(bar_seed) # (batch size x 1 x 24 x 84)\n",
        "            #print(f\"generated_bar: {generated_bar.size()}\")\n",
        "            generated_bars.append(generated_bar) \n",
        "\n",
        "        pianoroll = torch.cat(generated_bars, dim = 1) # (batch size x 4 x 24 x 84) \n",
        "        #print(f\"gen output: {pianoroll.size()}\")\n",
        "\n",
        "        return pianoroll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzd2tZHWSfnI"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWH4NwUsSfnJ"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorBlock(torch.nn.Module):\n",
        "    \"\"\"3d conv layer & Leaky ReLU\"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "        self.dis_block = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(in_dim, out_dim, kernel, stride),\n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2)   # MuseGAN Hyperparameter\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dis_block(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MusiDis (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "    1-Track musiCAN discriminator, with 2 heads \n",
        "    \n",
        "    input : (B x T x P) binary pianoroll\n",
        "\n",
        "    output: 1. single number, prob. that the input pianoroll is a \n",
        "            real and not generated\n",
        "            2. vector of length = number of genres, prob. that the input \n",
        "            pianoroll is of a certain genre type\n",
        "\n",
        "    n_labels : number of labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, n_labels = 13, log = False, **kwargs) :\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Data parameters\n",
        "        self.octaves    = lpd5.octaves\n",
        "        self.bars       = lpd5.bars    # bars per pianoroll\n",
        "        self.T          = lpd5.blips_per_bar  # timesteps per bar\n",
        "        self.P          = lpd5.pitches   # pitches\n",
        "        self.seedlength = 64\n",
        "        self.n_labels   = n_labels\n",
        "      \n",
        "        # common body: conv layers\n",
        "        self.discriminator_conv = torch.nn.Sequential(\n",
        "            DiscriminatorBlock(  1, 128, (2, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (3, 1,  1), (1, 1,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 1, 12), (1, 1, 12)), \n",
        "            DiscriminatorBlock(128, 128, (1, 1,  self.octaves), (1, 1,  self.octaves)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 128, (1, 2,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(128, 256, (1, 4,  1), (1, 2,  1)),\n",
        "            DiscriminatorBlock(256, 512, (1, 3,  1), (1, 2,  1))\n",
        "            )\n",
        "        \n",
        "        # heads: fully-connected layers\n",
        "        self.discriminator_music_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, 1))\n",
        "        \n",
        "        self.discriminator_genre_head = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512*2, 1024),  \n",
        "            torch.nn.LeakyReLU(negative_slope = 0.2),\n",
        "            torch.nn.Linear(1024, self.n_labels))\n",
        "\n",
        "        if log :\n",
        "            print(f\"Discriminator parameters: {self.count_params()}\")\n",
        "            print(\"\")\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward (self, pianoroll):\n",
        "\n",
        "        # reshape input for transconvs\n",
        "        pianoroll   = pianoroll.view(-1, 1, self.bars, self.T, self.P) \n",
        "        # print(\"dis input prep.\", pianoroll.shape)\n",
        "\n",
        "        # put through common body and flatten instances\n",
        "        common_conv_output = self.discriminator_conv(pianoroll)\n",
        "        common_fc_input = common_conv_output.view(-1, 512*2)  \n",
        "        # print(\"dis conv out\", common_conv_output.size())\n",
        "\n",
        "        # put through each head to judge music (real / fake) and genre labels\n",
        "        music_judgement = self.discriminator_music_head(common_fc_input).flatten().float()\n",
        "        genre_judgement = self.discriminator_genre_head(common_fc_input).view(-1, self.n_labels).float()\n",
        "        # print(\"dis out \", music_judgement.size(), genre_judgement.size())\n",
        "\n",
        "        return music_judgement, genre_judgement"
      ],
      "metadata": {
        "id": "EcxEMtK1ncLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POOjINWYSfnL"
      },
      "source": [
        "#### Training & Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gasGW3KpSfnM"
      },
      "outputs": [],
      "source": [
        "lpd5Train = GANTraining(MusiGen, MusiDis, lpd5.dataset)\n",
        "lpd5Train.setup(20000, batch_size = 25, discriminator_rounds = 5, loss_function = \"CAN\")\n",
        "lpd5Train.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# storage\n",
        "model_name = \"MusiCAN_test1\"\n",
        "training_filepath = \"/content/drive/MyDrive/MusiCAN_data_and_models/\" + data_name + \"/trained_models/\"\n",
        "lpd5Train.save(training_filepath, model_name)\n",
        "lpd5Train.load(training_filepath, model_name)"
      ],
      "metadata": {
        "id": "h2AAlqZFn_JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lpd5Train.plot()"
      ],
      "metadata": {
        "id": "nTHOnDOsxi1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-ZTquiObSfnD",
        "ymVvmrUiSfnG",
        "Xzd2tZHWSfnI",
        "uO0NtwA6SfnO",
        "A_0VgagxSfnS"
      ],
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('aml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9db57278ae8397bc5fe3bec6b9ba53c33a2aa76e79d386f678fc754e34f9547"
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}