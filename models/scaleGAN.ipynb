{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakioh/MusiCAN/blob/main/models/first_music_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scaleGAN\n",
        "**Description:** scalable GAN architecture with an equally scalable mock dataset.\\\n",
        "**Purpose:** find an efficient and stable architecture to generate images as large as pianorolls with.\\\n",
        "**Results:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Zy36G-CGamF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class and function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CentralDotImage :\n",
        "    \"\"\"\n",
        "        creates mock data set out of a simple image copied multiple times\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "        __init__(height, width, dataset_size = 100) : \n",
        "            creates all attributes\n",
        "        show() : \n",
        "            plt.plots image\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        height : int\n",
        "            of image, in pixels\n",
        "        width : int\n",
        "            of image, in pixels\n",
        "        size : int\n",
        "            number of pixels in image\n",
        "        dataset_size : int\n",
        "            number of images\n",
        "        \n",
        "        image : torch.Tensor\n",
        "            out of 1s and 0s,\n",
        "            size = (width, height)\n",
        "        vector : torch.Tensor\n",
        "            flattened image,\n",
        "            size = (size)\n",
        "        data : torch.Tensor\n",
        "            images copied dataset_size times\n",
        "            size = (dataset_size, size)\n",
        "        dataset : torch.TensorDataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, height, width, dataset_size = 100) :\n",
        "        # Input checks\n",
        "        assert  type(height) == int \n",
        "        assert  height >= 1 \n",
        "        assert  type(width) == int\n",
        "        assert  width >= 1\n",
        "        assert  type(dataset_size) == int\n",
        "        assert  dataset_size >= 1\n",
        "\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.shape  = (height, width)\n",
        "        self.size   = height * width\n",
        "        self.dataset_size = dataset_size\n",
        "\n",
        "        # Image creation\n",
        "        self.image = torch.zeros(height, width)\n",
        "        for i in range(height) :\n",
        "            for j in range(width) :\n",
        "                self.image[i, j] = \\\n",
        "                    i + 1 <= math.ceil(3/4 * height) and \\\n",
        "                    i + 1 > math.floor(1/4 * height) and \\\n",
        "                    j + 1 <= math.ceil(3/4 * width) and \\\n",
        "                    j + 1 > math.floor(1/4 * width)\n",
        "\n",
        "        # Dataset creation\n",
        "        self.vector  = self.image.flatten()\n",
        "        self.data    = self.vector[None, :].expand(dataset_size, self.size)\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data)\n",
        "\n",
        "    def show (self) :\n",
        "        plt.imshow(self.image)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    These two classes serves as torch layers to binarize the output of the Generator while keeping the layer still \"backpropagatable\" (via a hardtanh).\n",
        "    This is not our own code. For source, see:\n",
        "    https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#:~:text=A%20straight%2Dthrough%20estimator%20is,function%20was%20an%20identity%20function.\n",
        "\"\"\"\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return torch.nn.functional.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "        General neural network class for specialized networks.\n",
        "        Create those by:\n",
        "        ```\n",
        "        myNet = Network(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myNet.create_model(layer_list)\n",
        "        myNet.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, input_length, output_length, name) : \n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_length  = self.I = input_length\n",
        "        self.output_length = self.O = output_length\n",
        "        self.name          = name\n",
        "            \n",
        "\n",
        "    def create_model (self, layer_list) :\n",
        "        self.model = torch.nn.Sequential(*layer_list)\n",
        "\n",
        "\n",
        "    def print_stats (self) :\n",
        "        print(f\"{self.name}:\")\n",
        "        print(f\"    input length:  {self.input_length}\")\n",
        "        print(f\"    output length: {self.output_length}\")\n",
        "        if hasattr(self, 'model') :\n",
        "            print(f\"    layers:        {len(self.model)}\")\n",
        "            print(f\"    parameters:    {self.count_params()}\")\n",
        "        else :\n",
        "            print(f\"    Create the network architecture with .create_model(<layer_list>)\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, input, numpy_out = False) :\n",
        "        \"\"\"run network\"\"\"\n",
        "        output = self.model(input)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def _numpify (self, tensor) :\n",
        "        return tensor.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Generator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myGen = Generator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myGen.create_model(layer_list)\n",
        "        myGen.print_stats()\n",
        "        ```\n",
        "\n",
        "        There are two forward() variants:\n",
        "        * `forward(batchsize = 0, numpy_out = False)` with auto-generated normally distributed seeds.\n",
        "        * `forward_custom(seed, numpy_out = False)` with custom seeds as input.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, batch_size = 0, numpy_out = False) :\n",
        "        \"\"\"run network with a batch of normally distributed seeds\"\"\"\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 0\n",
        "\n",
        "        # Seed generation\n",
        "        if batch_size == 0 :\n",
        "            seed_size = (self.input_length,)\n",
        "        else :\n",
        "            seed_size = (batch_size, self.input_length)\n",
        "        seed = torch.normal(0, 1, seed_size)\n",
        "        \n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out)\n",
        "\n",
        "            \n",
        "    def forward_custom (self, seed, numpy_out = False) :\n",
        "        \"\"\"run network with custom seed\"\"\"\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  seed.shape[-1] == self.I\n",
        "\n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out = numpy_out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Discriminator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myDis = Discriminator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myDis.create_model(layer_list)\n",
        "        myDis.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, input, prob_out = False, numpy_out = False) :\n",
        "        \"\"\"\n",
        "            run network, optionally return probability (default logit) or numpy array (default torch)\n",
        "        \"\"\"\n",
        "        assert  type(input) in [torch.Tensor, np.ndarray]\n",
        "        assert  input.shape[-1] == self.I\n",
        "\n",
        "        if type(input) == np.ndarray :\n",
        "            input = torch.tensor(input)\n",
        "\n",
        "        # Running the network\n",
        "        \n",
        "        output = super().forward(input)\n",
        "        if prob_out :\n",
        "            output = torch.sigmoid(output)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generator_goodness (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "    compare two batches of data by calculating the absolute mean difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # averaged over batches \n",
        "    generated_mean = torch.mean(generated_batch)\n",
        "    real_mean      = torch.mean(real_batch)\n",
        "\n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    goodness_criteria = torch.mean(torch.abs(real_mean - generated_mean))\n",
        "\n",
        "    return goodness_criteria.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANTraining :\n",
        "    def __init__ (self, generator, discriminator, dataset) :\n",
        "        assert  type(generator) in [Network, Generator]\n",
        "        assert  hasattr(generator, \"model\")\n",
        "        assert  type(discriminator) in [Network, Discriminator]\n",
        "        assert  hasattr(discriminator, \"model\")\n",
        "        assert  type(dataset) == torch.utils.data.dataset.TensorDataset\n",
        "        \n",
        "        self.device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "        self.training_filepath = \"../execution/trained_models/\"\n",
        "\n",
        "        # Model, data and optimizer\n",
        "        self.gen     = generator.to(self.device)\n",
        "        self.dis     = discriminator.to(self.device)\n",
        "        self.dataset = dataset.to(self.device)\n",
        "        self.optimizer_gen = torch.optim.Adam(self.gen.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        self.optimizer_dis = torch.optim.Adam(self.dis.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        # Note: ADAM parameters from GAN tutorial [1].\n",
        "        \n",
        "\n",
        "    def set_params (self, rounds, batch_size = 1, discriminator_rounds = 1, \n",
        "                    loss_function = \"WGAN\") :\n",
        "        assert  type(rounds) == int\n",
        "        assert  rounds >= 1\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 1\n",
        "        assert  type(discriminator_rounds) == int\n",
        "        assert  discriminator_rounds >= 1\n",
        "        assert  loss_function in [\"GAN\", \"WGAN\"]\n",
        "\n",
        "        # Training parameters\n",
        "        self.rounds     = rounds\n",
        "        self.batch_size = batch_size\n",
        "        self.dis_rounds = discriminator_rounds\n",
        "        self.loss       = loss_function\n",
        "\n",
        "        # Dataloader\n",
        "        self.data_loader = torch.utils.data.DataLoader(self.dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                drop_last = True,\n",
        "                                shuffle = True)\n",
        "        \n",
        "        # Logs\n",
        "        self.log.losses       = np.zeros((5, self.rounds))\n",
        "        self.log.probs        = np.zeros((2, self.rounds))\n",
        "        self.log.gen_goodness = np.zeros((self.rounds,))\n",
        "        self.log._dis_losses  = torch.zeros((4, self.dis_rounds))\n",
        "        self.log._probs       = torch.zeros((2, self.dis_rounds))\n",
        "        \n",
        "\n",
        "\n",
        "    def train (self) :\n",
        "        assert  hasattr(self, \"data_loader\")  # If test fails, you haven't run set_params()\n",
        "\n",
        "        for round in range(self.rounds) :\n",
        "            for dis_round in range(self.dis_rounds) :\n",
        "                # Forward propagation\n",
        "                batch_real = iter(self.data_loader)\n",
        "                batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "                dis_real = self.dis.forward(batch_real)\n",
        "                dis_gen  = self.dis.forward(batch_gen)\n",
        "                self.prob_real = torch.sigmoid(dis_real)\n",
        "                self.prob_gen  = torch.sigmoid(dis_gen)\n",
        "\n",
        "                # Calculating the Discriminator loss function\n",
        "                if self.loss == \"GAN\" :\n",
        "                    self.loss_real = - torch.mean(torch.log(self.prob_real))\n",
        "                    self.loss_gen  = torch.mean(torch.log(\n",
        "                                     1 - self.prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "                elif self.loss == \"WGAN\" :\n",
        "                    var_gen   = torch.var(dis_gen)\n",
        "                    var_real  = torch.var(dis_real)\n",
        "                    self.loss_reg  = torch.where(var_gen > 1, \n",
        "                                                 (var_gen - 1)**2, 0) \\\n",
        "                                     + torch.where(var_real > 1, \n",
        "                                                   (var_real - 1)**2, 0)\n",
        "                    self.loss_real = - torch.mean(dis_real)\n",
        "                    self.loss_gen  = torch.mean(dis_gen)\n",
        "\n",
        "                self.loss_dis = self.loss_real + self.loss_gen + self.loss_reg\n",
        "                self._log_all(round, k = dis_round)\n",
        "                \n",
        "                # Discriminator update\n",
        "                self.optimizer_dis.zero_grad()\n",
        "                loss_dis.backward(retain_graph = True)\n",
        "                self.optimizer_dis.step()\n",
        "\n",
        "            # Calculating the Generator loss function\n",
        "            batch_gen = self.gen.forward(batch_size = self.batch_size)\n",
        "            dis_new   = self.dis.forward(batch_gen)\n",
        "            \n",
        "            if self.loss_function == \"GAN\" :\n",
        "                prob_new = torch.sigmoid(dis_new)\n",
        "                self.loss_gen = -torch.mean(torch.log(prob_new)) \n",
        "            elif self.loss_function == \"WGAN\" :\n",
        "                self.loss_gen = -torch.mean(dis_new)\n",
        "            self._log_all(round)\n",
        "            \n",
        "            # Generator update\n",
        "            self.optimizer_gen.zero_grad()\n",
        "            self.loss_gen.backward()\n",
        "            self.optimizer_gen.step()\n",
        "\n",
        "\n",
        "    def _log_all (round, k = -1) :\n",
        "        if k >= 0 : # before each Discriminator update\n",
        "            self.log._dis_losses[0, k] = self.loss_dis\n",
        "            self.log._dis_losses[1, k] = self.loss_real\n",
        "            self.log._dis_losses[2, k] = self.loss_gen\n",
        "            self.log._dis_losses[3, k] = self.loss_reg\n",
        "            self.log._probs[0, k] = self.prob_real.mean()\n",
        "            self.log._probs[1, k] = self.prob_gen\n",
        "        \n",
        "        if k == -1 : # before each Generator update\n",
        "            dis_losses = self.log._dis_losses.detach().numpy()\n",
        "            probs      = self.log._probs.detach().numpy()\n",
        "            self.log.losses[0:4, round] = dis_losses.mean(axis = 1)\n",
        "            self.log.losses[5, round]   = self.loss.gen.detach().numpy()\n",
        "            self.log.probs[:, round]    = probs.mean(axis = 1)\n",
        "\n",
        "            batch_real = iter(self.data_loader)\n",
        "            batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "            goodness   = generator_goodness(batch_gen, batch_real)\n",
        "            self.log.gen_goodness[round] = goodness\n",
        "\n",
        "\n",
        "\n",
        "    def save (self, name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"wb\")\n",
        "        pickle.dump(self, file)\n",
        "        print(f\"Saved training under '{file_name}'\")\n",
        "\n",
        "\n",
        "    def load (name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"rb\")\n",
        "        return pickle.load(file)\n",
        "\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "minimock = CentralDotImage(4, 4)\n",
        "minimock.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniGenerator:\n",
            "    input length:  4\n",
            "    output length: 16\n",
            "    layers:        4\n",
            "    parameters:    100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniGen = Generator(4, minimock.size, \"miniGenerator\")\n",
        "\n",
        "miniGen.create_model([\n",
        "    torch.nn.Linear(miniGen.I, miniGen.I),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(miniGen.I, miniGen.O),\n",
        "    StraightThroughEstimator()\n",
        "])\n",
        "\n",
        "miniGen.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniDiscriminator:\n",
            "    input length:  16\n",
            "    output length: 1\n",
            "    layers:        3\n",
            "    parameters:    73\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniDis = Discriminator(minimock.size, 1, \"miniDiscriminator\")\n",
        "\n",
        "miniDis.create_model([\n",
        "    torch.nn.Linear(miniDis.I,4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4, miniDis.O)\n",
        "])\n",
        "\n",
        "miniDis.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob. that image is real: 50%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "gen_flat = miniGen.forward(numpy_out = True)\n",
        "prob     = miniDis.forward(gen_flat, prob_out = True, numpy_out = True)[0]\n",
        "\n",
        "print(f\"Prob. that image is real: {prob*100:.0f}%\")\n",
        "gen_img = gen_flat.reshape(*minimock.shape)\n",
        "plt.imshow(gen_img);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "first-music-GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('aml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9db57278ae8397bc5fe3bec6b9ba53c33a2aa76e79d386f678fc754e34f9547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
