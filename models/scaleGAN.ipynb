{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakioh/MusiCAN/blob/main/models/first_music_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scaleGAN\n",
        "**Description:** scalable GAN architecture with an equally scalable mock dataset.\\\n",
        "**Purpose:** find an efficient and stable architecture to generate images as large as pianorolls with.\\\n",
        "**Results:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Zy36G-CGamF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class and function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CentralDotImage :\n",
        "    \"\"\"\n",
        "        creates mock data set out of a simple image copied multiple times\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "        __init__(height, width, dataset_size = 100) : \n",
        "            creates all attributes\n",
        "        show() : \n",
        "            plt.plots image\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        height : int\n",
        "            of image, in pixels\n",
        "        width : int\n",
        "            of image, in pixels\n",
        "        size : int\n",
        "            number of pixels in image\n",
        "        dataset_size : int\n",
        "            number of images\n",
        "        \n",
        "        image : torch.Tensor\n",
        "            out of 1s and 0s,\n",
        "            size = (width, height)\n",
        "        vector : torch.Tensor\n",
        "            flattened image,\n",
        "            size = (size)\n",
        "        data : torch.Tensor\n",
        "            images copied dataset_size times\n",
        "            size = (dataset_size, size)\n",
        "        dataset : torch.TensorDataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, height, width, dataset_size = 100) :\n",
        "        # Input checks\n",
        "        assert  type(height) == int \n",
        "        assert  height >= 1 \n",
        "        assert  type(width) == int\n",
        "        assert  width >= 1\n",
        "        assert  type(dataset_size) == int\n",
        "        assert  dataset_size >= 1\n",
        "\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.shape  = (height, width)\n",
        "        self.size   = height * width\n",
        "        self.dataset_size = dataset_size\n",
        "\n",
        "        # Image creation\n",
        "        self.image = torch.zeros(height, width)\n",
        "        for i in range(height) :\n",
        "            for j in range(width) :\n",
        "                self.image[i, j] = \\\n",
        "                    i + 1 <= math.ceil(3/4 * height) and \\\n",
        "                    i + 1 > math.floor(1/4 * height) and \\\n",
        "                    j + 1 <= math.ceil(3/4 * width) and \\\n",
        "                    j + 1 > math.floor(1/4 * width)\n",
        "\n",
        "        # Dataset creation\n",
        "        self.vector  = self.image.flatten()\n",
        "        self.data    = self.vector[None, :].expand(dataset_size, self.size)\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data)\n",
        "\n",
        "    def show (self) :\n",
        "        plt.imshow(self.image)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    These two classes serves as torch layers to binarize the output of the Generator while keeping the layer still \"backpropagatable\" (via a hardtanh).\n",
        "    This is not our own code. For source, see:\n",
        "    https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#:~:text=A%20straight%2Dthrough%20estimator%20is,function%20was%20an%20identity%20function.\n",
        "\"\"\"\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return torch.nn.functional.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "        General neural network class for specialized networks.\n",
        "        Create those by:\n",
        "        ```\n",
        "        myNet = Network(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myNet.create_model(layer_list)\n",
        "        myNet.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, input_length, output_length, name) : \n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_length  = self.I = input_length\n",
        "        self.output_length = self.O = output_length\n",
        "        self.name          = name\n",
        "            \n",
        "\n",
        "    def create_model (self, layer_list) :\n",
        "        self.model = torch.nn.Sequential(*layer_list)\n",
        "\n",
        "\n",
        "    def print_stats (self) :\n",
        "        print(f\"{self.name}:\")\n",
        "        print(f\"    input length:  {self.input_length}\")\n",
        "        print(f\"    output length: {self.output_length}\")\n",
        "        if hasattr(self, 'model') :\n",
        "            print(f\"    layers:        {len(self.model)}\")\n",
        "            print(f\"    parameters:    {self.count_params()}\")\n",
        "        else :\n",
        "            print(f\"    Create the network architecture with .create_model(<layer_list>)\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, input, numpy_out = False) :\n",
        "        \"\"\"run network\"\"\"\n",
        "        output = self.model(input)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def _numpify (self, tensor) :\n",
        "        return tensor.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Generator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myGen = Generator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myGen.create_model(layer_list)\n",
        "        myGen.print_stats()\n",
        "        ```\n",
        "\n",
        "        There are two forward() variants:\n",
        "        * `forward(batchsize = 0, numpy_out = False)` with auto-generated normally distributed seeds.\n",
        "        * `forward_custom(seed, numpy_out = False)` with custom seeds as input.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, batch_size = 0, numpy_out = False) :\n",
        "        \"\"\"run network with a batch of normally distributed seeds\"\"\"\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 0\n",
        "\n",
        "        # Seed generation\n",
        "        if batch_size == 0 :\n",
        "            seed_size = (self.input_length,)\n",
        "        else :\n",
        "            seed_size = (batch_size, self.input_length)\n",
        "        seed = torch.normal(0, 1, seed_size)\n",
        "        \n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out)\n",
        "\n",
        "            \n",
        "    def forward_custom (self, seed, numpy_out = False) :\n",
        "        \"\"\"run network with custom seed\"\"\"\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  seed.shape[-1] == self.I\n",
        "\n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out = numpy_out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator (Network) :\n",
        "    \"\"\"\n",
        "        GAN Discriminator class whose architecture is custom defined after initialization:\n",
        "        ```\n",
        "        myDis = Discriminator(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myDis.create_model(layer_list)\n",
        "        myDis.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "    def forward (self, input, prob_out = False, numpy_out = False) :\n",
        "        \"\"\"\n",
        "            run network, optionally return probability (default logit) or numpy array (default torch)\n",
        "        \"\"\"\n",
        "        assert  type(input) in [torch.Tensor, np.ndarray]\n",
        "        assert  input.shape[-1] == self.I\n",
        "\n",
        "        if type(input) == np.ndarray :\n",
        "            input = torch.tensor(input)\n",
        "\n",
        "        # Running the network\n",
        "        \n",
        "        output = super().forward(input)\n",
        "        if prob_out :\n",
        "            output = torch.sigmoid(output)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generator_goodness (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "        compare two batches of data by calculating the absolute mean difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # averaged over batches \n",
        "    generated_mean = torch.mean(generated_batch)\n",
        "    real_mean      = torch.mean(real_batch)\n",
        "\n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    goodness_criteria = torch.mean(torch.abs(real_mean - generated_mean))\n",
        "\n",
        "    return goodness_criteria.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Log :\n",
        "    \"\"\"\n",
        "        container class for GANTraining logs\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__ (self) :\n",
        "        self.losses       = None\n",
        "        self.probs        = None\n",
        "        self.gen_goodness = None\n",
        "        self._dis_losses  = None\n",
        "        self._probs       = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANTraining :\n",
        "    \"\"\"\n",
        "        general GAN training class\n",
        "        How To Use:\n",
        "        * `MyTrain = GANTraining(<Generator>, <Discriminator>, <torch_dataset>)`\n",
        "        * `MyTrain.setup(<int_rounds>, batchsize = 1, discriminator_rounds = 1,     \n",
        "                        loss_function = [\"WGAN\", \"GAN\"])`\n",
        "        * `MyTrain.train()`\n",
        "        \n",
        "        After That:\n",
        "        * `MyTrain.gen` contains trained Generator\n",
        "        * `MyTrain.dis` contains trained Discriminator\n",
        "        * `MyTrain.log` contains metrics from each round:\n",
        "            - .losses       : np.array, shape = (5, rounds)\n",
        "            - .probs        : np.array, shape = (2, rounds)\n",
        "            - .gen_goodness : np.array, shape = (rounds,)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, generator, discriminator, dataset) :\n",
        "        assert  type(generator) in [Network, Generator]\n",
        "        assert  hasattr(generator, \"model\")\n",
        "        assert  type(discriminator) in [Network, Discriminator]\n",
        "        assert  hasattr(discriminator, \"model\")\n",
        "        assert  type(dataset) == torch.utils.data.dataset.TensorDataset\n",
        "        \n",
        "        self.device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "        self.training_filepath = \"../execution/trained_models/\"\n",
        "\n",
        "        # Model, data and optimizer\n",
        "        self.gen     = generator.to(self.device)\n",
        "        self.dis     = discriminator.to(self.device)\n",
        "        self.dataset = dataset\n",
        "        self.dataset.tensors[0].to(self.device)\n",
        "        self.optimizer_gen = torch.optim.Adam(self.gen.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        self.optimizer_dis = torch.optim.Adam(self.dis.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        # Note: ADAM parameters from GAN tutorial [1].\n",
        "\n",
        "\n",
        "    def setup (self, rounds, batch_size = 1, discriminator_rounds = 1, \n",
        "               loss_function = \"WGAN\") :\n",
        "        assert  type(rounds) == int\n",
        "        assert  rounds >= 1\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 1\n",
        "        assert  type(discriminator_rounds) == int\n",
        "        assert  discriminator_rounds >= 1\n",
        "        assert  loss_function in [\"GAN\", \"WGAN\"]\n",
        "\n",
        "        # Training parameters\n",
        "        self.rounds     = rounds\n",
        "        self.batch_size = batch_size\n",
        "        self.dis_rounds = discriminator_rounds\n",
        "        self.loss       = loss_function\n",
        "\n",
        "        # Dataloader\n",
        "        self.data_loader = torch.utils.data.DataLoader(self.dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                drop_last = True,\n",
        "                                shuffle = True)\n",
        "        self._data_list  = list(self.data_loader)\n",
        "        self._batch_num  = 0\n",
        "\n",
        "        # Logs\n",
        "        self.log = Log()\n",
        "        self.log.losses       = np.zeros((5, self.rounds))\n",
        "        self.log.probs        = np.zeros((2, self.rounds))\n",
        "        self.log.gen_goodness = np.zeros((self.rounds,))\n",
        "        self.log._dis_losses  = torch.zeros((4, self.dis_rounds))\n",
        "        self.log._probs       = torch.zeros((2, self.dis_rounds))\n",
        "        \n",
        "\n",
        "\n",
        "    def train (self) :\n",
        "        assert  hasattr(self, \"data_loader\")  # If test fails, you haven't run set_params()\n",
        "\n",
        "        for round in range(self.rounds) :\n",
        "            for dis_round in range(self.dis_rounds) :\n",
        "                # Forward propagation\n",
        "                batch_real = self._get_batch()\n",
        "                batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "                dis_real = self.dis.forward(batch_real)\n",
        "                dis_gen  = self.dis.forward(batch_gen)\n",
        "                self.prob_real = torch.sigmoid(dis_real)\n",
        "                self.prob_gen  = torch.sigmoid(dis_gen)\n",
        "\n",
        "                # Calculating the Discriminator loss function\n",
        "                if self.loss == \"GAN\" :\n",
        "                    self.loss_real = - torch.mean(torch.log(self.prob_real))\n",
        "                    self.loss_gen  = torch.mean(torch.log(1 - self.prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "                elif self.loss == \"WGAN\" :\n",
        "                    var_gen   = torch.var(dis_gen)\n",
        "                    var_real  = torch.var(dis_real)\n",
        "                    self.loss_reg  = torch.where(var_gen > 1, \n",
        "                                                 (var_gen - 1)**2, 0) \\\n",
        "                                     + torch.where(var_real > 1, \n",
        "                                                   (var_real - 1)**2, 0)\n",
        "                    self.loss_real = - torch.mean(dis_real)\n",
        "                    self.loss_gen  = torch.mean(dis_gen)\n",
        "\n",
        "                self.loss_dis = self.loss_real + self.loss_gen + self.loss_reg\n",
        "                self._log_all(round, k = dis_round)\n",
        "                \n",
        "                # Discriminator update\n",
        "                self.optimizer_dis.zero_grad()\n",
        "                self.loss_dis.backward(retain_graph = True)\n",
        "                self.optimizer_dis.step()\n",
        "\n",
        "                print(\".\", end = \"\")\n",
        "\n",
        "            # Calculating the Generator loss function\n",
        "            batch_gen = self.gen.forward(batch_size = self.batch_size)\n",
        "            dis_new   = self.dis.forward(batch_gen)\n",
        "            \n",
        "            if self.loss == \"GAN\" :\n",
        "                prob_new = torch.sigmoid(dis_new)\n",
        "                self.loss_gen = -torch.mean(torch.log(prob_new)) \n",
        "            elif self.loss == \"WGAN\" :\n",
        "                self.loss_gen = -torch.mean(dis_new)\n",
        "            self._log_all(round)\n",
        "            \n",
        "            # Generator update\n",
        "            self.optimizer_gen.zero_grad()\n",
        "            self.loss_gen.backward()\n",
        "            self.optimizer_gen.step()\n",
        "\n",
        "            print(\"\", end=\"\\r\")\n",
        "            print(f\"round {round} of {self.rounds}\", end = \"\\r\")\n",
        "            #print(\"                               \", end = \"\\r\")\n",
        "\n",
        "\n",
        "    def _get_batch (self) :\n",
        "        \"\"\"\n",
        "            samples one batch of data from self.data_loader without replacement.\n",
        "            When the self.data_set is depleted of fresh batches, \n",
        "            self.data_loader will shuffle a list of new batches.\n",
        "        \"\"\"\n",
        "        if self._batch_num >= len(self._data_list) :\n",
        "            self._data_list = list(self.data_loader)\n",
        "            self._batch_num = 0\n",
        "        batch = self._data_list[self._batch_num][0]\n",
        "        self._batch_num += 1\n",
        "        return batch   \n",
        "\n",
        "\n",
        "    def _log_all (self, round, k = -1) :\n",
        "        if k >= 0 : # before each Discriminator update\n",
        "            self.log._dis_losses[0, k] = self.loss_dis\n",
        "            self.log._dis_losses[1, k] = self.loss_real\n",
        "            self.log._dis_losses[2, k] = self.loss_gen\n",
        "            self.log._dis_losses[3, k] = self.loss_reg\n",
        "            self.log._probs[0, k] = self.prob_real.mean()\n",
        "            self.log._probs[1, k] = self.prob_gen.mean()\n",
        "        \n",
        "        if k == -1 : # before each Generator update\n",
        "            # Losses\n",
        "            dis_losses = self.log._dis_losses.detach().numpy()\n",
        "            self.log.losses[0:4, round] = dis_losses.mean(axis = 1)\n",
        "            self.log.losses[4, round]   = self.loss_gen.detach().numpy()\n",
        "            \n",
        "            # Discriminator Probabilities\n",
        "            probs                    = self.log._probs.detach().numpy()\n",
        "            self.log.probs[:, round] = probs.mean(axis = 1)\n",
        "\n",
        "            # Generator Goodness\n",
        "            batch_real = self._get_batch()\n",
        "            batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "            goodness   = generator_goodness(batch_gen, batch_real)\n",
        "            self.log.gen_goodness[round] = goodness\n",
        "\n",
        "\n",
        "\n",
        "    def save (self, name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"wb\")\n",
        "        pickle.dump(self, file)\n",
        "        print(f\"Saved training under '{file_name}'\")\n",
        "\n",
        "\n",
        "    def load (self, name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"rb\")\n",
        "        return pickle.load(file)\n",
        "\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "minimock = CentralDotImage(4, 4, dataset_size=100)\n",
        "minimock.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniGenerator:\n",
            "    input length:  4\n",
            "    output length: 16\n",
            "    layers:        4\n",
            "    parameters:    100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniGen = Generator(4, minimock.size, \"miniGenerator\")\n",
        "\n",
        "miniGen.create_model([\n",
        "    torch.nn.Linear(miniGen.I, miniGen.I),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(miniGen.I, miniGen.O),\n",
        "    StraightThroughEstimator()\n",
        "])\n",
        "\n",
        "miniGen.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniDiscriminator:\n",
            "    input length:  16\n",
            "    output length: 1\n",
            "    layers:        3\n",
            "    parameters:    73\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniDis = Discriminator(minimock.size, 1, \"miniDiscriminator\")\n",
        "\n",
        "miniDis.create_model([\n",
        "    torch.nn.Linear(miniDis.I,4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4, miniDis.O)\n",
        "])\n",
        "\n",
        "miniDis.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob. that image is real: 42%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "gen_flat = miniGen.forward(numpy_out = True)\n",
        "prob     = miniDis.forward(gen_flat, prob_out = True, numpy_out = True)[0]\n",
        "\n",
        "print(f\"Prob. that image is real: {prob*100:.0f}%\")\n",
        "gen_img = gen_flat.reshape(*minimock.shape)\n",
        "plt.imshow(gen_img);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round 999 of 1000......\r"
          ]
        }
      ],
      "source": [
        "test = GANTraining(miniGen, miniDis, minimock.dataset)\n",
        "test.setup(1000, batch_size = 2, discriminator_rounds = 2, loss_function = \"GAN\")\n",
        "test.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "first-music-GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('aml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9db57278ae8397bc5fe3bec6b9ba53c33a2aa76e79d386f678fc754e34f9547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
