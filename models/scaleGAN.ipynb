{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakioh/MusiCAN/blob/main/models/first_music_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scaleGAN\n",
        "**Description:** scalable GAN architecture with an equally scalable mock dataset.\\\n",
        "**Purpose:** find an efficient and stable architecture to generate images as large as pianorolls with.\\\n",
        "**Results:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Zy36G-CGamF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class and function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CentralDotImage :\n",
        "    \"\"\"\n",
        "        creates mock data set out of a simple image copied multiple times\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "        __init__(height, width, dataset_size = 100) : \n",
        "            creates all attributes\n",
        "        show() : \n",
        "            plt.plots image\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        height : int\n",
        "            of image, in pixels\n",
        "        width : int\n",
        "            of image, in pixels\n",
        "        size : int\n",
        "            number of pixels in image\n",
        "        dataset_size : int\n",
        "            number of images\n",
        "        \n",
        "        image : torch.Tensor\n",
        "            out of 1s and 0s,\n",
        "            size = (width, height)\n",
        "        vector : torch.Tensor\n",
        "            flattened image,\n",
        "            size = (size)\n",
        "        data : torch.Tensor\n",
        "            images copied dataset_size times\n",
        "            size = (dataset_size, size)\n",
        "        dataset : torch.TensorDataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__ (self, height, width, dataset_size = 100) :\n",
        "        # Input checks\n",
        "        assert  type(height) == int and type(width) == int\n",
        "        assert  height >= 1 and width >= 1\n",
        "        assert  type(dataset_size) == int\n",
        "        assert  dataset_size >= 1\n",
        "\n",
        "        self.height = height\n",
        "        self.width  = width\n",
        "        self.shape  = (height, width)\n",
        "        self.size   = height * width\n",
        "        self.dataset_size = dataset_size\n",
        "\n",
        "        # Image creation\n",
        "        self.image = torch.zeros(height, width)\n",
        "        for i in range(height) :\n",
        "            for j in range(width) :\n",
        "                self.image[i, j] = \\\n",
        "                    i + 1 <= math.ceil(3/4 * height) and \\\n",
        "                    i + 1 > math.floor(1/4 * height) and \\\n",
        "                    j + 1 <= math.ceil(3/4 * width) and \\\n",
        "                    j + 1 > math.floor(1/4 * width)\n",
        "\n",
        "        # Dataset creation\n",
        "        self.vector  = self.image.flatten()\n",
        "        self.data    = self.vector[None, :].expand(dataset_size, self.size)\n",
        "        self.dataset = torch.utils.data.TensorDataset(self.data)\n",
        "\n",
        "    def show (self) :\n",
        "        plt.imshow(self.image)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    These two classes serves as torch layers to binarize the output of the Generator while keeping the layer still \"backpropagatable\" (via a hardtanh).\n",
        "    This is not our own code. For source, see:\n",
        "    https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#:~:text=A%20straight%2Dthrough%20estimator%20is,function%20was%20an%20identity%20function.\n",
        "\"\"\"\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return torch.nn.functional.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network (torch.nn.Module) :\n",
        "    \"\"\"\n",
        "        General neural network class for specialized networks.\n",
        "        Create those by:\n",
        "        ```\n",
        "        myNet = Networck(<int_input_length>, <int_output_length>, <str_name>)\n",
        "        layer_list = [<torch.nn.Module1>, ...]\n",
        "        myNet.create_model(layer_list)\n",
        "        myNet.print_stats()\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__ (self, input_length, output_length, name) : \n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_length  = self.I = input_length\n",
        "        self.output_length = self.O = output_length\n",
        "        self.name          = name\n",
        "            \n",
        "\n",
        "    def create_model (self, layer_list) :\n",
        "        self.model = torch.nn.Sequential(*layer_list)\n",
        "\n",
        "\n",
        "    def print_stats (self) :\n",
        "        print(f\"{self.name}:\")\n",
        "        print(f\"    input length:  {self.input_length}\")\n",
        "        print(f\"    output length: {self.output_length}\")\n",
        "        print(f\"    layers:        {len(self.model)}\")\n",
        "        print(f\"    parameters:    {self.count_params()}\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def count_params (self) :\n",
        "        \"\"\"count number of trainable parameters\"\"\"\n",
        "\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward (self, input, numpy_out = False) :\n",
        "        \"\"\"run network\"\"\"\n",
        "        output = self.model(input)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def _numpify (self, tensor) :\n",
        "        return tensor.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator (Network) :\n",
        "    \n",
        "    def forward (self, batch_size = 0, numpy_out = False) :\n",
        "        \"\"\"run network with a batch of normally distributed seeds\"\"\"\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 0\n",
        "\n",
        "        # Seed generation\n",
        "        if batch_size == 0 :\n",
        "            seed_size = (self.input_length,)\n",
        "        else :\n",
        "            seed_size = (batch_size, self.input_length)\n",
        "        seed = torch.normal(0, 1, seed_size)\n",
        "        \n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out)\n",
        "\n",
        "            \n",
        "    def forward_custom (self, seed, numpy_out = False) :\n",
        "        \"\"\"run network with custom seed\"\"\"\n",
        "        assert  type(seed) == torch.Tensor\n",
        "        assert  seed.shape[-1] == self.I\n",
        "\n",
        "        # Running the network\n",
        "        return super().forward(seed, numpy_out = numpy_out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator (Network) :\n",
        "\n",
        "    def forward (self, input, prob_out = False, numpy_out = False) :\n",
        "        \"\"\"\n",
        "            run network, optionally return probability (default logit) or numpy array (default torch)\n",
        "        \"\"\"\n",
        "        assert  type(input) in [torch.Tensor, np.ndarray]\n",
        "        assert  input.shape[-1] == self.I\n",
        "\n",
        "        if type(input) == np.ndarray :\n",
        "            input = torch.tensor(input)\n",
        "\n",
        "        # Running the network\n",
        "        \n",
        "        output = super().forward(input)\n",
        "        if prob_out :\n",
        "            output = torch.sigmoid(output)\n",
        "        if numpy_out :\n",
        "            output = self._numpify(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generator_goodness (generated_batch, real_batch) :\n",
        "    \"\"\"\n",
        "    compare two batches of data by calculating the absolute mean difference\n",
        "    \"\"\"\n",
        "    \n",
        "    # averaged over batches \n",
        "    generated_mean = torch.mean(generated_batch)\n",
        "    real_mean      = torch.mean(real_batch)\n",
        "\n",
        "    # take differnece & absolut value, average over features lastly\n",
        "    goodness_criteria = torch.mean(torch.abs(real_mean - generated_mean))\n",
        "\n",
        "    return goodness_criteria.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANTraining :\n",
        "    def __init__ (self, generator, discriminator, dataset) :\n",
        "        assert  type(generator) in [Network, Generator]\n",
        "        assert  hasattr(generator, \"model\")\n",
        "        assert  type(discriminator) in [Network, Discriminator]\n",
        "        assert  hasattr(discriminator, \"model\")\n",
        "        assert  type(dataset) == torch.utils.data.dataset.TensorDataset\n",
        "        \n",
        "        self.device = 'cuda'  if torch.cuda.is_available() else  'cpu'\n",
        "        self.training_filepath = \"../execution/trained_models/\"\n",
        "\n",
        "        # Model, data and optimizer\n",
        "        self.gen     = generator.to(self.device)\n",
        "        self.dis     = discriminator.to(self.device)\n",
        "        self.dataset = dataset.to(self.device)\n",
        "        self.optimizer_gen = torch.optim.Adam(self.gen.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        self.optimizer_dis = torch.optim.Adam(self.dis.parameters(), \n",
        "                                              lr = 0.001,\n",
        "                                              betas = (0.5, 0.9))\n",
        "        # Note: ADAM parameters from GAN tutorial [1].\n",
        "        \n",
        "\n",
        "    def set_params (self, rounds, batch_size = 1, discriminator_rounds = 1, \n",
        "                    loss_function = \"WGAN\") :\n",
        "        assert  type(rounds) == int\n",
        "        assert  rounds >= 1\n",
        "        assert  type(batch_size) == int\n",
        "        assert  batch_size >= 1\n",
        "        assert  type(discriminator_rounds) == int\n",
        "        assert  discriminator_rounds >= 1\n",
        "        assert  loss_function in [\"GAN\", \"WGAN\"]\n",
        "\n",
        "        # Training parameters\n",
        "        self.rounds     = rounds\n",
        "        self.batch_size = batch_size\n",
        "        self.dis_rounds = discriminator_rounds\n",
        "        self.loss       = loss_function\n",
        "\n",
        "        # Dataloader\n",
        "        self.data_loader = torch.utils.data.DataLoader(self.dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                drop_last = True,\n",
        "                                shuffle = True)\n",
        "        \n",
        "        # Logs\n",
        "        self.log.losses       = np.zeros((5, self.rounds))\n",
        "        self.log.probs        = np.zeros((2, self.rounds))\n",
        "        self.log.gen_goodness = np.zeros((self.rounds,))\n",
        "        self.log._dis_losses  = torch.zeros((4, self.dis_rounds))\n",
        "        self.log._probs       = torch.zeros((2, self.dis_rounds))\n",
        "        \n",
        "\n",
        "\n",
        "    def train (self) :\n",
        "        assert  hasattr(self, \"data_loader\")  # If test fails, you haven't run set_params()\n",
        "\n",
        "        for round in range(self.rounds) :\n",
        "            for dis_round in range(self.dis_rounds) :\n",
        "                # Forward propagation\n",
        "                batch_real = iter(self.data_loader)\n",
        "                batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "                dis_real = self.dis.forward(batch_real)\n",
        "                dis_gen  = self.dis.forward(batch_gen)\n",
        "                self.prob_real = torch.sigmoid(dis_real)\n",
        "                self.prob_gen  = torch.sigmoid(dis_gen)\n",
        "\n",
        "                # Calculating the Discriminator loss function\n",
        "                if self.loss == \"GAN\" :\n",
        "                    self.loss_real = - torch.mean(torch.log(self.prob_real))\n",
        "                    self.loss_gen  = torch.mean(torch.log(\n",
        "                                     1 - self.prob_gen))\n",
        "                    self.loss_reg  = torch.tensor(0.)\n",
        "                elif self.loss == \"WGAN\" :\n",
        "                    var_gen   = torch.var(dis_gen)\n",
        "                    var_real  = torch.var(dis_real)\n",
        "                    self.loss_reg  = torch.where(var_gen > 1, \n",
        "                                                 (var_gen - 1)**2, 0) \\\n",
        "                                     + torch.where(var_real > 1, \n",
        "                                                   (var_real - 1)**2, 0)\n",
        "                    self.loss_real = - torch.mean(dis_real)\n",
        "                    self.loss_gen  = torch.mean(dis_gen)\n",
        "\n",
        "                self.loss_dis = self.loss_real + self.loss_gen + self.loss_reg\n",
        "                self._log_all(round, k = dis_round)\n",
        "                \n",
        "                # Discriminator update\n",
        "                self.optimizer_dis.zero_grad()\n",
        "                loss_dis.backward(retain_graph = True)\n",
        "                self.optimizer_dis.step()\n",
        "\n",
        "            # Calculating the Generator loss function\n",
        "            batch_gen = self.gen.forward(batch_size = self.batch_size)\n",
        "            dis_new   = self.dis.forward(batch_gen)\n",
        "            \n",
        "            if self.loss_function == \"GAN\" :\n",
        "                prob_new = torch.sigmoid(dis_new)\n",
        "                self.loss_gen = -torch.mean(torch.log(prob_new)) \n",
        "            elif self.loss_function == \"WGAN\" :\n",
        "                self.loss_gen = -torch.mean(dis_new)\n",
        "            self._log_all(round)\n",
        "            \n",
        "            # Generator update\n",
        "            self.optimizer_gen.zero_grad()\n",
        "            self.loss_gen.backward()\n",
        "            self.optimizer_gen.step()\n",
        "\n",
        "\n",
        "    def _log_all (round, k = -1) :\n",
        "        if k >= 0 : # before each Discriminator update\n",
        "            self.log._dis_losses[0, k] = self.loss_dis\n",
        "            self.log._dis_losses[1, k] = self.loss_real\n",
        "            self.log._dis_losses[2, k] = self.loss_gen\n",
        "            self.log._dis_losses[3, k] = self.loss_reg\n",
        "            self.log._probs[0, k] = self.prob_real.mean()\n",
        "            self.log._probs[1, k] = self.prob_gen\n",
        "        \n",
        "        if k == -1 : # before each Generator update\n",
        "            dis_losses = self.log._dis_losses.detach().numpy()\n",
        "            probs      = self.log._probs.detach().numpy()\n",
        "            self.log.losses[0:4, round] = dis_losses.mean(axis = 1)\n",
        "            self.log.losses[5, round]   = self.loss.gen.detach().numpy()\n",
        "            self.log.probs[:, round]    = probs.mean(axis = 1)\n",
        "\n",
        "            batch_real = iter(self.data_loader)\n",
        "            batch_gen  = self.gen.forward(batch_size = self.batch_size)\n",
        "            goodness   = generator_goodness(batch_gen, batch_real)\n",
        "            self.log.gen_goodness[round] = goodness\n",
        "\n",
        "\n",
        "\n",
        "    def save (self, name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"wb\")\n",
        "        pickle.dump(self, file)\n",
        "        print(f\"Saved training under '{file_name}'\")\n",
        "\n",
        "\n",
        "    def load (name) :\n",
        "        file_name = self.training_filepath + name + \".obj\"\n",
        "        file      = open(file_name, \"rb\")\n",
        "        return pickle.load(file)\n",
        "\n",
        "\n",
        "# Sources:\n",
        "# [1] https://github.com/salu133445/ismir2019tutorial/blob/main/gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "minimock = CentralDotImage(4, 4)\n",
        "minimock.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniGenerator:\n",
            "    input length:  4\n",
            "    output length: 16\n",
            "    layers:        4\n",
            "    parameters:    100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniGen = Generator(4, minimock.size, \"miniGenerator\")\n",
        "\n",
        "miniGen.create_model([\n",
        "    torch.nn.Linear(miniGen.I, miniGen.I),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(miniGen.I, miniGen.O),\n",
        "    StraightThroughEstimator()\n",
        "])\n",
        "\n",
        "miniGen.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miniDiscriminator:\n",
            "    input length:  16\n",
            "    output length: 1\n",
            "    layers:        3\n",
            "    parameters:    73\n",
            "\n"
          ]
        }
      ],
      "source": [
        "miniDis = Discriminator(minimock.size, 1, \"miniDiscriminator\")\n",
        "\n",
        "miniDis.create_model([\n",
        "    torch.nn.Linear(miniDis.I,4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4, miniDis.O)\n",
        "])\n",
        "\n",
        "miniDis.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob. that image is real: 45%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "gen_flat = miniGen.forward(numpy_out = True)\n",
        "prob     = miniDis.forward(gen_flat, prob_out = True, numpy_out = True)[0]\n",
        "\n",
        "print(f\"Prob. that image is real: {prob*100:.0f}%\")\n",
        "gen_img = gen_flat.reshape(*minimock.shape)\n",
        "plt.imshow(gen_img);"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "first-music-GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('aml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9db57278ae8397bc5fe3bec6b9ba53c33a2aa76e79d386f678fc754e34f9547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
