{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505812a9",
   "metadata": {},
   "source": [
    "#  MAESTRO Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e45e50",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432fcba",
   "metadata": {},
   "source": [
    "install\n",
    "1. muspy & pypianoroll via pip install after activating conda environment folder \n",
    "2. fluidsynth via conda install -c conda-forge fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Audio, display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd333c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from tqdm import tqdm # valuebar for iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "import pypianoroll\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b714ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_musescore_soundfont() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_bravura_font() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50356c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c688fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO = muspy.datasets.MAESTRODatasetV3(\"./unprepared_data/MAESTRO\", download_and_extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999337f",
   "metadata": {},
   "source": [
    "## Prepare Piano-rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e229524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values\n",
    "dataset_root = \"./unprepared_data/MAESTRO/maestro-v3.0.0/all_midi\"\n",
    "\n",
    "n_pitches = 6*12  # number of pitches\n",
    "lowest_pitch = 2*12  # MIDI note number of the lowest pitch\n",
    "beat_resolution = 4 # temporal resolution of a beat (in timestep), 24 in data, 12 for MusiGAN\n",
    "bars_per_instance = 12 # number of bars per instance in prepared data \n",
    "\n",
    "# for later..\n",
    "bar_resolution = 4 * beat_resolution\n",
    "sample_size = 4 * bars_per_instance # number of beats per instance created by track-cropping, 4 bars for MusiGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def plot_pianoroll(pr):\n",
    "    \"\"\"\n",
    "    pr: Pitches x Time\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 6))\n",
    "    plt.imshow(pr.T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d11e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def inter_bar_var(splits, std_thr = 0.04) :\n",
    "    \"\"\"\n",
    "        computes the inter-bar standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    reshaped = np.reshape(splits, (splits.shape[0], bars_per_instance, bar_resolution, n_pitches))\n",
    "    inter_bar_std_dev = np.mean(np.std(splits, axis = 1, ddof = 1), -1) # std over bars\n",
    "    inter_bar_std_dev_mask = (inter_bar_std_dev >= std_thr)\n",
    "    \n",
    "    return(splits[inter_bar_std_dev_mask],  inter_bar_std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def qualified_note_rate(pianoroll, qnr_thr) :\n",
    "    \"\"\"\n",
    "        ratio of \"qualified\" notes,\n",
    "        defined as a qnr_thr blips/timesteps or longer. \n",
    "        \n",
    "        also called:\n",
    "            QN = \"qualified note rate\"\n",
    "    \"\"\"\n",
    "    minimum_length = qnr_thr # blips\n",
    "    conv = np.array([-1, 1]) # used to measure note start and ends\n",
    "\n",
    "    total_notes       = 0\n",
    "    total_quali_notes = 0\n",
    "    for pitch_line in pianoroll.T:\n",
    "        note_starts = np.convolve(pitch_line, conv)\n",
    "        note_stops  = np.convolve(pitch_line, -conv)\n",
    "        start_indices = np.where(note_starts == -1)[0]\n",
    "        stop_indices  = np.where(note_stops == -1)[0]\n",
    "            \n",
    "        note_lengths     = stop_indices - start_indices\n",
    "        note_count       = note_lengths.shape[0]\n",
    "        quali_note_count = np.sum(note_lengths >= minimum_length)\n",
    "        total_notes       += note_count\n",
    "        total_quali_notes += quali_note_count\n",
    "\n",
    "    quali_note_ratio = total_quali_notes / total_notes\n",
    "    \n",
    "    return quali_note_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multitrack(multitrack, label, track_idx = 1, qnr_thr = 0.4, std_thr = 0.03):\n",
    "    \n",
    "    crop_list = []\n",
    "    crop_label_list = []\n",
    "    inter_bar_stds = []\n",
    "    \n",
    "    # check if enough notes longer than the resolution & downsample, otherwise stop\n",
    "    pianoroll = multitrack.tracks[track_idx].pianoroll # get pianolroll\n",
    "    resolution = multitrack.resolution\n",
    "    qnr = qualified_note_rate(pianoroll > 0, resolution // beat_resolution)\n",
    "    \n",
    "    if qnr < qnr_thr:\n",
    "        return(crop_list, crop_label_list, qnr, inter_bar_stds)\n",
    "    \n",
    "    else:\n",
    "        multitrack = multitrack.set_resolution(beat_resolution, rounding = \"round\")\n",
    "    \n",
    "        # select piano trck (2nd one)\n",
    "        piano_track = multitrack.tracks[track_idx]\n",
    "    \n",
    "        # pad into mupliples of bars such that later piano can be splitted into bars easily\n",
    "        piano_track = piano_track.pad_to_multiple(bar_resolution)\n",
    "    \n",
    "        # array conversion (shape: time x pitches)\n",
    "        pianoroll = piano_track.pianoroll\n",
    "    \n",
    "        # binarize pianoroll\n",
    "        pianoroll = (pianoroll > 0)\n",
    "    \n",
    "        # fix pitch range\n",
    "        pianoroll = pianoroll[:, lowest_pitch : lowest_pitch + n_pitches] # (shape: time x pitches))\n",
    "    \n",
    "        # slice into pieces of sequences without empty bars\n",
    "        reshaped = pianoroll.reshape(-1, bar_resolution, n_pitches)\n",
    "        reshaped = pianoroll.reshape(-1, bar_resolution * n_pitches)\n",
    "        empty_bars_mask = np.any(reshaped, axis = 1)\n",
    "        split_after_this_bar_mask = (np.diff(empty_bars_mask) != 0)\n",
    "        split_after_this_bar_numbers = np.arange(len(empty_bars_mask) - 1)[split_after_this_bar_mask]\n",
    "        split_indices = ((split_after_this_bar_numbers + 1) * bar_resolution) \n",
    "        split_list = np.split(pianoroll, split_indices)\n",
    "    \n",
    "        # crop each split into smaller training samples\n",
    "        start = np.any(split_list[0]) # = 0 if first split empty, else 1\n",
    "        for split in split_list[1 - start::2]: # only select non-empty slices\n",
    "            n_timesteps = bars_per_instance * bar_resolution # time steps per instance\n",
    "            if split.shape[0] >= n_timesteps: # crop only what is at least as big as one crop should be\n",
    "                split = split[ : split.shape[0] - (split.shape[0] % n_timesteps), :] # make sure: number of total timesteps of track % n_timesteps == 0, else skip last bar\n",
    "                splits = split.reshape((-1, n_timesteps, n_pitches)) # crops x time x pitches\n",
    "                \n",
    "                # avoid too repetitive splits\n",
    "                good_splits, inter_bar_std_dev = inter_bar_var(splits, std_thr)\n",
    "                inter_bar_stds.append(inter_bar_std_dev)\n",
    "                \n",
    "                # append splits & labels\n",
    "                crop_list.append(good_splits)\n",
    "                crop_label_list.extend([label] * good_splits.shape[0]) # append as many labels as crops added\n",
    "    \n",
    "        return(crop_list, crop_label_list, qnr, inter_bar_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8685873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all the songs in the ID list & prepare data\n",
    "\n",
    "data_list = []\n",
    "data_label_list = []\n",
    "qnrs = []\n",
    "inter_bar_stds_list = []\n",
    "\n",
    "midi_file_path = \"./unprepared_data/MAESTRO/maestro-v3.0.0/all_midi\"\n",
    "label = \"classical\"\n",
    "n_midi_files = 0\n",
    "\n",
    "for path in tqdm(os.listdir(midi_file_path)):\n",
    "    midi_filepath = midi_file_path + \"/\" + path\n",
    "    \n",
    "    # sort out files with non single 4/4 time signature\n",
    "    pretty_midi_file = pretty_midi.PrettyMIDI(midi_filepath)\n",
    "    time_signatures = pretty_midi_file.time_signature_changes\n",
    "    if len(time_signatures) > 1 or (time_signatures[0].numerator != time_signatures[0].denominator != 4):\n",
    "        continue\n",
    "    \n",
    "    multitrack = pypianoroll.read(midi_filepath)\n",
    "    \n",
    "    # some files are corrupt or not compatible with pypianroll..\n",
    "    \"\"\"\n",
    "    try:\n",
    "        multitrack = pypianoroll.read(midi_filepath)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    if len(multitrack.tracks) == 0:\n",
    "        continue\n",
    "    \"\"\"\n",
    " \n",
    "    split_list, split_label_list, qnr, inter_bar_stds = prepare_multitrack(multitrack, label, track_idx = 0)\n",
    "    data_list.extend(split_list)\n",
    "    data_label_list.extend(split_label_list)\n",
    "    qnrs.append(qnr)\n",
    "    inter_bar_stds_list.extend(inter_bar_stds)\n",
    "    n_midi_files += 1\n",
    "    \n",
    "    \"\"\"\n",
    "    if n_midi_files > 25:\n",
    "        break\n",
    "    \"\"\"\n",
    "\n",
    "qnrs_array = np.array(qnrs)\n",
    "print(\"qnrs:\", np.mean(qnrs_array), np.std(qnrs_array))\n",
    "inter_bar_stds_array = np.concatenate(inter_bar_stds_list)\n",
    "print(\"ibstds:\", np.mean(inter_bar_stds_array), np.std(inter_bar_stds_array))       \n",
    "        \n",
    "data_array = np.concatenate(data_list, axis = 0) # (shape: n_instances x n_timesteps x n_pitches)\n",
    "label_array = np.array(data_label_list)\n",
    "print(f\"Successfully collected {len(data_array)} samples from {n_midi_files} songs\")\n",
    "print(f\"Data shape : {data_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeecf02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_pianoroll(data_array[i+40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a213b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prepared data\n",
    "\n",
    "## create unique file directory to save data\n",
    "timestamp = datetime.datetime.now()\n",
    "file_directory = f\"./prepared_data/maestro_{timestamp}\"\n",
    "os.makedirs(file_directory)\n",
    "os.makedirs(file_directory + \"/audio_examples\") # for later..\n",
    "\n",
    "## save preparation parameters as json file\n",
    "prep_pars_dict = {\"n_pitches\": n_pitches,\n",
    "                 \"lowest_pitch\": lowest_pitch,\n",
    "                 \"beat_resolution\": beat_resolution, \n",
    "                  \"beats_per_instance\": sample_size}\n",
    "with open(file_directory + \"/preparation_params.json\", \"w\") as file:\n",
    "    json.dump(prep_pars_dict, file, indent = 6)\n",
    "\n",
    "## save data as compressed npz files\n",
    "np.savez_compressed(file_directory + \"/prepared_arrays.npz\", data=data_array, labels=label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b879ab",
   "metadata": {},
   "source": [
    "## Evaluate Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "loaded_file_directory = file_directory # \"./prepared_data/maestro_full_12bars\" # change if wanted\n",
    "loaded_data = np.load(loaded_file_directory + \"/prepared_arrays.npz\")\n",
    "loaded_data_array, loaded_label_array = loaded_data[\"data\"], loaded_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96920dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total pitch range \n",
    "\n",
    "n_pitches_array = loaded_data_array.sum(axis = 1).sum(axis = 0)\n",
    "plt.plot(np.arange(72), n_pitches_array, \"ro\")\n",
    "plt.ylabel(\"# of pitches\")\n",
    "plt.xlabel(\"pitches\")\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f5912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert random instances of loaded data to wave (audio) file & display them\n",
    "\n",
    "n = 5 # number or random examples\n",
    "rand_idxs = np.random.randint(0, len(loaded_label_array), n)\n",
    "\n",
    "for i in tqdm(rand_idxs):\n",
    "    X, y = loaded_data_array[i, :, :], loaded_label_array[i]\n",
    "    \n",
    "    genre_of_X = label\n",
    "    \n",
    "    X_padded = np.pad(X, ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))) # complete pitch range\n",
    "    X_music = muspy.from_pianoroll_representation(X_padded > 0, \n",
    "                resolution = beat_resolution, encode_velocity = False) # convert to muspy.music_object\n",
    "\n",
    "    X_timestamp = datetime.datetime.now()\n",
    "    muspy.write_audio(path = loaded_file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\", \n",
    "                      music = X_music) \n",
    "    \n",
    "    # display audio & show pianoroll\n",
    "    print(genre_of_X + \":\")\n",
    "    display(Audio(filename = loaded_file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\"))\n",
    "    muspy.visualization.show_pianoroll(X_music)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b12ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into pytorch dataset & dataloader\n",
    "batch_size = 15\n",
    "\n",
    "# convert to pytorch tensor\n",
    "data_tensor = torch.as_tensor(loaded_data_array, dtype=torch.float32)\n",
    "label_tensor = torch.as_tensor(loaded_label_array, dtype=torch.int)\n",
    "\n",
    "# create pytorch dataset & dataloader\n",
    "dataset = torch.utils.data.TensorDataset(data_tensor, label_tensor)\n",
    "lpd5_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
