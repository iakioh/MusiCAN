{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505812a9",
   "metadata": {},
   "source": [
    "# Lakh Pianoroll Dataset 5 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e45e50",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432fcba",
   "metadata": {},
   "source": [
    "install\n",
    "1. muspy & pypianoroll via pip install in environment folder (e.g. /Users/kai/anaconda3/opt/envs/MusiCAN/bin)\n",
    "2. fluidsynth via conda install -c conda-forge fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Audio, display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd333c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from tqdm import tqdm # valuebar for iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "import pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b714ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_musescore_soundfont() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_bravura_font() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6c9e1",
   "metadata": {},
   "source": [
    "## Prepare Genre Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels & id_list\n",
    "\n",
    "genre_list = ['Rap', 'Latin', 'International', 'Electronic', \n",
    "              'Country', 'Folk', 'Blues', 'Reggae', 'Jazz',\n",
    "              'Vocal', 'New-Age', 'RnB', 'Pop_Rock'] # genre <-> numeric label = index\n",
    "\n",
    "id_list = [] # id = MillionSongsDataset ID\n",
    "track_label_list = []\n",
    "for path in os.listdir(\"unprepared_data/id_lists_amg\"):\n",
    "    filepath = \"unprepared_data/id_lists_amg/\" + path\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        ids = [line.rstrip() for line in f]\n",
    "        number_of_ids = len(ids)\n",
    "        id_list.extend(ids)\n",
    "    \n",
    "    genre_no = genre_list.index(path[8:-4])\n",
    "    track_label_list.extend([genre_no] * number_of_ids)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6831fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no multiple genre label \n",
    "n = 0\n",
    "id_array = np.array(id_list)\n",
    "for id_1 in id_list:\n",
    "    n_ids = np.sum(id_array == id_1)\n",
    "    n += (n_ids - 1)\n",
    "n == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999337f",
   "metadata": {},
   "source": [
    "## Prepare Piano-rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a99247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def msd_id_to_dirs(msd_id):\n",
    "    \"\"\"Given an MillionSongsDataset ID, generate the path prefix.\n",
    "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
    "    return(msd_id[2] + \"/\" + msd_id[3] + \"/\" + msd_id[4] + \"/\" + msd_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e229524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values\n",
    "dataset_root = \"unprepared_data/lpd_5/lpd_5_cleansed/\"\n",
    "\n",
    "n_pitches = 6*12  # number of pitches\n",
    "lowest_pitch = 2*12  # MIDI note number of the lowest pitch\n",
    "beat_resolution = 4 # temporal resolution of a beat (in timestep), 24 in data, 12 for MusiGAN\n",
    "bars_per_instance = 12 # number of bars per instance in prepared data \n",
    "min_n_notes = 8 # minimal number of notes per instance\n",
    "\n",
    "# for later..\n",
    "bar_resolution = 4 * beat_resolution\n",
    "sample_size = 4 * bars_per_instance # number of beats per instance created by track-cropping, 4 bars for MusiGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def plot_pianoroll(pr):\n",
    "    \"\"\"\n",
    "    pr: Pitches x Time\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 6))\n",
    "    plt.imshow(pr.T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a15f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all the songs in the ID list & prepare data\n",
    "\n",
    "data_list = []\n",
    "data_label_list = []\n",
    "\n",
    "for i, msd_id in enumerate(tqdm(id_list)):\n",
    "    \n",
    "    # load multitrack as a pypianoroll.Multitrack instance\n",
    "    song_dir = dataset_root + msd_id_to_dirs(msd_id)\n",
    "    filename = os.listdir(song_dir)[0]\n",
    "    multitrack = pypianoroll.load(song_dir + \"/\" + filename)\n",
    "\n",
    "    # downsample\n",
    "    multitrack = multitrack.set_resolution(beat_resolution, rounding = \"round\")\n",
    "    \n",
    "    # select piano trck (2nd one)\n",
    "    piano_track = multitrack.tracks[1]\n",
    "    \n",
    "    # pad into mupliples of bars such that later piano can be splitted into bars easily\n",
    "    piano_track = piano_track.pad_to_multiple(bar_resolution)\n",
    "    \n",
    "    # array conversion (shape: time x pitches)\n",
    "    pianoroll = piano_track.pianoroll\n",
    "    \n",
    "    # binarize pianoroll\n",
    "    pianoroll = (pianoroll > 0)\n",
    "    \n",
    "    # fix pitch range\n",
    "    pianoroll = pianoroll[:, lowest_pitch : lowest_pitch + n_pitches] # (shape: time x pitches))\n",
    "\n",
    "    # slice into pieces of sequences without empty bars\n",
    "    reshaped = pianoroll.reshape(-1, bar_resolution, n_pitches)\n",
    "    reshaped = pianoroll.reshape(-1, bar_resolution * n_pitches)\n",
    "    empty_bars_mask = np.any(reshaped, axis = 1)\n",
    "    split_after_this_bar_mask = (np.diff(empty_bars_mask) != 0)\n",
    "    split_after_this_bar_numbers = np.arange(len(empty_bars_mask) - 1)[split_after_this_bar_mask]\n",
    "    split_indices = ((split_after_this_bar_numbers + 1) * bar_resolution) \n",
    "    split_list = np.split(pianoroll, split_indices)\n",
    "    \n",
    "    # crop each split into smaller training samples\n",
    "    \n",
    "    start = np.any(split_list[0]) # = 0 if first split empty, else 1\n",
    "    for split in split_list[1 - start::2]: # only select non-empty slices\n",
    "        n_timesteps = bars_per_instance * bar_resolution # time steps per instance\n",
    "        if split.shape[0] >= n_timesteps: # crop only what is at least as big as one crop should be\n",
    "            split = split[ : split.shape[0] - (split.shape[0] % n_timesteps), :] # make sure: number of total timesteps of track % n_timesteps == 0, else skip last bar\n",
    "            splits = split.reshape((-1, n_timesteps, n_pitches)) # crops x time x pitches\n",
    "            \n",
    "            # append splits & labels\n",
    "            data_list.append(splits)\n",
    "            data_label_list.extend([track_label_list[i]] * splits.shape[0]) # append as many labels as crops added\n",
    "    \n",
    "data_array = np.concatenate(data_list, axis = 0) # (shape: n_instances x n_timesteps x n_pitches)\n",
    "label_array = np.array(data_label_list)\n",
    "print(f\"Successfully collect {len(data_array)} samples from {len(id_list)} songs\")\n",
    "print(f\"Data shape : {data_array.shape}, {label_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeecf02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plot_pianoroll(data_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a213b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prepared data\n",
    "\n",
    "## create unique file directory to save data\n",
    "timestamp = datetime.datetime.now()\n",
    "file_directory = f\"./prepared_data/lpd5_{timestamp}\"\n",
    "os.makedirs(file_directory)\n",
    "os.makedirs(file_directory + \"/audio_examples\") # for later..\n",
    "\n",
    "## save preparation parameters as json file\n",
    "prep_pars_dict = {\"n_pitches\": n_pitches,\n",
    "                 \"lowest_pitch\": lowest_pitch,\n",
    "                 \"beat_resolution\": beat_resolution, \n",
    "                  \"beats_per_instance\": sample_size}\n",
    "with open(file_directory + \"/preparation_params.json\", \"w\") as file:\n",
    "    json.dump(prep_pars_dict, file, indent = 6)\n",
    "\n",
    "## save data as compressed npz files\n",
    "np.savez_compressed(file_directory + \"/prepared_arrays.npz\", data=data_array, labels=label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b879ab",
   "metadata": {},
   "source": [
    "## Evaluate Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "file_directory = f\"./prepared_data/lpd5_full_12bars\"  # change if wanted\n",
    "loaded_data = np.load(file_directory + \"/prepared_arrays.npz\")\n",
    "loaded_data_array, loaded_label_array = loaded_data[\"data\"], loaded_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of data for each genre?\n",
    "\n",
    "plt.hist(loaded_label_array)\n",
    "plt.ylabel(\"# of instances\")\n",
    "plt.xlabel(\"genre label\")\n",
    "\n",
    "print(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96920dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total pitch range \n",
    "\n",
    "n_pitches_array = loaded_data_array.sum(axis = 1).sum(axis = 0)\n",
    "plt.plot(np.arange(72), n_pitches_array, \"ro\")\n",
    "plt.ylabel(\"# of pitches\")\n",
    "plt.xlabel(\"pitches\")\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f5912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert random instances of loaded data to wave (audio) file & display them\n",
    "\n",
    "n = 10 # number or random examples\n",
    "rand_idxs = np.random.randint(0, len(loaded_label_array), n)\n",
    "\n",
    "for i in tqdm(rand_idxs):\n",
    "    X, y = loaded_data_array[i, :, :], loaded_label_array[i]\n",
    "    \n",
    "    genre_of_X = genre_list[y]\n",
    "    \n",
    "    X_padded = np.pad(X, ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))) # complete pitch range\n",
    "    X_music = muspy.from_pianoroll_representation(X_padded > 0, \n",
    "                resolution = beat_resolution, encode_velocity = False) # convert to muspy.music_object\n",
    "\n",
    "    X_timestamp = datetime.datetime.now()\n",
    "    muspy.write_audio(path = file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\", \n",
    "                      music = X_music) \n",
    "    \n",
    "    # display audio & show pianoroll\n",
    "    print(genre_of_X + \":\")\n",
    "    display(Audio(filename = file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\"))\n",
    "    muspy.visualization.show_pianoroll(X_music)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b12ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into pytorch dataset & dataloader\n",
    "batch_size = 15\n",
    "\n",
    "# convert to pytorch tensor\n",
    "data_tensor = torch.as_tensor(loaded_data_array, dtype=torch.float32)\n",
    "label_tensor = torch.as_tensor(loaded_label_array, dtype=torch.int)\n",
    "\n",
    "# create pytorch dataset & dataloader\n",
    "dataset = torch.utils.data.TensorDataset(data_tensor, label_tensor)\n",
    "lpd5_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [1,2,3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0.,  1.,  2.])[np.array([True, True, False])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2dd837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
