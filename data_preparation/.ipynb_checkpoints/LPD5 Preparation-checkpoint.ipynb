{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6432fcba",
   "metadata": {},
   "source": [
    "install\n",
    "1. muspy & pypianoroll via pip install in environment folder (e.g. /Users/kai/anaconda3/opt/envs/MusiCAN/bin)\n",
    "2. fluidsynth via conda install -c conda-forge fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b714ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_musescore_soundfont() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "muspy.download_bravura_font() # if you didn't do it already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Audio, display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "from tqdm import tqdm # valuebar for iterations\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "\n",
    "import muspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels & id_list\n",
    "\n",
    "genre_list = ['Rap', 'Latin', 'International', 'Electronic', \n",
    "              'Country', 'Folk', 'Blues', 'Reggae', 'Jazz',\n",
    "              'Vocal', 'New-Age', 'RnB', 'Pop_Rock'] # genre <-> numeric label = index\n",
    "\n",
    "id_list = [] # id = MillionSongsDataset ID\n",
    "track_label_list = []\n",
    "for path in os.listdir(\"unprepared_data/id_lists_amg\"):\n",
    "    filepath = \"unprepared_data/id_lists_amg/\" + path\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        ids = [line.rstrip() for line in f]\n",
    "        number_of_ids = len(ids)\n",
    "        id_list.extend(ids)\n",
    "    \n",
    "    genre_no = genre_list.index(path[8:-4])\n",
    "    track_label_list.extend([genre_no] * number_of_ids)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6831fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no multiple genre label \n",
    "n = 0\n",
    "id_array = np.array(id_list)\n",
    "for id_1 in id_list:\n",
    "    n_ids = np.sum(id_array == id_1)\n",
    "    n += (n_ids - 1)\n",
    "n == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a99247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def msd_id_to_dirs(msd_id):\n",
    "    \"\"\"Given an MillionSongsDataset ID, generate the path prefix.\n",
    "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
    "    return(msd_id[2] + \"/\" + msd_id[3] + \"/\" + msd_id[4] + \"/\" + msd_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def pianoroll_plot(multitrack):\n",
    "    \"\"\"Given muspy.multitrack object, plot part of pianoroll\"\"\"\n",
    "    multitrack_copy = multitrack.copy()\n",
    "    multitrack_copy.trim(end=12 * 96)\n",
    "    axs = multitrack_copy.plot()\n",
    "    plt.gcf().set_size_inches((16, 8))\n",
    "    for ax in axs:\n",
    "        for x in range(96, 12 * 96, 96):     \n",
    "            ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a15f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "# set values\n",
    "n_pitches = 7*12  # number of pitches\n",
    "lowest_pitch = 2*12  # MIDI note number of the lowest pitch\n",
    "beat_resolution = 12 # temporal resolution of a beat (in timestep), 24 in data, 12 for MusiGAN\n",
    "sample_size = 4*4 # number of beats per instance created by track-cropping, 4 bars for MusiGAN\n",
    "min_n_notes = 8 # minimal number of notes per instance\n",
    "\n",
    "dataset_root = \"unprepared_data/lpd_5/lpd_5_cleansed/\"\n",
    "\n",
    "# iterate over all the songs in the ID list\n",
    "data_list = []\n",
    "data_label_list = []\n",
    "\n",
    "for i, msd_id in enumerate(tqdm(id_list)):\n",
    "    \n",
    "    # load multitrack as a pypianoroll.Multitrack instance\n",
    "    song_dir = dataset_root + msd_id_to_dirs(msd_id)\n",
    "    filename = os.listdir(song_dir)[0]\n",
    "    multitrack = pypianoroll.load(song_dir + \"/\" + filename)\n",
    "    \n",
    "    # binarize pianorolls\n",
    "    multitrack.binarize()\n",
    "    \n",
    "    # remove trailing silence: multitrack.trim()\n",
    "    \n",
    "    # downsample pianorolls (shape: time x pitches)\n",
    "    multitrack.set_resolution(beat_resolution)\n",
    "\n",
    "    # array conversion (shape: tracks x time x pitches) & extract piano track (= 2nd track) \n",
    "    pianoroll = multitrack.stack()[1,:,:]\n",
    "    \n",
    "    # fix pitch range\n",
    "    pianoroll = pianoroll[:, lowest_pitch : lowest_pitch + n_pitches] # (shape: time x pitches))\n",
    "    \n",
    "    # crop pianoroll into smaller training samples\n",
    "    n_timesteps = sample_size * beat_resolution # time steps per instance\n",
    "    pianoroll = pianoroll[ : pianoroll.shape[0] - (pianoroll.shape[0] % n_timesteps), :] # make sure: number of total timesteps of track % n_timesteps == 0, else skip last bar\n",
    "    pianoroll = pianoroll.reshape((-1, n_timesteps, n_pitches))\n",
    "    \n",
    "    # append instances with number of notes >= minimal number of notes (min_n_notes)\n",
    "    good_instances_mask = (pianoroll.sum(axis = 1).sum(axis = 1) >= min_n_notes)\n",
    "    data_list.append(pianoroll[good_instances_mask])\n",
    "    \n",
    "    # append labels\n",
    "    data_label_list.extend([track_label_list[i]] * np.sum(good_instances_mask))\n",
    "    \n",
    "data_array = np.concatenate(data_list, axis = 0) # (shape: n_instances x n_timesteps x n_pitches)\n",
    "label_array = np.array(data_label_list)\n",
    "print(f\"Successfully collect {len(data_array)} samples from {len(id_list)} songs\")\n",
    "print(f\"Data shape : {data_array.shape}, {label_array.shape}\")\n",
    "\n",
    "\n",
    "# create unique file directory to save data\n",
    "timestamp = datetime.datetime.now()\n",
    "file_directory = f\"./prepared_data/lpd5_{timestamp}\"\n",
    "os.makedirs(file_directory)\n",
    "os.makedirs(file_directory + \"/audio_examples\") # for later..\n",
    "\n",
    "# save preparation parameters as json file\n",
    "prep_pars_dict = {\"n_pitches\": n_pitches,\n",
    "                 \"lowest_pitch\": lowest_pitch,\n",
    "                 \"beat_resolution\": beat_resolution, \n",
    "                  \"beats_per_instance\": sample_size,\n",
    "                  \"minimal_number_of_notes_per_instance\": min_n_notes}\n",
    "with open(file_directory + \"/preparation_params.json\", \"w\") as file:\n",
    "    json.dump(prep_pars_dict, file, indent = 6)\n",
    "\n",
    "# save data as compressed npz files\n",
    "np.savez_compressed(file_directory + \"/prepared_arrays.npz\", data=data_array, labels=label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b12ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "batch_size = 15\n",
    "file_directory = file_directory # change if wanted\n",
    "\n",
    "loaded_data = np.load(file_directory + \"/prepared_arrays.npz\")\n",
    "loaded_data_array, loaded_label_array = loaded_data[\"data\"], loaded_data[\"labels\"]\n",
    "\n",
    "# convert to pytorch tensor\n",
    "data_tensor = torch.as_tensor(loaded_data_array, dtype=torch.float32)\n",
    "label_tensor = torch.as_tensor(loaded_label_array, dtype=torch.int)\n",
    "\n",
    "# create pytorch dataset & dataloader\n",
    "dataset = torch.utils.data.TensorDataset(data_tensor, label_tensor)\n",
    "lpd5_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f5912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert random instances of loaded data to wave (audio) file & display them\n",
    "\n",
    "n = 15 # number or random examples\n",
    "rand_idxs = np.random.randint(0, len(loaded_label_array), n)\n",
    "\n",
    "for i in tqdm(rand_idxs):\n",
    "    X, y = loaded_data_array[i, :, :], loaded_label_array[i]\n",
    "    \n",
    "    genre_of_X = genre_list[y]\n",
    "    \n",
    "    X_padded = np.pad(X, ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))) # complete pitch range\n",
    "    X_music = muspy.from_pianoroll_representation(X_padded > 0, \n",
    "                resolution = beat_resolution, encode_velocity = False) # convert to muspy.music_object\n",
    "\n",
    "    X_timestamp = datetime.datetime.now()\n",
    "    muspy.write_audio(path = file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\", \n",
    "                      music = X_music) \n",
    "    \n",
    "    # display audio & show pianoroll\n",
    "    print(genre_of_X + \":\")\n",
    "    display(Audio(filename = file_directory + f\"/audio_examples/{genre_of_X}_{X_timestamp}.wav\"))\n",
    "    muspy.visualization.show_pianoroll(X_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of data for each genre?\n",
    "\n",
    "plt.hist(loaded_label_array)\n",
    "plt.ylabel(\"# of instances\")\n",
    "plt.xlabel(\"genre label\")\n",
    "\n",
    "print(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2e8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
